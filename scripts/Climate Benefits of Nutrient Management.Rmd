---
title: "Climate Benefits of Nutrient Management"
author: "J. Beaulieu, E. Kopits, C. Moore, B. Parthum"
date: "`r Sys.Date()`"
output:
  html_document:
    df_print: paged
    toc: true
    toc_float: true
    fig_caption: yes
    depth: 2
    number_sections: true
    code_folding:  hide
editor_options: 
  chunk_output_type: console
---

# Setup R
```{r message=FALSE, warning=FALSE}
# R 3.6.1 
library(tidyverse) # dplyr, ggplot2,...
library(scales)
library(readxl) # read excel file readData.R
library(sf) # spatial data
library(USAboundaries) # for map in readData.R
library(kableExtra) # nice tables
library(MASS)
library(magrittr)

# Define local path for each user.  Will enable reading data from 
# 'Climate benefits of nutrient management' OneDrive folder maintained by Chris Moore
# 12/11/2020 moved all data into repo; no longer reading files out
# localPath <- Sys.getenv("USERPROFILE")

# This sets knitr wd to that of the Rstudio project.
knitr::opts_knit$set(
     # This should allow Rmarkdown to locate the data
     root.dir = rprojroot::find_rstudio_root_file()
)


# Print R session info
print(sessionInfo())
```

# Background

Lakes and reservoirs are sources of the greenhouse gases (GHG) methane (CH~4~), carbon dioxide (CO~2~), and nitrous oxide (N~2~O).  Emission rates (mass of GHG/unit time/unit area) tend to increase with lake nutrient and chlorophyll (chl) concentrations.  Water quality regulations that limit nutrient loading to surface waters could lead to reduced lake nutrient and chl content, thereby indirectly reducing GHG emission rates.  

In this project we combined modeled chl and nutrient concentrations for ~4000 lakes in the Chesepeake watershed under 1) psuedo current conditions,  and 2) a hypothetical future scenario where water quality regulations have reduced lake nutrient and chl concentration.  These estimates were combined with published models (DelSontro et al. 2018) that predict GHG emission rates from lake chl and nutrient concentration.  The objective of the project is to quantify the aggregate reduction in GHG emissions from the ~4000 lakes following the water quality improvement.  The reduction in GHG emissions is called the 'incremental' change.

# Methods
## Lake Model

Retired EPA researcher Bryan Milstead used the 'Northeast Lakes' model to estimate chl for lakes within the Chesapeake Bay watershed.  Chlorophyll was modeled under the 2010 and TMDLnew scenarios as defined below:

**2010** – represents an estimate of “current” load levels and uses estimated 2010 land uses, animal populations, atmospheric deposition, and point source loads (our “constant baseline” scenario for the SP study, probably a good candidate for our baseline).   

**TMDLnew** - Based on the final WIPs approved by EPA and air deposition that would meet 2020 air quality standards.

The modeled chl and nutrient concentrations are reported in ChesLakeLoadsConc.xlsx.

```{r}
chesDat <- read_excel("store/ChesLakeLoadsConc.xlsx",
                      sheet = "ChesLakeConc")

```

The model includes `r chesDat %>% nrow()` waterbodies.  Modeled chl and TP concentrations under the 2010 scenario average `r chesDat %>% summarize(meanChl = mean(Chla2010, na.rm = TRUE)*1000) %>% pull() %>% round(1)` ug L^-1^ and `r chesDat %>% summarize(meanTP = mean(Pvv2010, na.rm = TRUE)*1000) %>% pull() %>% round(1)` ug L^-1^, respectively, which are reasonable environmental values.  The model predicts that lake chl and TP will be reduced by `r chesDat %>% mutate(chlReduction = ((Chla2010 - ChlaTMDLnew) / Chla2010) * 100) %>% summarize(percentRed = mean(chlReduction, na.rm = TRUE)) %>% pull() %>% round(1)`% and `r chesDat %>% mutate(tpReduction = ((Pvv2010 - PvvTMDLnew) / Pvv2010) * 100) %>% summarize(percentRed = mean(tpReduction, na.rm = TRUE)) %>% pull() %>% round(1)`%, respectively, under the TMDLnew scenario. 
```{r }
chl.p.summary <- do.call(cbind, lapply(chesDat %>% dplyr::select(Chla2010, Pvv2010) %>% 
                                         mutate_all(~.*1000), summary)) %>% # *1000 mg/L to ug/L
  as.data.frame() %>%
  rownames_to_column(var = 'statistic') %>% 
  mutate_at(vars(contains("2010")), round, digits = 4)
  
chl.p.summary %>% kbl(col.names = c("statistic", "2010 chl", "2010 TP")) %>% kable_classic()
```
Each waterbody in the lake model output is uniquely identified by a 'WB_ID' value.  These values correspond to 'COMID' values in the NHDPlusV2 dataset, a spatial database of U.S. waterbodies.  Below we merge these data sets to combine the model output with other waterbody characteristics in NHDPlusV2, including waterbody surface areas.

``` {r results='hide', warning = FALSE, message = FALSE}
# 50 seconds
nhdSf <- st_read(dsn = "store/NHDPlusV21_National_Seamless_Flattened_Lower48.gdb",
                 layer = "NHDWaterbody") %>%
  dplyr::select(COMID, FDATE, RESOLUTION, # note, no OBJECTID when read with sf
         GNIS_ID, GNIS_NAME, AREASQKM, 
         ELEVATION, REACHCODE, FTYPE, FCODE,
         ONOFFNET, PurpCode, PurpDesc,
         MeanDepth, LakeVolume, MaxDepth, MeanDUsed, MeanDCode) # lakeMorpho data

st_crs(nhdSf) # 4269, NAD83
dim(nhdSf) # 448512 waterbodies
dim(chesDat) # 4247 waterbodies in Chesepeake Bay simulations

# we assume chesDat$WB_ID == nhdSf$COMID.  Are all WB_ID in NHD?
chesDat %>% filter(!(WB_ID %in% nhdSf$COMID)) %>% nrow() # 25 waterbodies not in NHD

chesDat %>% filter(!(WB_ID %in% nhdSf$COMID)) %>% # nothing obviously wrong with values.
  dplyr::select(WB_ID) %>% print(n=Inf)


# merge datasets
dat.sf <- merge(nhdSf, chesDat, by.x = "COMID", by.y = "WB_ID", all.y = TRUE) %>% # retain all chesDat observations
  mutate(WB_ID = as.character(COMID)) %>% # restore WB_ID column for consistency with original data.  convert to character for plotting
  dplyr::select(-COMID) %>% # remove residual COMID column
  st_transform(5070) # Transform to Albers for making map of US

dim(dat.sf) # 4247, good, kept all data

#  All WB_ID preserved from chesDat?
sum(!(dat.sf$WB_ID %in% chesDat$WB_ID)) # all are present in chesDat
sum(!(chesDat$WB_ID %in% dat.sf$WB_ID)) # all chesDat WB_ID in dat

# how many missing AREASQKM?
dat.sf %>% filter(is.na(AREASQKM)) %>% nrow() # just the 25 identified above
```

```{r fig.cap = "Location of 4,247 waterbodies in Chesapeake Bay model"}
# Map to make sure we are in correct region.
states <- us_states() %>% # get states map
  filter(name %in% c("Virginia", "Maryland", "Delaware",
                     "West Virginia", "Pennsylvania", "New York")) %>%
  st_transform(5070)

# Make a quick map.
# This seems about right.
ggplot(states) +
  geom_sf() +
  geom_sf(data = dat.sf)

dat <- as_tibble(dat.sf) # sf carries a lot of overhead not needed for most calcs.  Can convert to sf later if needed.
```



# GHG model
DelSontro et al. (2018) present linear regression models based on literature reports of chl concentration (ug/L), TP concentration (ug/L) and areal GHG emission rates (mg CH~4~-C m^-2^ day^-1^).  The models were created on the log-log scale with a small positive offset to accommodate negative areal emission rates reported in the literature.  Below we read in the model objects.

```{r}
# Total CH4 model.  mg CH4-C m-2 d-1
# read from disk
mod.ch4 <- readRDS("store/pCh4.rds")

summary(mod.ch4) # review model

# CO2 model.  mg CO2-C m-2 d-1
mod.co2 <- readRDS("store/pCo2.rds")

summary(mod.co2) # review model


# N2O model. mg N2O-n m-2 day-1
mod.n2o <- readRDS("store/pn2o.rds")

summary(mod.n2o) # review model
```


The models predict emission rates as log10(emission rate + positive offset) with the emission rate in units of mg CH~4~-C m^-2^ day^-1^, mg CO~2~-C m^-2^ day^-1^, or mg N~2~O-N m^-2^ day^-1^.  Predictions are back transformed to linear space and converted from mg of C or N, to mass of CH~4~, CO~2~, or N~2~O via helper functions.

```{r}
# little function to get CH4 in desired units
pCh4 <- function(x) { # x is output from above model which predicts log10(CH4-C +1)  (mg CH4-C m-2 d-1)
  mgCh4c <- 10^(x) - 1 # unlog, then subtract 1
  mgCh4 <- mgCh4c * (16/12) # mg CH4-C -> mg CH4
  return(mgCh4)
}

# little function to get CO2 in desired units
pCo2 <- function(x) { # x is output from above model which predicts log10(CH4-C +1)  (mg CO2-C m-2 d-1)
  mgCo2c <- 10^(x) - 43 # unlog, then subtract 43
  mgCo2 <- mgCo2c * (44/12) # mg CO2-C -> mg CO2
  return(mgCo2)
}

# little function to get N2O in desired units
pN2o <- function(x) { # x is output from above model which predicts log10(N2O-N)  (mg N2O-N m-2 d-1)
  mgN2on <- 10^(x) - 0.25 # unlog, then subtract 0.25
  mgN2o <- mgN2on * (44/14) # mg N2O-N -> mg N2O
  return(mgN2o)
}
```

## Inverse hyperbolic sine transformation
Bryan Parthum suggested using the inverse hyperbolic sine (IHS) transformation rather than log + positive offset. Under some conditions, the IHS transformation can lead to more accurate elasticity estimates than the log + positive offset transformation (Bellamare and Wichman 2020).  Here we use the data and CH~4~ model structure from DelSontro et al, but apply the IHS transformation rather than the log + positive offset.  Both models identify chlorophyll as a highly significant predictor and have similar coefficient of determination values.

```{r}
# Define transformation
ihs <- function(x) {
  y <- log(x + sqrt(x ^ 2 + 1))
  return(y)
}

# Inverse of IHS transformation
hs <- function(x) {
  y <- 0.5*exp(-x)*(exp(2*x)-1)
  return(y)
}

# load data for DelSontro et al CH4 model
allFlux <- read.table("store/allFlux.txt", 
                      header = TRUE, as.is = TRUE)

# new model with ihs transformation
mod.ch4.ihs <- lm(ihs(mg.CH4.C.m.2.d.1.Diffusive...Ebullitive) ~ ihs(Chlorophyll.a..ug.L.),
                    data = allFlux)

# compare models
summary(mod.ch4) # DelSontro model
summary(mod.ch4.ihs) # ihs model
```

Residuals from both models are approximately normally distributed and homoscedastic.
```{r}
ihs.log <- tibble(resid = c(resid(mod.ch4.ihs), resid(mod.ch4)), # model residuals
                  chl = c(mod.ch4.ihs$model$'ihs(Chlorophyll.a..ug.L.)', # ihs transformed chl
                          mod.ch4$model$`log10(Chlorophyll.a..ug.L.)`), # log transformed chl
                  model = c(rep("ihs", length(resid(mod.ch4.ihs))), # labels
                            rep("log", length(resid(mod.ch4))))) # labels

# homoscedasticity
ggplot(ihs.log, aes(chl, resid)) + 
  geom_point() + 
  facet_wrap(~model, scales = "free")
       
# normality
ggplot(ihs.log, aes(x = resid)) +
  geom_density() +
  facet_wrap(~model, scales = "free")
```

When back transformed to linear space, the model predictions are very similar up to approximately 150 mg CH4-C m-2 day-1.  Beyond that threshold, the ihs model predicts higher emission rates than the log-log model.

```{r}
# compare predictions
preds <- tibble(log.preds = predict(mod.ch4, 
                                    newdata = list(Chlorophyll.a..ug.L. = 1:100)), #75th percentile of ches chl is 36.6
                ihs.preds = predict(mod.ch4.ihs, 
                                    newdata = list(Chlorophyll.a..ug.L. = 1:100))) %>%#75th percentile of ches chl is 36.6
  mutate(log.preds = 10^(log.preds) - 1,
         ihs.preds = hs(ihs.preds))

ggplot(preds, aes(log.preds, ihs.preds)) +
  geom_point() + 
  geom_abline(slope = 1, intercept = 0) +
  xlab("CH4 emission rate (mg CH4-C m-2 day-1)\n predicted from log-log model") +
  ylab("CH4 emission rate (mg CH4-C m-2 day-1)\n predicted from ihs model") +
  ggtitle("Predictions from log-log model and ihs model")



```

## GHG Emissions and Uncertainty Estimates

We use the DelSontro et al. (2018) models to predict areal GHG emission rates (mg GHG m^-2^ day^-1^) for each waterbody under the 2010 and TMDLnew scenarios.  Uncertainty was estimated using two approaches.  

### Predict mean areal emission rates (mg GHG m^-2^ day^-1^) and 95% confidence interval 
In the first approach, we calculate the 95% confidence interval of the model prediction using the 'interval' argument in the predict() function.  This results in a prediction of the mean areal emission rate, lower 2.5 percentile, and upper 97.5 percentile for each waterbody. 

```{r}
    
dat <- dat %>% 
  mutate(ChlaDiff = Chla2010 - ChlaTMDLnew , # policy effect on chla
         PvvDiff = Pvv2010 - PvvTMDLnew,  # policy effect on P
         
         # CH4
         # 2010 emissions
         ch42010 = predict(mod.ch4, # kettlebell model.  predicts log10(mgCH4-c m-2 d-1 + 1)
                           # model expects Chlorophyll.a..ug.L., must tell it which data to use
                           newdata = list(Chlorophyll.a..ug.L. = .$Chla2010 * 1000),  # *1000 because chla2010 is mg/l.
                           interval = "confidence")[,1] %>%
           pCh4(.), # function to convert to mg Ch4 m-2 d-1
         ch42010.lwr = predict(mod.ch4, # kettlebell model.  predicts log10(mgCH4-c m-2 d-1 + 1)
                           # model expects Chlorophyll.a..ug.L., must tell it which data to use
                           newdata = list(Chlorophyll.a..ug.L. = .$Chla2010 * 1000),  # *1000 because chla2010 is mg/l.
                           interval = "confidence")[,2] %>%
           pCh4(.), # function to convert to mg Ch4 m-2 d-1         
         ch42010.upr = predict(mod.ch4, # kettlebell model.  predicts log10(mgCH4-c m-2 d-1 + 1)
                           # model expects Chlorophyll.a..ug.L., must tell it which data to use
                           newdata = list(Chlorophyll.a..ug.L. = .$Chla2010 * 1000),  # *1000 because chla2010 is mg/l.
                           interval = "confidence")[,3] %>%
           pCh4(.), # function to convert to mg Ch4 m-2 d-1
      
         
         # TMDL emissions
         ch4TMDLnew = predict(mod.ch4, # kettlebell model.  predicts log10(mgCH4-c m-2 d-1 + 1)
                              # model expects Chlorophyll.a..ug.L., must tell it which data to use
                              newdata = list(Chlorophyll.a..ug.L. = .$ChlaTMDLnew * 1000), # *1000 because chla is mg/l.
                              interval = "confidence")[,1] %>%
           pCh4(.), # function to convert to mg Ch4 m-2 d-1
         ch4TMDLnew.lwr = predict(mod.ch4, # kettlebell model.  predicts log10(mgCH4-c m-2 d-1 + 1)
                              # model expects Chlorophyll.a..ug.L., must tell it which data to use
                              newdata = list(Chlorophyll.a..ug.L. = .$ChlaTMDLnew * 1000), # *1000 because chla is mg/l.
                              interval = "confidence")[,2] %>%
           pCh4(.), # function to convert to mg Ch4 m-2 d-1
         ch4TMDLnew.upr = predict(mod.ch4, # kettlebell model.  predicts log10(mgCH4-c m-2 d-1 + 1)
                              # model expects Chlorophyll.a..ug.L., must tell it which data to use
                              newdata = list(Chlorophyll.a..ug.L. = .$ChlaTMDLnew * 1000), # *1000 because chla is mg/l.
                              interval = "confidence")[,3] %>%
           pCh4(.), # function to convert to mg Ch4 m-2 d-1
         
         
         # CO2
         # 2010 emissions
         co22010 = predict(mod.co2, # kettlebell model.  predicts log10(mgco2-c m-2 d-1 + 43)
                           # model expects Surface.Area..km2. and TP..ug.L., must tell it which data to use
                           newdata = list(Surface.Area..km2. = .$AREASQKM,
                                          TP..ug.L. = .$Pvv2010 * 1000),  # *1000 because Pvv2010 is mg/l.
                           interval = "confidence")[,1] %>%
           pCo2(.), # function to convert to mg co2 m-2 d-1
         co22010.lwr = predict(mod.co2, # kettlebell model.  predicts log10(mgco2-c m-2 d-1 + 1)
                           # model expects Surface.Area..km2. and TP..ug.L., must tell it which data to use
                           newdata = list(Surface.Area..km2. = .$AREASQKM,
                                          TP..ug.L. = .$Pvv2010 * 1000),  # *1000 because Pvv2010 is mg/l.
                           interval = "confidence")[,2] %>%
           pCo2(.), # function to convert to mg co2 m-2 d-1         
         co22010.upr = predict(mod.co2, # kettlebell model.  predicts log10(mgco2-c m-2 d-1 + 1)
                         # model expects Surface.Area..km2. and TP..ug.L., must tell it which data to use
                           newdata = list(Surface.Area..km2. = .$AREASQKM,
                                          TP..ug.L. = .$Pvv2010 * 1000),  # *1000 because Pvv2010 is mg/l.
                           interval = "confidence")[,3] %>%
           pCo2(.), # function to convert to mg co2 m-2 d-1
      
         
         # TMDL emissions
         co2TMDLnew = predict(mod.co2, # kettlebell model.  predicts log10(mgco2-c m-2 d-1 + 1)
                             # model expects Surface.Area..km2. and TP..ug.L., must tell it which data to use
                           newdata = list(Surface.Area..km2. = .$AREASQKM,
                                          TP..ug.L. = .$PvvTMDLnew * 1000),  # *1000 because Pvv2010 is mg/l.
                              interval = "confidence")[,1] %>%
           pCo2(.), # function to convert to mg co2 m-2 d-1
         co2TMDLnew.lwr = predict(mod.co2, # kettlebell model.  predicts log10(mgco2-c m-2 d-1 + 1)
                             # model expects Surface.Area..km2. and TP..ug.L., must tell it which data to use
                           newdata = list(Surface.Area..km2. = .$AREASQKM,
                                          TP..ug.L. = .$PvvTMDLnew * 1000),  # *1000 because Pvv2010 is mg/l.
                              interval = "confidence")[,2] %>%
           pCo2(.), # function to convert to mg co2 m-2 d-1
         co2TMDLnew.upr = predict(mod.co2, # kettlebell model.  predicts log10(mgco2-c m-2 d-1 + 1)
                             # model expects Surface.Area..km2. and TP..ug.L., must tell it which data to use
                           newdata = list(Surface.Area..km2. = .$AREASQKM,
                                          TP..ug.L. = .$PvvTMDLnew * 1000),  # *1000 because Pvv2010 is mg/l.
                              interval = "confidence")[,3] %>%
           pCo2(.), # function to convert to mg co2 m-2 d-1
         
         # N2O
         # 2010 emissions
         n2o2010 = predict(mod.n2o, # kettlebell model.  predicts log10(mgn2o-c m-2 d-1 + 43)
                           # model expects Surface.Area..km2. and TP..ug.L., must tell it which data to use
                           newdata = list(Surface.Area..km2. = .$AREASQKM,
                                          Chlorophyll.a..ug.L. = .$Chla2010 * 1000),  # *1000 because chl is mg/l.
                           interval = "confidence")[,1] %>%
           pN2o(.), # function to convert to mg n2o m-2 d-1
         n2o2010.lwr = predict(mod.n2o, # kettlebell model.  predicts log10(mgn2o-c m-2 d-1 + 1)
                           # model expects Surface.Area..km2. and TP..ug.L., must tell it which data to use
                           newdata = list(Surface.Area..km2. = .$AREASQKM,
                                           Chlorophyll.a..ug.L. = .$Chla2010 * 1000),  # *1000 because chl is mg/l.
                           interval = "confidence")[,2] %>%
           pN2o(.), # function to convert to mg n2o m-2 d-1         
         n2o2010.upr = predict(mod.n2o, # kettlebell model.  predicts log10(mgn2o-c m-2 d-1 + 1)
                         # model expects Surface.Area..km2. and TP..ug.L., must tell it which data to use
                           newdata = list(Surface.Area..km2. = .$AREASQKM,
                                           Chlorophyll.a..ug.L. = .$Chla2010 * 1000),  # *1000 because chl is mg/l.
                           interval = "confidence")[,3] %>%
           pN2o(.), # function to convert to mg n2o m-2 d-1
      
         
         # TMDL emissions
         n2oTMDLnew = predict(mod.n2o, # kettlebell model.  predicts log10(mgn2o-c m-2 d-1 + 1)
                             # model expects Surface.Area..km2. and TP..ug.L., must tell it which data to use
                           newdata = list(Surface.Area..km2. = .$AREASQKM,
                                          Chlorophyll.a..ug.L. = .$ChlaTMDLnew * 1000),  # *1000 because chl is mg/l.
                              interval = "confidence")[,1] %>%
           pN2o(.), # function to convert to mg n2o m-2 d-1
         n2oTMDLnew.lwr = predict(mod.n2o, # kettlebell model.  predicts log10(mgn2o-c m-2 d-1 + 1)
                             # model expects Surface.Area..km2. and TP..ug.L., must tell it which data to use
                           newdata = list(Surface.Area..km2. = .$AREASQKM,
                                          Chlorophyll.a..ug.L. = .$ChlaTMDLnew * 1000),  # *1000 because chl is mg/l.
                              interval = "confidence")[,2] %>%
           pN2o(.), # function to convert to mg n2o m-2 d-1
         n2oTMDLnew.upr = predict(mod.n2o, # kettlebell model.  predicts log10(mgn2o-c m-2 d-1 + 1)
                             # model expects Surface.Area..km2. and TP..ug.L., must tell it which data to use
                           newdata = list(Surface.Area..km2. = .$AREASQKM,
                                          Chlorophyll.a..ug.L. = .$ChlaTMDLnew * 1000),  # *1000 because chl is mg/l.
                              interval = "confidence")[,3] %>%
           pN2o(.)) # function to convert to mg n2o m-2 d-1

dat[1:5,] %>% dplyr::select(WB_ID, contains("n2o")) %>%
  kbl(caption = "Mean, lower 2.5 percentile, and upper 97.5 percentile N2O emission rate (mg N2O m-2 day-1) for five waterbodies under the '2010' and 'TMDLnew' scenarios.") %>%
  kable_classic()

dat[1:5,] %>% dplyr::select(WB_ID, contains("co2")) %>%
  kbl(caption = "Mean, lower 2.5 percentile, and upper 97.5 percentile CO2 emission rate (mg CO2 m-2 day-1) for five waterbodies under the '2010' and 'TMDLnew' scenarios.") %>%
  kable_classic()

dat[1:5,] %>% dplyr::select(WB_ID, contains("ch4")) %>%
  kbl(caption = "Mean, lower 2.5 percentile, and upper 97.5 percentile CH4 emission rate (mg CH4 m-2 day-1) for five waterbodies under the '2010' and 'TMDLnew' scenarios.") %>%
  kable_classic()

```


### Upscale to mg GHG day^-1^
The next step is to convert the areal emission rates (mg GHG m^-2^ day^-1^) to a daily emission (mg GHG day^-1^) for each waterbody.  


``` {r}

dat <- dat %>% mutate(
  # CH4
  # 2010: upscale to per lake per day emissions
  ch42010.lk.d = ch42010 * 1000000 * AREASQKM, # 1000000m2 = 1km2.  mg CH4 d-1
  ch42010.lk.d.lwr = ch42010.lwr * 1000000 * AREASQKM, # 1000000m2 = 1km2.  mg CH4 d-1
  ch42010.lk.d.upr = ch42010.upr * 1000000 * AREASQKM, # 1000000m2 = 1km2.  mg CH4 d-1
  
  # TMDLNew: upscale to per lake per day emisions
  ch4TMDLnew.lk.d = ch4TMDLnew * 1000000 * AREASQKM, # 1000000m2 = 1km2.  new variable in mg CH4 d-1
  ch4TMDLnew.lk.d.lwr = ch4TMDLnew.lwr * 1000000 * AREASQKM, # 1000000m2 = 1km2.  new variable in mg CH4 d-1
  ch4TMDLnew.lk.d.upr = ch4TMDLnew.upr * 1000000 * AREASQKM, # 1000000m2 = 1km2.  new variable in mg CH4 d-1
  
  # CO2
  # 2010: upscale to per lake per day emissions
  co22010.lk.d = co22010 * 1000000 * AREASQKM, # 1000000m2 = 1km2.  mg CO2 d-1
  co22010.lk.d.lwr = co22010.lwr * 1000000 * AREASQKM, # 1000000m2 = 1km2.  mg CO2 d-1
  co22010.lk.d.upr = co22010.upr * 1000000 * AREASQKM, # 1000000m2 = 1km2.  mg CO2 d-1
  
  # TMDLNew: upscale to per lake per day emisions
  co2TMDLnew.lk.d = co2TMDLnew * 1000000 * AREASQKM, # 1000000m2 = 1km2.  new variable in mg CO2 d-1
  co2TMDLnew.lk.d.lwr = co2TMDLnew.lwr * 1000000 * AREASQKM, # 1000000m2 = 1km2.  new variable in mg CO2 d-1
  co2TMDLnew.lk.d.upr = co2TMDLnew.upr * 1000000 * AREASQKM, # 1000000m2 = 1km2.  new variable in mg CO2 d-1 
  
  # N2O
  # 2010: upscale to per lake per day emissions
  n2o2010.lk.d = n2o2010 * 1000000 * AREASQKM, # 1000000m2 = 1km2.  mg N2O d-1
  n2o2010.lk.d.lwr = n2o2010.lwr * 1000000 * AREASQKM, # 1000000m2 = 1km2.  mg N2O d-1
  n2o2010.lk.d.upr = n2o2010.upr * 1000000 * AREASQKM, # 1000000m2 = 1km2.  mg N2O d-1
  
  # TMDLNew: upscale to per lake per day emisions
  n2oTMDLnew.lk.d = n2oTMDLnew * 1000000 * AREASQKM, # 1000000m2 = 1km2.  new variable in mg N2O d-1
  n2oTMDLnew.lk.d.lwr = n2oTMDLnew.lwr * 1000000 * AREASQKM, # 1000000m2 = 1km2.  new variable in mg N2O d-1
  n2oTMDLnew.lk.d.upr = n2oTMDLnew.upr * 1000000 * AREASQKM) # 1000000m2 = 1km2.  new variable in mg N2O d-1


dat[1:5, ] %>% dplyr::select(WB_ID, matches("n2o.*lk.d")) %>%
  kbl(caption = "Mean, lower 2.5 percentile, and upper 97.5 percentile daily N2O emission (mg N2O day-1) for five waterbodies under the '2010' and 'TMDLnew' scenarios.") %>%
  kable_classic()

dat[1:5, ] %>% dplyr::select(WB_ID, matches("co2.*lk.d")) %>%
  kbl(caption = "Mean, lower 2.5 percentile, and upper 97.5 percentile daily CO2 emission (mg CO2 day-1) for five waterbodies under the '2010' and 'TMDLnew' scenarios.") %>%
  kable_classic()

dat[1:5, ] %>% dplyr::select(WB_ID, matches("ch4.*lk.d")) %>%
  kbl(caption = "Mean, lower 2.5 percentile, and upper 97.5 percentile daily CH4 emission (mg CH4 day-1) for five waterbodies under the '2010' and 'TMDLnew' scenarios.") %>%
  kable_classic()


```

### Upscale daily emissions to annual emissions
The models used to predict areal GHG emission rates (mg GHG m^-2^ day^-1^) are based on published measurements, most of which were made during the warm summer months when emission rates are expected to be greatest.  We therefore assume the predicted areal emission rates are constant during the open-water season.  During periods of ice cover, which conservatively extend from Nov.15 - March 15 in the Chesapeake Bay watershed, areal emission rates are zero.  

```{r}
dat <- dat %>%
  dplyr::select(WB_ID, contains("lk.d")) %>%
  mutate_at(vars(-WB_ID), function(x) x * (365 - 120)) %>% # 120 days of ice cover
  rename_at(vars(-WB_ID), function(x) gsub(".d", ".yr", x))
```


### Sum annual emissions across all waterbodies.
We can now sum the total annual emissions (metric tons of GHG) across all waterbodies and both scenarios.

```{r}
dat.sum <- dat %>% 
  dplyr::select(contains("lk.yr")) %>%
 summarize_all(sum, na.rm = TRUE) %>%
  mutate_all(~. / (1000*1000*1000)) %>% # mg->g, g->kg, kg->Mg. 1 MG = 1 metric ton = 1000kg)
  rename_all(function(x) paste0(x, ".sum")) %>%
  rename_all(function(x) gsub("lk.", "", x))

dat.sum %>% dplyr::select(matches("n2o.*.yr")) %>%
  mutate_all(round, digits = 0) %>%
  kbl(caption = "Mean, lower 2.5 percentile, and upper 97.5 percentile aggregate annual N2O emission (metric tons N2O day-1) for all waterbodies under the '2010' and 'TMDLnew' scenarios.") %>%
  kable_classic()

dat.sum %>% dplyr::select(matches("co2.*.yr")) %>%
  mutate_all(round, digits = 0) %>%
  kbl(caption = "Mean, lower 2.5 percentile, and upper 97.5 percentile aggregate annual CO2 emission (metric tons CO2 day-1) for all waterbodies under the '2010' and 'TMDLnew' scenarios.") %>%
  kable_classic()

dat.sum %>% dplyr::select(matches("ch4.*.yr")) %>%
  mutate_all(round, digits = 0) %>%
  kbl(caption = "Mean, lower 2.5 percentile, and upper 97.5 percentile aggregate annual CH4 emission (metric tons CH4 day-1) for all waterbodies under the '2010' and 'TMDLnew' scenarios.") %>%
  kable_classic()

```

### Calculate incremental change

The 'incremental change' is defined as the difference in emissions between the '2010' and 'TMDLnew' scenarios.  The mean incremental change is simply calculated as the difference between the model predicted 'mean' values.  The upper 97.5 percentile of the incremental change can be calculated as the difference between the 2010 97.5 percentile and the TMDLnew 97.5 percentile.  The lower 2.5 percentile can be calculated as the difference between the 2010 and TMDLnew lower 2.5 percentile.

<!-- This calculation leads to very wide confidence intervals, including negative values for N~2~O and CO~2~.  This is probably not the best way to estimate uncertainty; however, the 'mean' estimates should be pretty good. -->

```{r}
dat.sum <- dat.sum %>%
   # incremental change (metric tons yr-1)
  mutate(ch4incr.yr = ch42010.yr.sum - ch4TMDLnew.yr.sum, 
         ch4incr.yr.upr = ch42010.yr.upr.sum - ch4TMDLnew.yr.upr.sum, 
         ch4incr.yr.lwr = ch42010.yr.lwr.sum - ch4TMDLnew.yr.lwr.sum,
         
         # CO2
         co2incr.yr = co22010.yr.sum - co2TMDLnew.yr.sum, 
         co2incr.yr.upr = co22010.yr.upr.sum - co2TMDLnew.yr.upr.sum, 
         co2incr.yr.lwr = co22010.yr.lwr.sum - co2TMDLnew.yr.lwr.sum,
         
         # N2O
         n2oincr.yr = n2o2010.yr.sum - n2oTMDLnew.yr.sum, 
         n2oincr.yr.upr = n2o2010.yr.upr.sum - n2oTMDLnew.yr.upr.sum, 
         n2oincr.yr.lwr = n2o2010.yr.lwr.sum - n2oTMDLnew.yr.lwr.sum) 


dat.sum %>% 
  dplyr::select(ch4incr.yr, ch4incr.yr.upr, ch4incr.yr.lwr, co2incr.yr, co2incr.yr.upr, 
         co2incr.yr.lwr, n2oincr.yr, n2oincr.yr.upr, n2oincr.yr.lwr) %>%
  mutate_at(vars(!contains("n2o", ignore.case = TRUE)), function(x) round(x, 0)) %>%
  mutate_at(vars(contains("n2o", ignore.case = TRUE)), function(x) round(x, 1))  %>%
  kbl(col.names = rep(c("mean", "upper 97.5", "lower 2.5"), 3),
      caption = "Incremental GHG (metric tons) calculated from model prediction error") %>%
  add_header_above(c("incremental CH4" = 3, "incremental CO2" = 3, "incremental N2O" = 3)) %>%
  kable_classic()
```

### Incremental change and uncertainty with bootstrapping

An alternative approach to estimating uncertainty is to bootstrap a sample from the `r chesDat %>% nrow()` waterbodies in the data.  This approach assumes the statistical predictions are correct, then simulates sampling error by bootstrapping across the sample.  As shown below, this generates much narrower confidence intervals than the approach utilizing the statistical prediction error.  This probably isn't the appropriate approach because we have a census of lake (e.g. perfect knowledge of the population) rather than a sample.

```{r}
# CALCULATE GHG EMISSIONS, AND INCREMENTAL CHANGES FOR GHG, CHLA, AND P-------------------

 
ghg <- list() # empty list to hold results
# time.i <- print(Sys.time())
for(i in 1:10000) { # 4 minutes
  #print(i) # print status update
  tmpData <- dat[sample(1:nrow(dat), replace = TRUE), ] # bootstrap piece: sample with replacement
  ghg[[i]] <- tmpData %>% # assign object to element i of list
    dplyr::select("WB_ID", !contains("yr.")) # exclude the upper and lower confidence estimates
}
# time.i; print(Sys.time())

# simulated incremental GHG
simIncrGhg <- lapply(ghg, function(x) {
  # sum incremental difference across all lakes
  x %>% summarise(incrementalCh4 = (sum(ch42010.lk.yr, na.rm = TRUE) - sum(ch4TMDLnew.lk.yr, na.rm = TRUE)),
                  incrementalCo2 = (sum(co22010.lk.yr, na.rm = TRUE) - sum(co2TMDLnew.lk.yr, na.rm = TRUE)),
                  incrementalN2o = (sum(n2o2010.lk.yr, na.rm = TRUE) - sum(n2oTMDLnew.lk.yr, na.rm = TRUE))) %>%
    mutate_all(function(x) x / (1000*1000*1000)) # mg->g, g->kg, kg->Mg. 1 MG = 1 metric ton = 1000kg)
}) %>%
  do.call("rbind", .) %>% # collapse to tibble
  summarise(incrCh4 = mean(incrementalCh4), # mean CH4 increment across all lakes 
            incrCh4upr = quantile(incrementalCh4, 0.975), # upper 95% increment across all lakes
            incrCh4lwr = quantile(incrementalCh4, 0.025), # lower 5% increment across all lakes
            #CO2
            incrCo2 = mean(incrementalCo2), # mean CO2 increment across all lakes 
            incrCo2upr = quantile(incrementalCo2, 0.975), # upper 95% increment across all lakes
            incrCo2lwr = quantile(incrementalCo2, 0.025), # lower 5% increment across all lakes
            #N2O
            incrN2o = mean(incrementalN2o), # mean N2o increment across all lakes 
            incrN2oupr = quantile(incrementalN2o, 0.975), # upper 95% increment across all lakes
            incrN2olwr = quantile(incrementalN2o, 0.025)) # lower 5% increment across all lakes

simIncrGhg %>%
  mutate_at(vars(!contains("n2o", ignore.case = TRUE)), function(x) round(x, 0)) %>%
  mutate_at(vars(contains("n2o", ignore.case = TRUE)), function(x) round(x, 1)) %>%
  kbl(col.names = rep(c("mean", "upper 97.5", "lower 2.5"), 3),
      caption = "Incremental GHG (metric tons) calculated from bootstrapping.") %>%
   add_header_above(c("incremental CH4" = 3, "incremental CO2" = 3, "incremental N2O" = 3)) %>%
  kable_classic()
```

### Incremental change and uncertainty in model predictions using simulation (Krinsky and Robb, 1986)

An alternative approach to estimating uncertainty is to exploit the uncertainty in the model by randomly sampling from the distribution of the model coefficients using their covariance matrix to accommodate correlation within draws. We iterate this with 10,000 random draws.

<!-- Krinsky, I and A. L. Robb. 1986. “On Approximating the Statistical Properties of Elasticities.” Review of -->
<!-- Economic and Statistics 68: 715-719. -->

```{r results='hide', message=FALSE, warning=FALSE}

dat <- as_tibble(dat.sf) # sf carries a lot of overhead not needed for most calcs.  Can convert to sf later if needed.
lakes <- dat %>% dplyr::select(WB_ID,AREASQKM)

#####################################
################################  CH4
#####################################

## 2010 Data
dat_2010 <-  dat %>%
  dplyr::select(Chla2010) %>%
  mutate('(Intercept)'=1, # match names in model
         Chla2010 = log10(Chla2010 * 1000)) %>% # mg/L chl to ug/L
  rename('log10(Chlorophyll.a..ug.L.)'=Chla2010) %>% # match names in model
  relocate('(Intercept)','log10(Chlorophyll.a..ug.L.)') %>%
  as.matrix()

## TMDL Data
dat_tmdl <-  dat %>%
  dplyr::select(ChlaTMDLnew) %>%
  mutate('(Intercept)'=1,
         ChlaTMDLnew = log10(ChlaTMDLnew * 1000)) %>% # mg/L chl to ug/L
  rename('log10(Chlorophyll.a..ug.L.)'=ChlaTMDLnew) %>%
  relocate('(Intercept)','log10(Chlorophyll.a..ug.L.)') %>%
  as.matrix()


####  PREDICTIONS

set.seed(42)
diff_ch4 <- replicate(10000, {
  
## Distribution of coefficients 
coefs = MASS::mvrnorm(1, mu = coef(mod.ch4), Sigma = vcov(mod.ch4))

## Predictions based on model uncertainty
preds_2010_lakes <- cbind(lakes,
                          dat_2010 %*% coefs) # this produces emission rate as log10(CH4-C + offset)
preds_tmdl_lakes <- cbind(lakes,
                          dat_tmdl %*% coefs)

preds_2010_lakes %<>% mutate(preds_2010_lakes = pCh4(preds_2010_lakes[,3])) # transform according to functions above -> mg CH4 m-2 day-1
preds_tmdl_lakes %<>% mutate(preds_tmdl_lakes = pCh4(preds_tmdl_lakes[,3])) # transform according to functions above -> mg CH4 m-2 day-1

preds_2010_lakes %<>% mutate(preds_2010_lakes = preds_2010_lakes * 1000000 * AREASQKM, na.rm=TRUE) # 1000000m2 = 1km2.  new variable in mg CH4 d-1
preds_tmdl_lakes %<>% mutate(preds_tmdl_lakes = preds_tmdl_lakes * 1000000 * AREASQKM, na.rm=TRUE) # 1000000m2 = 1km2.  new variable in mg CH4 d-1

preds_2010_lakes %<>% mutate(preds_2010_lakes = preds_2010_lakes * (365 - 120), na.rm=TRUE) # 120 days of ice cover. mg CH4 year-1
preds_tmdl_lakes %<>% mutate(preds_tmdl_lakes = preds_tmdl_lakes * (365 - 120), na.rm=TRUE) # 120 days of ice cover. mg CH4 year-1

preds_2010_lakes %<>% mutate(preds_2010_lakes = preds_2010_lakes / (1000*1000*1000), na.rm=TRUE) # mg->g, g->kg, kg->Mg. 1 MG = 1 metric ton = 1000kg.  
preds_tmdl_lakes %<>% mutate(preds_tmdl_lakes = preds_tmdl_lakes / (1000*1000*1000), na.rm=TRUE) # mg->g, g->kg, kg->Mg. 1 MG = 1 metric ton = 1000kg

## Convert and take difference in predictions and sum across all lakes
sum(preds_2010_lakes$preds_2010_lakes - preds_tmdl_lakes$preds_tmdl_lakes, na.rm=TRUE)

## THIS RETURNS A VECTOR OF PREDICTIONS FROM WHICH WE CAN CREATE CONFIDENCE INTERVALS
})
summary(diff_ch4)

#####################################
################################  CO2
#####################################

#### PARTS 

## 2010 Data
dat_2010 <-  dat %>%
  dplyr::select(Pvv2010,AREASQKM) %>%
  mutate('(Intercept)'=1,
         AREASQKM = log10(AREASQKM),
         TP..ug.L. = log10(Pvv2010 * 1000), #mg/L -> ug/L
         'log10(Surface.Area..km2.):log10(TP..ug.L.)' = AREASQKM*TP..ug.L.) %>%
  rename('log10(Surface.Area..km2.)'=AREASQKM,'log10(TP..ug.L.)'=TP..ug.L.) %>%
  relocate('(Intercept)','log10(Surface.Area..km2.)','log10(TP..ug.L.)','log10(Surface.Area..km2.):log10(TP..ug.L.)') %>%
  dplyr::select(-Pvv2010) %>%
  as.matrix()

## TMDL Data
dat_tmdl <-  dat %>%
  dplyr::select(PvvTMDLnew,AREASQKM) %>%
  mutate('(Intercept)'=1,
         AREASQKM = log10(AREASQKM),
         TP..ug.L. = log10(PvvTMDLnew * 1000),
         'log10(Surface.Area..km2.):log10(TP..ug.L.)' = AREASQKM*TP..ug.L.) %>%
  rename('log10(Surface.Area..km2.)'=AREASQKM,'log10(TP..ug.L.)'=TP..ug.L.) %>%
  relocate('(Intercept)','log10(Surface.Area..km2.)','log10(TP..ug.L.)','log10(Surface.Area..km2.):log10(TP..ug.L.)') %>%
  dplyr::select(-PvvTMDLnew) %>%
  as.matrix()


####  PREDICTIONS

set.seed(42)
diff_co2 <- replicate(10000, {
  
## Distribution of coefficients 
coefs = MASS::mvrnorm(1, mu = coef(mod.co2), Sigma = vcov(mod.co2))

## Predictions based on model uncertainty
preds_2010_lakes <- cbind(lakes,
                          dat_2010 %*% coefs)
preds_tmdl_lakes <- cbind(lakes,
                          dat_tmdl %*% coefs)

preds_2010_lakes %<>% mutate(preds_2010_lakes = pCo2(preds_2010_lakes[,3])) # transform according to functions above. mg CO2 m-2 day-1
preds_tmdl_lakes %<>% mutate(preds_tmdl_lakes = pCo2(preds_tmdl_lakes[,3])) # transform according to functions above. mg CO2 m-2 day-1

preds_2010_lakes %<>% mutate(preds_2010_lakes = preds_2010_lakes * 1000000 * AREASQKM, na.rm=TRUE) # 1000000m2 = 1km2.  new variable in mg CO2 d-1
preds_tmdl_lakes %<>% mutate(preds_tmdl_lakes = preds_tmdl_lakes * 1000000 * AREASQKM, na.rm=TRUE) # 1000000m2 = 1km2.  new variable in mg CO2 d-1

preds_2010_lakes %<>% mutate(preds_2010_lakes = preds_2010_lakes * (365 - 120), na.rm=TRUE) # 120 days of ice cover. mg CO2 year-1
preds_tmdl_lakes %<>% mutate(preds_tmdl_lakes = preds_tmdl_lakes * (365 - 120), na.rm=TRUE) # 120 days of ice cover. mg CO2 year-1

preds_2010_lakes %<>% mutate(preds_2010_lakes = preds_2010_lakes / (1000*1000*1000), na.rm=TRUE) # mg->g, g->kg, kg->Mg. 1 MG = 1 metric ton = 1000kg
preds_tmdl_lakes %<>% mutate(preds_tmdl_lakes = preds_tmdl_lakes / (1000*1000*1000), na.rm=TRUE) # mg->g, g->kg, kg->Mg. 1 MG = 1 metric ton = 1000kg

## Convert and take difference in predictions and sum across all lakes
sum(preds_2010_lakes$preds_2010_lakes - preds_tmdl_lakes$preds_tmdl_lakes, na.rm=TRUE)

## THIS RETURNS A VECTOR OF PREDICTIONS FROM WHICH WE CAN CREATE CONFIDENCE INTERVALS
})
summary(diff_co2)

#####################################
################################  N20
#####################################

#### PARTS 

## 2010 Data
dat_2010 <-  dat %>%
  dplyr::select(Chla2010,AREASQKM) %>%
  mutate('(Intercept)'=1,
         AREASQKM = log10(AREASQKM),
         Chla2010 = log10(Chla2010 * 1000)) %>% # mg L-1 -> ug L-1
  rename('log10(Surface.Area..km2.)'=AREASQKM,'log10(Chlorophyll.a..ug.L.)'=Chla2010) %>%
  relocate('(Intercept)','log10(Surface.Area..km2.)','log10(Chlorophyll.a..ug.L.)') %>%
  as.matrix()

## TMDL Data
dat_tmdl <-  dat %>%
  dplyr::select(ChlaTMDLnew,AREASQKM) %>%
  mutate('(Intercept)'=1,
         AREASQKM = log10(AREASQKM),
         ChlaTMDLnew = log10(ChlaTMDLnew * 1000)) %>% # mg L-1 -> ug L-1
  rename('log10(Surface.Area..km2.)'=AREASQKM,'log10(Chlorophyll.a..ug.L.)'=ChlaTMDLnew) %>%
  relocate('(Intercept)','log10(Surface.Area..km2.)','log10(Chlorophyll.a..ug.L.)') %>%
  as.matrix()


####  PREDICTIONS

set.seed(42)
diff_n2o <- replicate(10000, {
  
## Distribution of coefficients 
coefs = MASS::mvrnorm(1, mu = coef(mod.n2o), Sigma = vcov(mod.n2o))

## Predictions based on model uncertainty
preds_2010_lakes <- cbind(lakes,
                          dat_2010 %*% coefs)
preds_tmdl_lakes <- cbind(lakes,
                          dat_tmdl %*% coefs)

preds_2010_lakes %<>% mutate(preds_2010_lakes = pN2o(preds_2010_lakes[,3]),) # transform according to functions above. mg N2O m-2 day-1
preds_tmdl_lakes %<>% mutate(preds_tmdl_lakes = pN2o(preds_tmdl_lakes[,3])) # transform according to functions above. mg N2O m-2 day-1

preds_2010_lakes %<>% mutate(preds_2010_lakes = preds_2010_lakes * 1000000 * AREASQKM, na.rm=TRUE) # 1000000m2 = 1km2.  new variable in mg N2O d-1
preds_tmdl_lakes %<>% mutate(preds_tmdl_lakes = preds_tmdl_lakes * 1000000 * AREASQKM, na.rm=TRUE) # 1000000m2 = 1km2.  new variable in mg N2O d-1

preds_2010_lakes %<>% mutate(preds_2010_lakes = preds_2010_lakes * (365 - 120), na.rm=TRUE) # 120 days of ice cover. mg N2O year-1
preds_tmdl_lakes %<>% mutate(preds_tmdl_lakes = preds_tmdl_lakes * (365 - 120), na.rm=TRUE) # 120 days of ice cover. mg N2O year-1

preds_2010_lakes %<>% mutate(preds_2010_lakes = preds_2010_lakes / (1000*1000*1000), na.rm=TRUE) # mg->g, g->kg, kg->Mg. 1 MG = 1 metric ton = 1000kg
preds_tmdl_lakes %<>% mutate(preds_tmdl_lakes = preds_tmdl_lakes / (1000*1000*1000), na.rm=TRUE) # mg->g, g->kg, kg->Mg. 1 MG = 1 metric ton = 1000kg

## Convert and take difference in predictions and sum across all lakes
sum(preds_2010_lakes$preds_2010_lakes - preds_tmdl_lakes$preds_tmdl_lakes, na.rm=TRUE)

## THIS RETURNS A VECTOR OF PREDICTIONS FROM WHICH WE CAN CREATE CONFIDENCE INTERVALS
})
summary(diff_n2o)
```

```{r}
kr_simulations <- data.frame(mean_ch4 = round(mean(diff_ch4),0),
                             uppr_ch4 = round(quantile(diff_ch4,.95),0),
                             lowr_ch4 = round(quantile(diff_ch4,.05),0),
                             mean_co2 = round(mean(diff_co2),0),
                             uppr_co2 = round(quantile(diff_co2,.95),0),
                             lowr_co2 = round(quantile(diff_co2,.05),0),
                             mean_n2o = round(mean(diff_n2o),1),
                             uppr_n2o = round(quantile(diff_n2o,.95),1),
                             lowr_n2o = round(quantile(diff_n2o,.05),1))
rownames(kr_simulations) <- c()
  
kr_simulations %>%
  kbl(col.names = rep(c("mean", "upper 95", "lower 5"), 3),
      caption = "Incremental GHG (metric tons) calculated from simulation (Krinsky and Robb, 1986)") %>%
   add_header_above(c("incremental CH4" = 3, "incremental CO2" = 3, "incremental N2O" = 3)) %>%
  kable_classic()
```
