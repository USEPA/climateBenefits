---
title: "Climate Benefits of Nutrient Management"
author: "J. Beaulieu, E. Kopits, C. Moore, B. Parthum"
date: "`r Sys.Date()`"
output:
  html_document:
    df_print: paged
    toc: true
    toc_float: true
    fig_caption: yes
    depth: 2
    number_sections: true
    code_folding:  hide
editor_options: 
  chunk_output_type: console
---

# Setup R
```{r message=FALSE, warning=FALSE}
# R 4.0.3
# see renv.lock for package versions
library(tidyverse) # dplyr, ggplot2,...
library(scales)
library(readxl) # read excel file readData.R
library(sf) # spatial data
library(USAboundaries) # for states map in Methods section
library(maps) # county map in 'Plots of total emission reductions per county'
library(geodata) # NLCD data
library(kableExtra) # nice tables
library(MASS)
library(magrittr)
library(tigris) # county level data
library(cowplot) # multiple plots per page
library(ggiraph) # interactive county level plots
library(ggallin) # psuedo log10 transformation
library(rcartocolor) # color scales for maps
library(lubridate)
library(truncnorm)
library(tictoc) # for timing processes
library(future.apply) # future_replicate
library(furrr) # future_map
library(data.table) #rbindlist

# these libraries are needed when reading raw netCDF files,
# but this work has been done and files are written to disk, then
# read in below.  The netCDF code has been commented out.  We technically
# dont' need these libraries, but lets keep them for future reproducibility.
library(ncdf4) # reading in ice data
library(ncdf4.helpers) # reading in ice data
library(pbapply) # status updates for big ice data loop


library(conflicted)
conflicted::conflict_scout()
conflict_prefer("select", "dplyr") # select() will call dplyr::select()
conflict_prefer("filter", "dplyr") # filter() will call dplyr::filter()
conflict_prefer("rename", "dplyr") # filter() will call dplyr::rename()
conflict_prefer("map", "purrr")

# Define local path for each user.  Will enable reading data from 
# 'Climate benefits of nutrient management' OneDrive folder maintained by Chris Moore
# 12/11/2020 moved all data into repo; no longer reading files out
# localPath <- Sys.getenv("USERPROFILE")

# This sets knitr wd to that of the Rstudio project.
knitr::opts_knit$set(
  # This should allow Rmarkdown to locate the data
  root.dir = rprojroot::find_rstudio_root_file()
)

# Print R session info
print(sessionInfo())
```

# Background

Lakes and reservoirs are sources of the greenhouse gases (GHG) methane (CH~4~), carbon dioxide (CO~2~), and nitrous oxide (N~2~O).  Emission rates (mass of GHG/unit time/unit area) tend to increase with lake nutrient and chlorophyll (chl) concentrations.  Water quality regulations that limit nutrient loading to surface waters could lead to reduced lake nutrient and chl content, thereby indirectly reducing GHG emission rates.  

In this project we combined modeled chl and nutrient concentrations for ~4000 lakes in the Chesepeake watershed under 1) psuedo current conditions,  and 2) a hypothetical future scenario where water quality regulations have reduced lake nutrient and chl concentration.  These estimates were combined with published models (DelSontro et al. 2018) that predict GHG emission rates from lake chl and nutrient concentration.  The objective of the project is to quantify the aggregate reduction in GHG emissions from the ~4000 lakes following the water quality improvement.  The reduction in GHG emissions is called the 'incremental' change.

# Methods
## Lake Model

Retired EPA researcher Bryan Milstead used the 'Northeast Lakes' model to estimate chl for lakes within the Chesapeake Bay watershed.  Chlorophyll was modeled under the 2010 and TMDLnew scenarios as defined below:

**2010** – represents an estimate of “current” load levels and uses estimated 2010 land uses, animal populations, atmospheric deposition, and point source loads (our “constant baseline” scenario for the SP study, probably a good candidate for our baseline).   

**TMDLnew** - Based on the final WIPs approved by EPA and air deposition that would meet 2020 air quality standards.

The modeled chl and nutrient concentrations are reported in ChesLakeLoadsConc.xlsx.

```{r}
chesDat <- read_excel("store/ChesLakeLoadsConc.xlsx",
                      sheet = "ChesLakeConc")

```

The model includes `r chesDat %>% nrow()` waterbodies.  Modeled chl and TP concentrations under the 2010 scenario average `r chesDat %>% summarize(meanChl = mean(Chla2010, na.rm = TRUE)*1e3) %>% pull() %>% round(1)` ug L^-1^ and `r chesDat %>% summarize(meanTP = mean(Pvv2010, na.rm = TRUE)*1e3) %>% pull() %>% round(1)` ug L^-1^, respectively, which are reasonable environmental values.  The model predicts that lake chl and TP will be reduced by `r chesDat %>% mutate(chlReduction = ((Chla2010 - ChlaTMDLnew) / Chla2010) * 100) %>% summarize(percentRed = mean(chlReduction, na.rm = TRUE)) %>% pull() %>% round(1)`% and `r chesDat %>% mutate(tpReduction = ((Pvv2010 - PvvTMDLnew) / Pvv2010) * 100) %>% summarize(percentRed = mean(tpReduction, na.rm = TRUE)) %>% pull() %>% round(1)`%, respectively, under the TMDLnew scenario. 
```{r }
chl.p.summary <- do.call(cbind, lapply(chesDat %>% dplyr::select(Chla2010, Pvv2010, Nvv2010) %>% 
                                         mutate_all(~.*1e3), summary)) %>% # *1e3 mg/L to ug/L
  as.data.frame() %>%
  rownames_to_column(var = 'statistic') %>% 
  mutate_at(vars(contains("2010")), round, digits = 4)

chl.p.summary %>% kbl(col.names = c("statistic", "2010 chl", "2010 TP", "2010 TN")) %>% kable_classic()
```
Each waterbody in the lake model output is uniquely identified by a 'WB_ID' value.  These values correspond to 'COMID' values in the NHDPlusV2 dataset, a spatial database of U.S. waterbodies.  Below we merge these data sets to combine the model output with other waterbody characteristics in NHDPlusV2, including waterbody surface areas.

``` {r results='hide', warning = FALSE, message = FALSE}

# 50 seconds
nhdSf <- st_read(dsn = "store/NHDPlusV21_National_Seamless_Flattened_Lower48.gdb",
                 layer = "NHDWaterbody") %>%
    dplyr::select(COMID, FDATE, RESOLUTION, # note, no OBJECTID when read with sf
                GNIS_ID, GNIS_NAME, AREASQKM, 
                ELEVATION, REACHCODE, FTYPE, FCODE,
                ONOFFNET, PurpCode, PurpDesc,
                MeanDepth, LakeVolume, MaxDepth, MeanDUsed, MeanDCode) # lakeMorpho data

st_crs(nhdSf) # 4269, NAD83
dim(nhdSf) # 448512 waterbodies
dim(chesDat) # 4247 waterbodies in Chesepeake Bay simulations

# we assume chesDat$WB_ID == nhdSf$COMID.  Are all WB_ID in NHD?
chesDat %>% filter(!(WB_ID %in% nhdSf$COMID)) %>% nrow() # 25 waterbodies not in NHD

chesDat %>% filter(!(WB_ID %in% nhdSf$COMID)) %>% # nothing obviously wrong with values.
  dplyr::select(WB_ID) %>% print(n=Inf)

# merge datasets
dat.sf <- merge(nhdSf, chesDat, by.x = "COMID", by.y = "WB_ID", all.y = TRUE) %>% # retain all chesDat observations
  mutate(WB_ID = as.character(COMID)) %>% # restore WB_ID column for consistency with original data.  convert to character for plotting
  dplyr::select(-COMID) # remove residual COMID column

dim(dat.sf) # 4247, good, kept all data

#  All WB_ID preserved from chesDat?
sum(!(dat.sf$WB_ID %in% chesDat$WB_ID)) # all are present in chesDat
sum(!(chesDat$WB_ID %in% dat.sf$WB_ID)) # all chesDat WB_ID in dat

# how many missing AREASQKM?
dat.sf %>% filter(is.na(AREASQKM)) %>% nrow() # just the 25 identified above
dat.sf <- dat.sf %>% dplyr::filter(!is.na(AREASQKM))# remove rows without area, corrupts ice extent calcs below
dim(dat.sf) #4222, missing area deleted

#st_write(dat.sf, 'store\\study_lakes\\study_lakes.shp') ## export lake polys
#st_write(dat.sf, 'store\\study_lakes\\study_lakes.gpkg') ## export lake polys

dat <- sf::st_drop_geometry(dat.sf) %>% as_tibble() # sf carries a lot of overhead not needed for most calcs.  Can convert to sf later if needed.
```

```{r fig.cap = "Location of 4,222 waterbodies in Chesapeake Bay Watershed model"}
# read in chesapeake bay watershed boundary
# https://data-chesbay.opendata.arcgis.com/search?categories=boundaries
wsb <- st_read("maps/chesapeakeBayWatershed/Chesapeake_Bay_Watershed_Boundary.shp")

# read in chesapeake bay boundary
# https://data-chesbay.opendata.arcgis.com/search?categories=boundaries

cbb <- st_read("maps/Chesapeake_Bay_Shoreline_Medium_Resolution.shp")

# Map to make sure we are in correct region.
states <- us_states() %>% # get states map
  filter(name %in% c("Virginia", "Maryland", "Delaware",
                     "West Virginia", "Pennsylvania", "New York")) 

# Make a quick map.
# This seems about right.
ggplot() +
  geom_sf(data = states) +
  geom_sf(data = wsb, fill = "light blue") +
  geom_sf(data = cbb, fill = "blue", size = NA) +
  geom_sf(data = dat.sf) +
  coord_sf(crs = st_crs(5070)) # change to albers for plotting
```


##  Ice cover
```{r message=FALSE, warning=FALSE, results="hide"}
lakeCtr <- st_centroid(dat.sf) # define centroid of lake polygon
#plot(st_geometry(dat.sf)[1]) # plot one lake
#plot(st_geometry(lakeCtr)[1], add = TRUE) # overlay centroid

# netCDF file------------------------------------------
# # Commented code below used to extract and summarize ice cover data.  It writes .shp that
# # has no ice cover data for a handful of lakes.  That .shp is read into ArcGIS Pro and missing
# # values are permuted using a nearest neighbor approach.  The final filled .shp is written out
# # of ArcGIS Pro and read in below.  The code for the netCDF does not need to be rerun.

# 
# # awesome package vignette: 
# # https://cran.r-project.org/web/packages/futureheatwaves/vignettes/starting_from_netcdf.html#:~:text=You%20can%20read%20netCDF%20data,connection%20to%20a%20netCDF%20file.
# # ncdf file downloaded  from Climate Data Center
# ice <- nc_open("store/ice.cover.10year.nc") 
# 
# ice # good!  one variable with three dimensions!
# 
# lon <- ncvar_get(ice, varid = "longitude") # extract longitude
# lat <- ncvar_get(ice, varid = "latitude") # extract latitude
# summary(lon);summary(lat) # lon matches bounding box for watershed
# 
# # inspect time dimension
# ice$dim$time
# ice$dim$time$units # hours since 1900-01-01 00:00:00.0
# ice$dim$time$calendar # gregorian.  Good, consistent with base R as.Date
# 
# ice.time <- as.POSIXct(ice$dim$time$vals * 3600, # convert hours to seconds, which are basis for POSIX class (60*60=3600)
#                         origin = as.POSIXct("1900-01-01 00:00:00"), tz = "UTC") # UTC per CDS manual
# ice.time # looks good
# 
# # licd = lake ice depth see table 1 at
# # https://confluence.ecmwf.int/display/CKB/ERA5-Land%3A+data+documentation#ERA5Land:datadocumentation-Howtouselake-relatedfields
# iceU <- ncvar_get(ice, varid = "licd") # pull ice depth data.   
# 
# # This variable is in a 3 dimensional array ordered as longitude, then latitude, then time
# dim(iceU) # 71 81 1513 
# dim(lon) # 71
# dim(lat) # 81
# dim(ice.time) # 1513
# 
# {# demo
# # # demo:  pull the modeled U10 at a certain location and time step.
# # lon.index <- which.min(abs(lon - sampFrm$lon.dd83[1])) # minimal distance between grid and desired location
# # lat.index <- which.min(abs(lat - sampFrm$lat.dd83[1])) # minimal distance between grid and desired location
# # time.index <- which(ice.time == as.POSIXct("2017-07-13 12:00:00")) # hourly data available.
# # 
# # iceU[lon.index, lat.index, time.index] # -0.9, cool!
# # 
# # # demo: get and plot full time series at grid point closes to lake:
# # iceU.ts <- nc.get.var.subset.by.axes(ice, "u10",
# #                                       axis.indices = list(X = lon.index,
# #                                                           Y = lat.index))
# # dim(iceU.ts) # 1 1 2208  1 lon, 1 lat, 2208 times
# # 
# # data_frame(time = ice.time,
# #            u10 = as.vector(iceU.ts)) %>%
# #   ggplot(aes(time, u10)) +
# #   geom_line()
# }
# 
# # pull entire time series for each waterbody
# #1. calculate lon and lat indices for each row (e.g. waterbody)
# # need to project to WGS84 for lat long
# dim(lakeCtr) #4222
# dim(lon) #71
# 
# lakeCtr <- lakeCtr %>% 
#   mutate(lk.lon = st_coordinates(.)[,1],
#          lk.lat = st_coordinates(.)[,2]) %>%
#   dplyr::select(lk.lat, lk.lon, WB_ID) %>%
#   st_drop_geometry() %>%
#   rowwise() %>% # mutate by row!!!!
#   mutate(lon.index = which.min(abs(lon - lk.lon)), # index for minimum distance between target and grid longitude
#          lat.index = which.min(abs(lat - lk.lat)), # index for minimum distance between target and grid latitude
#          lon.grid = lon[lon.index], # extract lon of closest grid, not needed for calcs, just to double check map matches observed
#          lat.grid = lat[lat.index]) %>% # extract lat of closest grid, not needed for calcs, just to double check map matches observed
#   ungroup()
# 
# # double check that extracted grids are spatially matched to lake targets
# lakeCtr %>%
#   dplyr::select(lk.lon, lk.lat, lon.grid, lat.grid) %>% # yes
#   print(n=Inf)
# 
# 
# #2. split dataframe into list
# lakeCtr.l <- split(lakeCtr, seq(nrow(lakeCtr)))
# 
# 
# #3. extract ice depth time series for each waterbody and place in list element.
# # each list element is a df containing full time series of ice depth for each lake.
# # winter 2010/2011: Nov - Dec. 2010, Jan - March 2011
# # winter 2011/2012: Nov - Dec. 2011, Jan - March 2012
# # winter 2012/2013: Nov - Dec. 2012, Jan - March 2013
# # winter 2013/2014: Nov - Dec. 2013, Jan - March 2014
# # winter 2014/2015: Nov - Dec. 2014, Jan - March 2015
# # winter 2015/2016: Nov - Dec. 2015, Jan - March 2016
# # winter 2016/2017: Nov - Dec. 2016, Jan - March 2017
# # winter 2017/2018: Nov - Dec. 2017, Jan - March 2018
# # winter 2018/2019: Nov - Dec. 2018, Jan - March 2019
# # winter 2019/2020: Nov - Dec. 2019, Jan - March 2020
# 
# # 2 minutes
# lakeCtr.l.i <- pblapply(lakeCtr.l, function(x) { # pblapply produces progress bar
#   data.frame(ice = nc.get.var.subset.by.axes(ice, "licd", # extract ice cover component 
#                                              axis.indices = list(X = x$lon.index,
#                                                                  Y = x$lat.index)) %>%
#                as.vector(),
#              time = ice.time, # add time stamp (daily ice data)
#              date = as.Date(ice.time), # collapse time stamp to date
#              lk.lat = x$lk.lat, # add latitude
#              lk.lon = x$lk.lon, # add longitude
#              WB_ID = x$WB_ID) %>% # add waterbody ID
#     # filter out extra time periods that came with climate data center download.
#     dplyr::filter(date > as.Date("2010-10-01"), # exclude Jan-Mar 2010
#                   date < as.Date("2020-04-01")) %>% # exclude Nov-Dec 2020
#     #  lake ice can be fractional within a grid-box with inland water (10 cm of ice means 
#     # 100 % of a grid-box or tile is covered with ice; 0 cm of ice means 100 % of the grid-box 
#     # is covered by water; in between a linear interpolation is applied)
#     mutate(ice = ice * 100, # convert from m to cm:  
#            ice.present = ifelse(ice > 1, # thickness > 1 cm
#                                 1, # yes, ice cover
#                                 0), # else, no ice cover
#     ice.year = ifelse(time < as.Date("2011-04-01"),
#                       "2010/2011",
#                       ifelse(time > as.Date("2011-04-01") & time < as.Date("2012-04-01"),
#                              "2011/2012",
#                              ifelse(time > as.Date("2012-04-01") & time < as.Date("2013-04-01"),
#                                     "2012/2013",
#                                     ifelse(time > as.Date("2013-04-01") & time < as.Date("2014-04-01"),
#                                            "2013/2014",
#                                            ifelse(time > as.Date("2014-04-01") & time < as.Date("2015-04-01"),
#                                                   "2014/2015",
#                                                   ifelse(time > as.Date("2015-04-01") & time < as.Date("2016-04-01"),
#                                                          "2015/2016",
#                                                          ifelse(time > as.Date("2016-04-01") & time < as.Date("2017-04-01"),
#                                                                 "2016/2017",
#                                                                 ifelse(time > as.Date("2017-04-01") & time < as.Date("2018-04-01"),
#                                                                        "2017/2018",
#                                                        ifelse(time > as.Date("2018-04-01") & time < as.Date("2019-04-01"),
#                                                               "2018/2019",
#                                                   ifelse(time > as.Date("2019-04-01"),
#                                                          "2019/2020",
#                                                          "test"))))))))))) %>% # test if no match.  should be none
#     group_by(ice.year) %>%
#     summarise(day.of.ice = sum(ice.present)) %>% # this gives total days of ice per year
#     summarise(day.of.ice = mean(day.of.ice)) # average days of ice across ten years
# 
# })
# 
# lakeCtr.i <- do.call("rbind", lakeCtr.l.i) # 
# head(lakeCtr.i) # 10 year mean day of ice per row
# dim(lakeCtr.i) # 4222, 1
# names(lakeCtr.i) # day.of.ice
# names(lakeCtr) 
# 
# # convert to sf object
# lakeCtr.sf <- cbind(lakeCtr, lakeCtr.i) %>%
#   st_as_sf(coords = c("lk.lon", "lk.lat"), crs = 4269)
# 
# # 165 lakes missing ice data?
# lakeCtr.sf %>% dplyr::filter(is.na(day.of.ice))
# 
# # Prepare to write to .shp.  will fill missing values with nearest neighbor values
# # in ArcGIS Pro.
# lakeCtr_sf <- lakeCtr.sf %>% 
#   rename_all(function(x) gsub("\\.", "_", x)) %>% # replace . with _
#   # .shp replaces NA with 0!  To avoid this, I replaced all NA with -9999 as flag to screen in GIS (see below).
#   # In GIS, convert .shp to .gdb, select all -9999 values, use field calculator
#   # to set to 'None', then use 'Fill Missing Values" tool (K (5) nearest neighbors).
#   # finally, use 'Spatial Join' in GIS to merge filled values with original file.
#   mutate(day_of_ice = replace(day_of_ice, is.na(day_of_ice), -9999)) 
# 
# # write .shp
# # st_write(lakeCtr_sf, "output/iceCover.shp", delete_layer = TRUE)
# 
# # Can't get .gpkg to work?  File not readable in ArcGIS?
# # st_write(obj = lakeCtr_sf,
# #          dsn = "output/iceCover.gpkg",
# #          layer = "ice_cover",
# #          append = FALSE,
# #          driver = "GPKG")
# # st_layers("output/iceCover.gpkg")

# read in file with missing values filled in--------------------
iceCover <- st_read("output/iceCover.gdb", layer = "iceCoverFill") %>%
  rename(day_of_ice_filled = DAY_OF_ICE_1) %>%
  dplyr::select(WB_ID, day_of_ice_filled)

# no missing values!
iceCover %>% dplyr::filter(is.na(day_of_ice_filled))
names(iceCover)

# merge ice cover estimates with dat
dim(dat) # 4222
dat <- inner_join(dat, st_drop_geometry(iceCover))
dim(dat) # 4222
```

Ice cover effectively eliminates the exchange of gases between lakes and the atmosphere; therefore GHG emission rates are 0 during periods of ice cover.  Duration of ice cover during the winter of 2019 - 2020 was downloaded from the ERA-5 Land data set (https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-land?tab=overview) and spatially joined to the centroid of the NHD polygon for each waterbody in the watershed. Total days of ice cover range from `r min(lakeCtr$day.of.ice, na.rm = TRUE)` to `r max(lakeCtr$day.of.ice, na.rm = TRUE)`, with lakes in the northern portion of the watershed experiencing longer ice-cover duration than those in the south.
```{r message = FALSE, fig.cap = "Ice cover duration during the 2010-2020 winter for waterbodies in Chesapeake Bay Watershed model"}
ggplot(states) +
  geom_sf(data = wsb) + # 
  geom_sf(fill = NA) +
  geom_sf(data = iceCover, aes(color = day_of_ice_filled)) +
  coord_sf(crs = st_crs(5070)) # change to albers for plotting

# ggsave("output/figures/iceCover.tiff")

```

# GHG model
DelSontro et al. (2018) present linear regression models based on literature reports of chl concentration (ug/L), TP concentration (ug/L) and areal GHG emission rates (mg CH~4~-C m^-2^ day^-1^).  The models were created on the log-log scale with a small positive offset to accommodate negative areal emission rates reported in the literature.  Below we read in the model objects.

```{r }
# Total CH4 model.  mg CH4-C m-2 d-1
# read from disk
mod.ch4 <- readRDS("store/pCh4.rds")
summary(mod.ch4) # review model

# CO2 model.  mg CO2-C m-2 d-1
mod.co2 <- readRDS("store/pCo2.rds")
summary(mod.co2) # review model

# N2O model. mg N2O-n m-2 day-1
mod.n2o <- readRDS("store/pn2o.rds")
summary(mod.n2o) # review model
```

The models predict emission rates as log10(emission rate + positive offset) with the emission rate in units of mg CH~4~-C m^-2^ day^-1^, mg CO~2~-C m^-2^ day^-1^, or mg N~2~O-N m^-2^ day^-1^.  Predictions are back transformed to linear space and converted from mg of C or N, to mass of CH~4~, CO~2~, or N~2~O via helper functions.
```{r}
# little function to get CH4 in desired units
pCh4 <- function(x) { # x is output from above model which predicts log10(CH4-C +1)  (mg CH4-C m-2 d-1)
  mgCh4c <- 10^(x) - 1 # unlog, then subtract 1
  mgCh4 <- mgCh4c * (16/12) # mg CH4-C -> mg CH4
  return(mgCh4)
}

# little function to get CO2 in desired units
pCo2 <- function(x) { # x is output from above model which predicts log10(CH4-C +1)  (mg CO2-C m-2 d-1)
  mgCo2c <- 10^(x) - 43 # unlog, then subtract 43
  mgCo2 <- mgCo2c * (44/12) # mg CO2-C -> mg CO2
  return(mgCo2)
}

# little function to get N2O in desired units
pN2o <- function(x) { # x is output from above model which predicts log10(N2O-N)  (mg N2O-N m-2 d-1)
  mgN2on <- 10^(x) - 0.25 # unlog, then subtract 0.25
  mgN2o <- mgN2on * (44/28) # mg N2O-N -> mg N2O  28mg N in N2O
  return(mgN2o)
}
```

## Inverse hyperbolic sine transformation
Bryan Parthum suggested using the inverse hyperbolic sine (IHS) transformation rather than log + positive offset. Under some conditions, the IHS transformation can lead to more accurate elasticity estimates than the log + positive offset transformation (Bellamare and Wichman 2020).  Here we use the data and CH~4~ model structure from DelSontro et al, but apply the IHS transformation rather than the log + positive offset.  Both models identify chlorophyll as a highly significant predictor and have similar coefficient of determination values.
```{r}
# Define transformation
ihs <- function(x) {
  y <- log(x + sqrt(x ^ 2 + 1))
  return(y)
}

# Inverse of IHS transformation
hs <- function(x) {
  y <- 0.5*exp(-x)*(exp(2*x)-1)
  return(y)
}

# load data for DelSontro et al CH4 model
allFlux <- read.table("store/allFlux.txt", 
                      header = TRUE, as.is = TRUE)

# new model with ihs transformation
mod.ch4.ihs <- lm(ihs(mg.CH4.C.m.2.d.1.Diffusive...Ebullitive) ~ ihs(Chlorophyll.a..ug.L.),
                  data = allFlux)

# compare models
summary(mod.ch4) # DelSontro model
summary(mod.ch4.ihs) # ihs model
```

Residuals from both models are approximately normally distributed and homoscedastic.
```{r}
ihs.log <- tibble(resid = c(resid(mod.ch4.ihs), resid(mod.ch4)), # model residuals
                  chl = c(mod.ch4.ihs$model$'ihs(Chlorophyll.a..ug.L.)', # ihs transformed chl
                          mod.ch4$model$`log10(Chlorophyll.a..ug.L.)`), # log transformed chl
                  model = c(rep("ihs", length(resid(mod.ch4.ihs))), # labels
                            rep("log", length(resid(mod.ch4))))) # labels

# homoscedasticity
ggplot(ihs.log, aes(chl, resid)) + 
  geom_point() + 
  facet_wrap(~model, scales = "free")

# normality
ggplot(ihs.log, aes(x = resid)) +
  geom_density() +
  facet_wrap(~model, scales = "free")
```

When back transformed to linear space, the model predictions are very similar up to approximately 150 mg CH4-C m-2 day-1.  Beyond that threshold, the ihs model predicts higher emission rates than the log-log model.
```{r}
# compare predictions
preds <- tibble(log.preds = predict(mod.ch4, 
                                    newdata = list(Chlorophyll.a..ug.L. = 1:100)), #75th percentile of ches chl is 36.6
                ihs.preds = predict(mod.ch4.ihs, 
                                    newdata = list(Chlorophyll.a..ug.L. = 1:100))) %>%#75th percentile of ches chl is 36.6
  mutate(log.preds = 10^(log.preds) - 1,
         ihs.preds = hs(ihs.preds))

ggplot(preds, aes(log.preds, ihs.preds)) +
  geom_point() + 
  geom_abline(slope = 1, intercept = 0) +
  xlab("CH4 emission rate (mg CH4-C m-2 day-1)\n predicted from log-log model") +
  ylab("CH4 emission rate (mg CH4-C m-2 day-1)\n predicted from ihs model") +
  ggtitle("Predictions from log-log model and ihs model")
```

# Upscaling
## GHG Emissions and Uncertainty Estimates

We use the DelSontro et al. (2018) models to predict areal GHG emission rates (mg GHG m^-2^ day^-1^) for each waterbody under the 2010 and TMDLnew scenarios.  Uncertainty was estimated using three approaches.  

### INTERVAL APPROACH: Predict mean areal emission rates (mg GHG m^-2^ day^-1^) and 95% confidence interval 
In the first approach, we calculate the 95% confidence interval of the model prediction using the 'interval' argument in the predict() function.  This results in a prediction of the mean areal emission rate, lower 2.5 percentile, and upper 97.5 percentile for each waterbody. 

```{r}
dat <- dat %>% 
  mutate(ChlaDiff = Chla2010 - ChlaTMDLnew , # policy effect on chla
         PvvDiff = Pvv2010 - PvvTMDLnew,  # policy effect on P
         
         # CH4
         # 2010 emissions
         ch42010 = predict(mod.ch4, # kettlebell model.  predicts log10(mgCH4-c m-2 d-1 + 1)
                           # model expects Chlorophyll.a..ug.L., must tell it which data to use
                           newdata = list(Chlorophyll.a..ug.L. = .$Chla2010 * 1e3),  # *1e3 because chla2010 is mg/l.
                           interval = "confidence")[,1] %>%
           pCh4(.), # function to convert to mg Ch4 m-2 d-1
         ch42010.lwr = predict(mod.ch4, # kettlebell model.  predicts log10(mgCH4-c m-2 d-1 + 1)
                               # model expects Chlorophyll.a..ug.L., must tell it which data to use
                               newdata = list(Chlorophyll.a..ug.L. = .$Chla2010 * 1e3),  # *1e3 because chla2010 is mg/l.
                               interval = "confidence")[,2] %>%
           pCh4(.), # function to convert to mg Ch4 m-2 d-1         
         ch42010.upr = predict(mod.ch4, # kettlebell model.  predicts log10(mgCH4-c m-2 d-1 + 1)
                               # model expects Chlorophyll.a..ug.L., must tell it which data to use
                               newdata = list(Chlorophyll.a..ug.L. = .$Chla2010 * 1e3),  # *1e3 because chla2010 is mg/l.
                               interval = "confidence")[,3] %>%
           pCh4(.), # function to convert to mg Ch4 m-2 d-1
         
         
         # TMDL emissions
         ch4TMDLnew = predict(mod.ch4, # kettlebell model.  predicts log10(mgCH4-c m-2 d-1 + 1)
                              # model expects Chlorophyll.a..ug.L., must tell it which data to use
                              newdata = list(Chlorophyll.a..ug.L. = .$ChlaTMDLnew * 1e3), # *1e3 because chla is mg/l.
                              interval = "confidence")[,1] %>%
           pCh4(.), # function to convert to mg Ch4 m-2 d-1
         ch4TMDLnew.lwr = predict(mod.ch4, # kettlebell model.  predicts log10(mgCH4-c m-2 d-1 + 1)
                                  # model expects Chlorophyll.a..ug.L., must tell it which data to use
                                  newdata = list(Chlorophyll.a..ug.L. = .$ChlaTMDLnew * 1e3), # *1e3 because chla is mg/l.
                                  interval = "confidence")[,2] %>%
           pCh4(.), # function to convert to mg Ch4 m-2 d-1
         ch4TMDLnew.upr = predict(mod.ch4, # kettlebell model.  predicts log10(mgCH4-c m-2 d-1 + 1)
                                  # model expects Chlorophyll.a..ug.L., must tell it which data to use
                                  newdata = list(Chlorophyll.a..ug.L. = .$ChlaTMDLnew * 1e3), # *1e3 because chla is mg/l.
                                  interval = "confidence")[,3] %>%
           pCh4(.), # function to convert to mg Ch4 m-2 d-1
         
         
         # CO2
         # 2010 emissions
         co22010 = predict(mod.co2, # kettlebell model.  predicts log10(mgco2-c m-2 d-1 + 43)
                           # model expects Surface.Area..km2. and TP..ug.L., must tell it which data to use
                           newdata = list(Surface.Area..km2. = .$AREASQKM,
                                          TP..ug.L. = .$Pvv2010 * 1e3),  # *1e3 because Pvv2010 is mg/l.
                           interval = "confidence")[,1] %>%
           pCo2(.), # function to convert to mg co2 m-2 d-1
         co22010.lwr = predict(mod.co2, # kettlebell model.  predicts log10(mgco2-c m-2 d-1 + 1)
                               # model expects Surface.Area..km2. and TP..ug.L., must tell it which data to use
                               newdata = list(Surface.Area..km2. = .$AREASQKM,
                                              TP..ug.L. = .$Pvv2010 * 1e3),  # *1e3 because Pvv2010 is mg/l.
                               interval = "confidence")[,2] %>%
           pCo2(.), # function to convert to mg co2 m-2 d-1         
         co22010.upr = predict(mod.co2, # kettlebell model.  predicts log10(mgco2-c m-2 d-1 + 1)
                               # model expects Surface.Area..km2. and TP..ug.L., must tell it which data to use
                               newdata = list(Surface.Area..km2. = .$AREASQKM,
                                              TP..ug.L. = .$Pvv2010 * 1e3),  # *1e3 because Pvv2010 is mg/l.
                               interval = "confidence")[,3] %>%
           pCo2(.), # function to convert to mg co2 m-2 d-1
         
         
         # TMDL emissions
         co2TMDLnew = predict(mod.co2, # kettlebell model.  predicts log10(mgco2-c m-2 d-1 + 1)
                              # model expects Surface.Area..km2. and TP..ug.L., must tell it which data to use
                              newdata = list(Surface.Area..km2. = .$AREASQKM,
                                             TP..ug.L. = .$PvvTMDLnew * 1e3),  # *1e3 because Pvv2010 is mg/l.
                              interval = "confidence")[,1] %>%
           pCo2(.), # function to convert to mg co2 m-2 d-1
         co2TMDLnew.lwr = predict(mod.co2, # kettlebell model.  predicts log10(mgco2-c m-2 d-1 + 1)
                                  # model expects Surface.Area..km2. and TP..ug.L., must tell it which data to use
                                  newdata = list(Surface.Area..km2. = .$AREASQKM,
                                                 TP..ug.L. = .$PvvTMDLnew * 1e3),  # *1e3 because Pvv2010 is mg/l.
                                  interval = "confidence")[,2] %>%
           pCo2(.), # function to convert to mg co2 m-2 d-1
         co2TMDLnew.upr = predict(mod.co2, # kettlebell model.  predicts log10(mgco2-c m-2 d-1 + 1)
                                  # model expects Surface.Area..km2. and TP..ug.L., must tell it which data to use
                                  newdata = list(Surface.Area..km2. = .$AREASQKM,
                                                 TP..ug.L. = .$PvvTMDLnew * 1e3),  # *1e3 because Pvv2010 is mg/l.
                                  interval = "confidence")[,3] %>%
           pCo2(.), # function to convert to mg co2 m-2 d-1
         
         # N2O
         # 2010 emissions
         n2o2010 = predict(mod.n2o, # kettlebell model.  predicts log10(mgn2o-c m-2 d-1 + 43)
                           # model expects Surface.Area..km2. and TP..ug.L., must tell it which data to use
                           newdata = list(Surface.Area..km2. = .$AREASQKM,
                                          Chlorophyll.a..ug.L. = .$Chla2010 * 1e3),  # *1e3 because chl is mg/l.
                           interval = "confidence")[,1] %>%
           pN2o(.), # function to convert to mg n2o m-2 d-1
         n2o2010.lwr = predict(mod.n2o, # kettlebell model.  predicts log10(mgn2o-c m-2 d-1 + 1)
                               # model expects Surface.Area..km2. and TP..ug.L., must tell it which data to use
                               newdata = list(Surface.Area..km2. = .$AREASQKM,
                                              Chlorophyll.a..ug.L. = .$Chla2010 * 1e3),  # *1e3 because chl is mg/l.
                               interval = "confidence")[,2] %>%
           pN2o(.), # function to convert to mg n2o m-2 d-1         
         n2o2010.upr = predict(mod.n2o, # kettlebell model.  predicts log10(mgn2o-c m-2 d-1 + 1)
                               # model expects Surface.Area..km2. and TP..ug.L., must tell it which data to use
                               newdata = list(Surface.Area..km2. = .$AREASQKM,
                                              Chlorophyll.a..ug.L. = .$Chla2010 * 1e3),  # *1e3 because chl is mg/l.
                               interval = "confidence")[,3] %>%
           pN2o(.), # function to convert to mg n2o m-2 d-1
         
         
         # TMDL emissions
         n2oTMDLnew = predict(mod.n2o, # kettlebell model.  predicts log10(mgn2o-c m-2 d-1 + 1)
                              # model expects Surface.Area..km2. and TP..ug.L., must tell it which data to use
                              newdata = list(Surface.Area..km2. = .$AREASQKM,
                                             Chlorophyll.a..ug.L. = .$ChlaTMDLnew * 1e3),  # *1e3 because chl is mg/l.
                              interval = "confidence")[,1] %>%
           pN2o(.), # function to convert to mg n2o m-2 d-1
         n2oTMDLnew.lwr = predict(mod.n2o, # kettlebell model.  predicts log10(mgn2o-c m-2 d-1 + 1)
                                  # model expects Surface.Area..km2. and TP..ug.L., must tell it which data to use
                                  newdata = list(Surface.Area..km2. = .$AREASQKM,
                                                 Chlorophyll.a..ug.L. = .$ChlaTMDLnew * 1e3),  # *1e3 because chl is mg/l.
                                  interval = "confidence")[,2] %>%
           pN2o(.), # function to convert to mg n2o m-2 d-1
         n2oTMDLnew.upr = predict(mod.n2o, # kettlebell model.  predicts log10(mgn2o-c m-2 d-1 + 1)
                                  # model expects Surface.Area..km2. and TP..ug.L., must tell it which data to use
                                  newdata = list(Surface.Area..km2. = .$AREASQKM,
                                                 Chlorophyll.a..ug.L. = .$ChlaTMDLnew * 1e3),  # *1e3 because chl is mg/l.
                                  interval = "confidence")[,3] %>%
           pN2o(.)) # function to convert to mg n2o m-2 d-1


dat[1:5,] %>% dplyr::select(WB_ID, contains("n2o")) %>%
  kbl(caption = "Mean, lower 2.5 percentile, and upper 97.5 percentile N2O emission rate (mg N2O m-2 day-1) for five waterbodies under the '2010' and 'TMDLnew' scenarios.") %>%
  kable_classic()

dat[1:5,] %>% dplyr::select(WB_ID, contains("co2")) %>%
  kbl(caption = "Mean, lower 2.5 percentile, and upper 97.5 percentile CO2 emission rate (mg CO2 m-2 day-1) for five waterbodies under the '2010' and 'TMDLnew' scenarios.") %>%
  kable_classic()

dat[1:5,] %>% dplyr::select(WB_ID, contains("ch4")) %>%
  kbl(caption = "Mean, lower 2.5 percentile, and upper 97.5 percentile CH4 emission rate (mg CH4 m-2 day-1) for five waterbodies under the '2010' and 'TMDLnew' scenarios.") %>%
  kable_classic()
```

#### Upscale to mg GHG day^-1^
The next step is to convert the areal emission rates (mg GHG m^-2^ day^-1^) to a daily emission (mg GHG day^-1^) for each waterbody.  
``` {r}
dat %<>% mutate(
  # CH4
  # 2010: upscale to per lake per day emissions
  ch42010.lk.d = ch42010 * 1e6 * AREASQKM, # 1000000m2 = 1km2.  mg CH4 d-1
  ch42010.lk.d.lwr = ch42010.lwr * 1e6 * AREASQKM, # 1000000m2 = 1km2.  mg CH4 d-1
  ch42010.lk.d.upr = ch42010.upr * 1e6 * AREASQKM, # 1000000m2 = 1km2.  mg CH4 d-1
  
  # TMDLNew: upscale to per lake per day emisions
  ch4TMDLnew.lk.d = ch4TMDLnew * 1e6 * AREASQKM, # 1000000m2 = 1km2.  new variable in mg CH4 d-1
  ch4TMDLnew.lk.d.lwr = ch4TMDLnew.lwr * 1e6 * AREASQKM, # 1000000m2 = 1km2.  new variable in mg CH4 d-1
  ch4TMDLnew.lk.d.upr = ch4TMDLnew.upr * 1e6 * AREASQKM, # 1000000m2 = 1km2.  new variable in mg CH4 d-1
  
  # CO2
  # 2010: upscale to per lake per day emissions
  co22010.lk.d = co22010 * 1e6 * AREASQKM, # 1000000m2 = 1km2.  mg CO2 d-1
  co22010.lk.d.lwr = co22010.lwr * 1e6 * AREASQKM, # 1000000m2 = 1km2.  mg CO2 d-1
  co22010.lk.d.upr = co22010.upr * 1e6 * AREASQKM, # 1000000m2 = 1km2.  mg CO2 d-1
  
  # TMDLNew: upscale to per lake per day emisions
  co2TMDLnew.lk.d = co2TMDLnew * 1e6 * AREASQKM, # 1000000m2 = 1km2.  new variable in mg CO2 d-1
  co2TMDLnew.lk.d.lwr = co2TMDLnew.lwr * 1e6 * AREASQKM, # 1000000m2 = 1km2.  new variable in mg CO2 d-1
  co2TMDLnew.lk.d.upr = co2TMDLnew.upr * 1e6 * AREASQKM, # 1000000m2 = 1km2.  new variable in mg CO2 d-1 
  
  # N2O
  # 2010: upscale to per lake per day emissions
  n2o2010.lk.d = n2o2010 * 1e6 * AREASQKM, # 1000000m2 = 1km2.  mg N2O d-1
  n2o2010.lk.d.lwr = n2o2010.lwr * 1e6 * AREASQKM, # 1000000m2 = 1km2.  mg N2O d-1
  n2o2010.lk.d.upr = n2o2010.upr * 1e6 * AREASQKM, # 1000000m2 = 1km2.  mg N2O d-1
  
  # TMDLNew: upscale to per lake per day emisions
  n2oTMDLnew.lk.d = n2oTMDLnew * 1e6 * AREASQKM, # 1000000m2 = 1km2.  new variable in mg N2O d-1
  n2oTMDLnew.lk.d.lwr = n2oTMDLnew.lwr * 1e6 * AREASQKM, # 1000000m2 = 1km2.  new variable in mg N2O d-1
  n2oTMDLnew.lk.d.upr = n2oTMDLnew.upr * 1e6 * AREASQKM) # 1000000m2 = 1km2.  new variable in mg N2O d-1


dat[1:5, ] %>% dplyr::select(WB_ID, matches("n2o.*lk.d")) %>%
  kbl(caption = "Mean, lower 2.5 percentile, and upper 97.5 percentile daily N2O emission (mg N2O day-1) for five waterbodies under the '2010' and 'TMDLnew' scenarios.") %>%
  kable_classic()

dat[1:5, ] %>% dplyr::select(WB_ID, matches("co2.*lk.d")) %>%
  kbl(caption = "Mean, lower 2.5 percentile, and upper 97.5 percentile daily CO2 emission (mg CO2 day-1) for five waterbodies under the '2010' and 'TMDLnew' scenarios.") %>%
  kable_classic()

dat[1:5, ] %>% dplyr::select(WB_ID, matches("ch4.*lk.d")) %>%
  kbl(caption = "Mean, lower 2.5 percentile, and upper 97.5 percentile daily CH4 emission (mg CH4 day-1) for five waterbodies under the '2010' and 'TMDLnew' scenarios.") %>%
  kable_classic()
```

#### Upscale daily emissions to annual emissions (mg GHG year^-1^)
The models used to predict areal GHG emission rates (mg GHG m^-2^ day^-1^) are based on published measurements, most of which were made during the warm summer months when emission rates are expected to be greatest.  We therefore assume the predicted areal emission rates are constant during the open-water season.  During periods of ice cover (see above) areal emission rates are zero.  

```{r}
## get number of summer and winter days
warm.days = as.numeric(mdy('11.01.2020') - mdy('04.01.2020')) # emissions during 7 warm months (April 1 - Nov. 1)
cold.days = as.numeric(mdy('03.31.2021') - mdy('11.01.2020')) # 5 months of open-water winter rates

##  Winter rate
# Waldo et al In Review.  Mean rate from Nov.1 - April 1 = 10.56 mg CH4 m-2 d-1
ch4.winter <- 10.56 # mg CH4 m-2 d-1

dat.yr <- dat %>%
  dplyr::select(WB_ID, day_of_ice_filled, AREASQKM, contains("lk.d")) %>%
  # calculate CH4 
  mutate(across(contains("ch4"), function(x) {
    (x * warm.days) + # emissions during 7 warm months (April 1 - Nov. 1)
      ((ch4.winter * 1e6 * AREASQKM) * # 1000000m2 = 1km2.  mg CH4 d-1
         (cold.days-day_of_ice_filled))} # 5 months of open-water winter rates, discounted by days of ice)
  )
  ) %>%
  # calculate N2O and CO2.  No winter rate adjustment needed
  mutate(across(contains(c("co2", "n2o")), function(x) x * (365 - .$day_of_ice_filled))) %>% 
  rename_at(vars(-WB_ID, -day_of_ice_filled, -AREASQKM), function(x) gsub(".d", ".yr", x)) %>%
  dplyr::select(-AREASQKM)
```

#### Sum annual emissions across all waterbodies.
We can now sum the total annual emissions (metric tons of GHG) across all waterbodies and both scenarios.
```{r}
dat.sum <- dat.yr %>% 
  dplyr::select(contains("lk.yr")) %>%
  summarize_all(sum, na.rm = TRUE) %>%
  mutate_all(~. / (1e3*1e3*1e3)) %>% # mg->g, g->kg, kg->Mg. 1 MG = 1 metric ton = 1000kg)
  rename_all(function(x) paste0(x, ".sum")) %>%
  rename_all(function(x) gsub("lk.", "", x))

dat.sum %>% dplyr::select(matches("n2o.*.yr")) %>%
  mutate_all(round, digits = 0) %>%
  kbl(caption = "Mean, lower 2.5 percentile, and upper 97.5 percentile aggregate annual N2O emission (metric tons N2O day-1) for all waterbodies under the '2010' and 'TMDLnew' scenarios.") %>%
  kable_classic()

dat.sum %>% dplyr::select(matches("co2.*.yr")) %>%
  mutate_all(round, digits = 0) %>%
  kbl(caption = "Mean, lower 2.5 percentile, and upper 97.5 percentile aggregate annual CO2 emission (metric tons CO2 day-1) for all waterbodies under the '2010' and 'TMDLnew' scenarios.") %>%
  kable_classic()

dat.sum %>% dplyr::select(matches("ch4.*.yr")) %>%
  mutate_all(round, digits = 0) %>%
  kbl(caption = "Mean, lower 2.5 percentile, and upper 97.5 percentile aggregate annual CH4 emission (metric tons CH4 day-1) for all waterbodies under the '2010' and 'TMDLnew' scenarios.") %>%
  kable_classic()
```

#### Calculate incremental change

The 'incremental change' is defined as the difference in emissions between the '2010' and 'TMDLnew' scenarios.  The mean incremental change is simply calculated as the difference between the model predicted 'mean' values.  The upper 97.5 percentile of the incremental change can be calculated as the difference between the 2010 97.5 percentile and the TMDLnew 97.5 percentile.  The lower 2.5 percentile can be calculated as the difference between the 2010 and TMDLnew lower 2.5 percentile.
<!-- This calculation leads to very wide confidence intervals, including negative values for N~2~O and CO~2~.  This is probably not the best way to estimate uncertainty; however, the 'mean' estimates should be pretty good. -->
```{r}
dat.sum %<>%
  # incremental change (metric tons yr-1)
  mutate(ch4incr.yr = ch42010.yr.sum - ch4TMDLnew.yr.sum, 
         ch4incr.yr.upr = ch42010.yr.upr.sum - ch4TMDLnew.yr.upr.sum, 
         ch4incr.yr.lwr = ch42010.yr.lwr.sum - ch4TMDLnew.yr.lwr.sum,
         
         # CO2
         co2incr.yr = co22010.yr.sum - co2TMDLnew.yr.sum, 
         co2incr.yr.upr = co22010.yr.upr.sum - co2TMDLnew.yr.upr.sum, 
         co2incr.yr.lwr = co22010.yr.lwr.sum - co2TMDLnew.yr.lwr.sum,
         
         # N2O
         n2oincr.yr = n2o2010.yr.sum - n2oTMDLnew.yr.sum, 
         n2oincr.yr.upr = n2o2010.yr.upr.sum - n2oTMDLnew.yr.upr.sum, 
         n2oincr.yr.lwr = n2o2010.yr.lwr.sum - n2oTMDLnew.yr.lwr.sum) 


dat.sum %>% 
  dplyr::select(ch4incr.yr, ch4incr.yr.upr, ch4incr.yr.lwr, co2incr.yr, co2incr.yr.upr, 
                co2incr.yr.lwr, n2oincr.yr, n2oincr.yr.upr, n2oincr.yr.lwr) %>%
  mutate_at(vars(!contains("n2o", ignore.case = TRUE)), function(x) round(x, 0)) %>%
  mutate_at(vars(contains("n2o", ignore.case = TRUE)), function(x) round(x, 1))  %>%
  kbl(col.names = rep(c("mean", "upper 97.5", "lower 2.5"), 3),
      caption = "Incremental GHG (metric tons) calculated from model prediction error") %>%
  add_header_above(c("incremental CH4" = 3, "incremental CO2" = 3, "incremental N2O" = 3)) %>%
  kable_classic()
```

### BOOTSTRAP APPROACH: Incremental change and uncertainty with bootstrapping

An alternative approach to estimating uncertainty is to bootstrap a sample from the `r dat %>% nrow()` waterbodies in the data.  This approach assumes the statistical predictions are correct, then simulates sampling error by bootstrapping across the sample.  As shown below, this generates much narrower confidence intervals than the approach utilizing the statistical prediction error.  This probably isn't the appropriate approach because we have a census of lake (e.g. perfect knowledge of the population) rather than a sample.
```{r}
# CALCULATE GHG EMISSIONS, AND INCREMENTAL CHANGES FOR GHG, CHLA, AND P-------------------

ghg <- list() # empty list to hold results
# time.i <- print(Sys.time())
for(i in 1:1e4) { # 4 minutes
  #print(i) # print status update
  tmpData <- dat.yr[sample(1:nrow(dat.yr), replace = TRUE), ] # bootstrap piece: sample with replacement
  ghg[[i]] <- tmpData %>% # assign object to element i of list
    dplyr::select("WB_ID", !contains("yr.")) # exclude the upper and lower confidence estimates
}
# time.i; print(Sys.time())

# simulated incremental GHG
simIncrGhg <- lapply(ghg, function(x) {
  # sum incremental difference across all lakes
  x %>% summarise(incrementalCh4 = (sum(ch42010.lk.yr, na.rm = TRUE) - sum(ch4TMDLnew.lk.yr, na.rm = TRUE)),
                  incrementalCo2 = (sum(co22010.lk.yr, na.rm = TRUE) - sum(co2TMDLnew.lk.yr, na.rm = TRUE)),
                  incrementalN2o = (sum(n2o2010.lk.yr, na.rm = TRUE) - sum(n2oTMDLnew.lk.yr, na.rm = TRUE))) %>%
    mutate_all(function(x) x / (1e3*1e3*1e3)) # mg->g, g->kg, kg->Mg. 1 MG = 1 metric ton = 1000kg)
}) %>%
  do.call("rbind", .) %>% # collapse to tibble
  summarise(incrCh4 = mean(incrementalCh4), # mean CH4 increment across all lakes 
            incrCh4upr = quantile(incrementalCh4, 0.975), # upper 95% increment across all lakes
            incrCh4lwr = quantile(incrementalCh4, 0.025), # lower 5% increment across all lakes
            #CO2
            incrCo2 = mean(incrementalCo2), # mean CO2 increment across all lakes 
            incrCo2upr = quantile(incrementalCo2, 0.975), # upper 95% increment across all lakes
            incrCo2lwr = quantile(incrementalCo2, 0.025), # lower 5% increment across all lakes
            #N2O
            incrN2o = mean(incrementalN2o), # mean N2o increment across all lakes 
            incrN2oupr = quantile(incrementalN2o, 0.975), # upper 95% increment across all lakes
            incrN2olwr = quantile(incrementalN2o, 0.025)) # lower 5% increment across all lakes

simIncrGhg %>%
  mutate_at(vars(!contains("n2o", ignore.case = TRUE)), function(x) round(x, 0)) %>%
  mutate_at(vars(contains("n2o", ignore.case = TRUE)), function(x) round(x, 1)) %>%
  kbl(col.names = rep(c("mean", "upper 97.5", "lower 2.5"), 3),
      caption = "Incremental GHG (metric tons) calculated from bootstrapping.") %>%
  add_header_above(c("incremental CH4" = 3, "incremental CO2" = 3, "incremental N2O" = 3)) %>%
  kable_classic()
```

### KRINSKY AND ROBB APPROACH: Incremental change and uncertainty in model predictions using simulation (Krinsky and Robb, 1986)

An alternative approach to estimating uncertainty is to exploit the uncertainty in the model by randomly sampling from the distribution of the model coefficients using their covariance matrix to accommodate correlation within draws. We iterate this with 10,000 random draws.

<!-- Krinsky, I and A. L. Robb. 1986. “On Approximating the Statistical Properties of Elasticities.” Review of -->
<!-- Economic and Statistics 68: 715-719. -->
#### CH4
```{r results='hide', message=FALSE, warning=FALSE}
## build data for simulation
datKR =
  inner_join(st_drop_geometry(dat.sf), 
             st_drop_geometry(iceCover))

## Add climate zone and type (pond vs reservoir) to lake area and days of ice cover
## climate zone and type file created in get_ipcc_climate_zones.r
lakes =
  left_join(
    datKR %>% 
      dplyr::select(WB_ID, AREASQKM, day_of_ice_filled),
    read_csv('store/climate_zones_for_ches_waterbodies.csv') %>% 
      mutate(WB_ID = as.character(WB_ID)),
    by = 'WB_ID'
  )


## get number of summer and winter days
warm.days = as.numeric(mdy('11.01.2020') - mdy('04.01.2020')) # emissions during 7 warm months (April 1 - Nov. 1)
cold.days = as.numeric(mdy('03.31.2021') - mdy('11.01.2020')) # 5 months of open-water winter rates



#####################################
################################  CH4
#####################################

## 2010 Data
dat_2010 <-  datKR %>%
  dplyr::select(Chla2010) %>%
  mutate('(Intercept)'=1, # match names in model
         Chla2010 = log10(Chla2010 * 1e3)) %>% # log needed for model input: mg/L chl to ug/L
  rename('log10(Chlorophyll.a..ug.L.)' = Chla2010) %>% # match names in model
  relocate('(Intercept)','log10(Chlorophyll.a..ug.L.)') %>%
  as.matrix()

## TMDL Data
dat_tmdl <-  datKR %>%
  dplyr::select(ChlaTMDLnew) %>%
  mutate('(Intercept)'=1,
         ChlaTMDLnew = log10(ChlaTMDLnew * 1e3)) %>% # mg/L chl to ug/L
  rename('log10(Chlorophyll.a..ug.L.)'=ChlaTMDLnew) %>%
  relocate('(Intercept)','log10(Chlorophyll.a..ug.L.)') %>%
  as.matrix()

####  PREDICTIONS

## empty canvas for storing climate zone specific emissions factors
emissions.by.type.ch4 = tibble()

## set seed for replication
set.seed(42)

## number of simulations
#N = 10
N = 1e4 # laptop: 9 minutes with pbreplicate, 2 minutes with future_replicate
        # VM: 86 seconds with future_replicate

plan("multisession") # parallel processing with future_replicate.

tic()
ch4 <- future_replicate(N, { ## future_replicate used parallel processing
  
  ## Distribution of coefficients 
  coefs = MASS::mvrnorm(1, mu = coef(mod.ch4), Sigma = vcov(mod.ch4))
  
  ## Predictions based on model uncertainty
  preds_2010_lakes <- cbind(lakes,
                            # %*% matrix multiplication
                            dat_2010 %*% coefs) # this produces emission rate as log10(CH4-C + offset)
  preds_tmdl_lakes <- cbind(lakes,
                            dat_tmdl %*% coefs)
  
  preds_2010_lakes %<>% mutate(preds_2010_lakes = pCh4(preds_2010_lakes$`dat_2010 %*% coefs`)) # transform according to functions above -> mg CH4 m-2 day-1
  preds_tmdl_lakes %<>% mutate(preds_tmdl_lakes = pCh4(preds_tmdl_lakes$`dat_tmdl %*% coefs`)) # transform according to functions above -> mg CH4 m-2 day-1
  
  ##  Winter rate
  # Waldo et al 2021.  Mean rate from Nov.1 - April 1 = 10.56 +/-11.52
  # this generates a winter emission rate for each lake based on the mean and sd
  # reported in Waldo et al.  Each lake will have a different winter rate, but 
  # the same rate will be used for 2010 and tmdl scenarios
  
  # set.seed(42)
  # ch4.winter <- rnorm(n = nrow(lakes), mean = 10.56, sd = 11.52) # mg CH4 m-2 d-1
  ## we want a truncated normal such that winter rates don't extend beyond the tails of the summer emission rates
  ## JB:  I concur.  Large negative values during the winter aren't realistic.
  # set.seed(42)
  ch4.winter.truncated <- rtruncnorm(n = nrow(lakes), a = 0, b = 4e3, mean = 10.56, sd = 11.52)
  
  ## plot histogram comparing normal to truncated normal
  # b <- min(c(ch4.winter, ch4.winter.truncated)) - 0.001 # Set the minimum for the breakpoints
  # e <- max(c(ch4.winter, ch4.winter.truncated)) + 0.5 # Set the maximum for the breakpoints
  # ax <- pretty(b:e, n = 20) # Make a neat vector for the breakpoints
  # c1 <- rgb(173,216,230,max = 255, alpha = 80, names = "lt.blue")
  # c2 <- rgb(255,192,203, max = 255, alpha = 80, names = "lt.pink")
  # hgA <- hist(ch4.winter, breaks = ax, plot = FALSE) # Save first histogram data
  # hgB <- hist(ch4.winter.truncated, breaks = ax, plot = FALSE) # Save 2nd histogram data
  # plot(hgA, col = c1) # Plot 1st histogram using a transparent color
  # plot(hgB, col = c2, add = TRUE)
  
  ## discount winter ch4 emissions for the mass subject to methanotrophy during ice out.
  ## literature reports that 1 - 50% of methane that accumulates under ice is subject to methanotrophy
  ## during ice out.  See conversion_of_CH4_to_CO2.html
  ch4.prop.methantrophy <- runif(n = nrow(lakes), min = 0.01, max = 0.6) # proportion of ch4 that is subject to methanotrophy
  
  ## methanotrophy: ch4 oxidized to co2, as opposed to being incorporated into microbial biomass
  ## See conversion_of_CH4_to_CO2.html
  ch4.to.co2 <- runif(n = nrow(lakes), min = 0.2, max = 0.95) # proportion of ch4 that oxidizes to co2 
  
  #################################
  #################################
  ## CH4 production rates during the winter are based on winter-rates measured in Waldo et al, but Waldo et al.
  ## does not relate these rates to nutrients.  We want to model a TMDL affect of winter rates.  Since we don't have
  ## a model to predict winter rates as a function of nutrients/chl, lets assume that the TMDL will change winter rates
  ## by the same proportion that summer rates are changed.  This is calculated on a per-lake basis.
  tmdl.winter = preds_tmdl_lakes$preds_tmdl_lakes / preds_2010_lakes$preds_2010_lakes
  
  preds_2010_lakes %<>% 
    mutate(preds_2010_lakes = # calculated in units of mg CH4 per year
             # first half of summation is mg CH4 produced during open-water conditions (cold + warm days)
             ((((preds_2010_lakes * warm.days) + (ch4.winter.truncated * (cold.days - day_of_ice_filled))) ) +   
                # second half of summation is mg CH4 produced under ice that remains after methanotrophy
                (ch4.winter.truncated * day_of_ice_filled * (1-ch4.prop.methantrophy))) * 
             1e6 * AREASQKM, # 1,000,000 m2 = 1 km2
           winter_ch4 = 
             # first half of summation is mg CH4 produced during open-water cold days
             ((ch4.winter.truncated * (cold.days - day_of_ice_filled)) +
             # second half of summation is mg CH4 produced under ice that remains after methanotrophy
                (ch4.winter.truncated * day_of_ice_filled * (1-ch4.prop.methantrophy))) *
             1e6 * AREASQKM, # 1000000 m2 = 1 km2
           warm_ch4 = 
             # now calculate how much CH4 was produced during warm days
             preds_2010_lakes - winter_ch4
           )
             
  
  preds_tmdl_lakes %<>% 
    mutate(preds_tmdl_lakes = # calculated in units of mg CH4 per year
             ((preds_tmdl_lakes * warm.days) + # CH4 produced in warm days under TMDL (mg CH4/m2)
                # tmdl.winter term modifies the winter rate to reflect TMDL on winter production
                ((ch4.winter.truncated * tmdl.winter) * (cold.days - day_of_ice_filled)) + # cold days CH4 under TMDL (mg CH4/m2)
                ((ch4.winter.truncated * tmdl.winter) * day_of_ice_filled * (1 - ch4.prop.methantrophy))) * # add ch4 that remains after methanotrophy (mg CH4/m2)
             1e6 * AREASQKM, # 1000000 m2 = 1 km2
           winter_ch4 = 
             # first half of summation is mg CH4 produced during open-water cold days
             (((ch4.winter.truncated * tmdl.winter) * (cold.days - day_of_ice_filled)) +
             # second half of summation is mg CH4 produced under ice that remains after methanotrophy
             ((ch4.winter.truncated * tmdl.winter) * day_of_ice_filled * (1-ch4.prop.methantrophy))) *
              1e6 * AREASQKM, # 1000000 m2 = 1 km2
           warm_ch4 = 
             # now calculate how much CH4 was produced during warm days
             preds_tmdl_lakes - winter_ch4
    )
  
  preds_2010_lakes %<>% 
    mutate(across(c(preds_2010_lakes, winter_ch4, warm_ch4), ~ .x / (1e3*1e3*1e3))) # mg->g, g->kg, kg->Mg. 1 MG = 1 metric ton = 1000kg.  
  preds_tmdl_lakes %<>% 
    mutate(across(c(preds_tmdl_lakes, winter_ch4, warm_ch4), ~ .x / (1e3*1e3*1e3))) # mg->g, g->kg, kg->Mg. 1 MG = 1 metric ton = 1000kg
  
  # preds_2010_lakes %<>% mutate(preds_2010_lakes = ((preds_2010_lakes * (7*30)) + # emissions during 7 warm months (April 1 - Nov. 1)
  #                                                    (ch4.winter * ((5*30)-day_of_ice_filled))) * # 5 months of open-water winter rates, discounted by days of ice
  #                                1000000 * AREASQKM, na.rm=TRUE) # 1000000m2 = 1km2.  new variable in mg CH4 d-1
  # 
  # 
  # preds_tmdl_lakes %<>% mutate(preds_tmdl_lakes = ((preds_tmdl_lakes * (7*30)) + # emissions during 7 warm months (April 1 - Nov. 1)
  #                                                    (ch4.winter * ((5*30) - day_of_ice_filled))) * # 5 months of open-water winter rates, discounted by days of ice
  #                                1000000 * AREASQKM, na.rm=TRUE) # 1000000m2 = 1km2.  new variable in mg CH4 d-1
  # 
  # 
  # preds_2010_lakes %<>% mutate(preds_2010_lakes = preds_2010_lakes / (1e3*1e3*1e3), na.rm=TRUE) # mg->g, g->kg, kg->Mg. 1 MG = 1 metric ton = 1000kg.  
  # preds_tmdl_lakes %<>% mutate(preds_tmdl_lakes = preds_tmdl_lakes / (1e3*1e3*1e3), na.rm=TRUE) # mg->g, g->kg, kg->Mg. 1 MG = 1 metric ton = 1000kg
  
  # ## Convert and take difference in predictions and sum across all lakes
  # sum(preds_2010_lakes$preds_2010_lakes - preds_tmdl_lakes$preds_tmdl_lakes, na.rm=TRUE)
  
  ## export climate zone specific emissions to extrapolate to mississippi river basin
  emissions.by.type.ch4 = 
    bind_rows(
      emissions.by.type.ch4,
      left_join(
        left_join(
          aggregate((preds_2010_lakes$preds_2010_lakes - preds_tmdl_lakes$preds_tmdl_lakes)/preds_2010_lakes$preds_2010_lakes, 
                    list(preds_2010_lakes$type, 
                         preds_2010_lakes$climate.zone), 
                    FUN = mean) %>% 
            rename(type         = Group.1,
                   climate.zone = Group.2, 
                   incr.ch4.mean.pct = x),
          aggregate((ch4.winter.truncated * preds_2010_lakes$day_of_ice_filled * 1e6 * preds_2010_lakes$AREASQKM * ch4.prop.methantrophy * (ch4.to.co2) * 44/16)  / (1e3*1e3*1e3), 
                    list(preds_2010_lakes$type,
                         preds_2010_lakes$climate.zone),
                    FUN = mean) %>% 
            rename(type         = Group.1,
                   climate.zone = Group.2,
                   methanotrophy.co2.2010.mean = x), 
          by = c('type', 'climate.zone')
        ),
        aggregate((ch4.winter.truncated * tmdl.winter * preds_2010_lakes$day_of_ice_filled * 1e6 * preds_2010_lakes$AREASQKM * ch4.prop.methantrophy * (ch4.to.co2) * 44/16)  / (1e3*1e3*1e3), 
                  list(preds_2010_lakes$type,
                       preds_2010_lakes$climate.zone),
                  FUN = mean) %>% 
          rename(type         = Group.1,
                 climate.zone = Group.2, 
                 methanotrophy.co2.tmdl.mean = x), 
        by = c('type', 'climate.zone')
      ) %>% 
        mutate(incr.methanotrophy.co2.mean = methanotrophy.co2.2010.mean - methanotrophy.co2.tmdl.mean) 
    ) %>% 
    group_by(type, climate.zone) %>% 
    summarize(incr.ch4.mean.pct           = mean(incr.ch4.mean.pct, na.rm = T),
              incr.methanotrophy.co2.mean = mean(incr.methanotrophy.co2.mean, na.rm = T),
              .groups = 'drop')
  
  ## This list will be populated with each iteration of the simulation and will be
  ## assigned to the object 'ch4'
  ## Convert and take difference in predictions and sum across all lakes and store CO2 from methanotrophy
  ## also catch lake-specific results from each iteration
  list(
    # element 1:  CH4 incremental change, summed across all lakes
    incr.ch4 = sum(preds_2010_lakes$preds_2010_lakes - preds_tmdl_lakes$preds_tmdl_lakes, na.rm=TRUE),
    
    # element 2:  CO2 produced via methanotrophy under ice in 2010
    methanotrophy.co2.2010 = (ch4.winter.truncated * preds_2010_lakes$day_of_ice_filled * 1e6 * preds_2010_lakes$AREASQKM * ch4.prop.methantrophy * (ch4.to.co2) * (44/16)) / (1e3*1e3*1e3), # mg->g, g->kg, kg->Mg. 1 MG = 1 metric ton = 1000kg
    
    # element 3:  CO2 produced via methanotrophy under ice in tmdl scenario
    methanotrophy.co2.tmdl =   (ch4.winter.truncated * tmdl.winter * preds_2010_lakes$day_of_ice_filled * 1e6 * preds_2010_lakes$AREASQKM * ch4.prop.methantrophy * (ch4.to.co2) * (44/16)) / (1e3*1e3*1e3), # mg->g, g->kg, kg->Mg. 1 MG = 1 metric ton = 1000kg
    
    # element 4:  emissions by IPCC categories for MRB extrapolation
    emissions.by.type.ch4,
    
    # element 5: lake specific results for 2010 scenario
    preds_2010_lakes %<>% rename(preds_2010_lakes_Mg = preds_2010_lakes),
    
    # element 6:  lake specific results for tmdl scenario
    preds_tmdl_lakes %<>% rename(preds_tmdl_lakes_Mg = preds_tmdl_lakes),
  
    # element 7: winter and warm weather emissions
    seasonal_ch4 = bind_cols(preds_tmdl_lakes %>% 
                               rename(winter_ch4_tmdl = winter_ch4, warm_ch4_tmdl = warm_ch4) %>%
                               select(winter_ch4_tmdl, warm_ch4_tmdl),
                             preds_2010_lakes %>%
                               rename(winter_ch4_2010 = winter_ch4, warm_ch4_2010 = warm_ch4) %>%
                               select(winter_ch4_2010, warm_ch4_2010))
  ) # close list
}) # close future_replicate
toc()
plan("sequential") # turn off parallel processing


## EXTRACT AND NAME RELEVANT VECTORS------------------
diff_ch4 = unlist(ch4[1,]) # 1 MG = 1 metric ton = 1000kg

# co2 from ch4 for each lake and simulation in 2010.  10000 simulations of ~4200 lakes
co2.from.ch4.2010 = data.frame(co2.from.ch4.Mg = unlist(ch4[2,]), # 1 MG = 1 metric ton = 1000kg
                               WB_ID = ch4[[5,1]]$WB_ID, # for merging
                               simulation = rep(1:N, each = nrow(ch4[[5]]))) # called in co2 calcs below

# co2 from ch4 for each lake and simulation in tmdl.  10000 simulations of ~4200 lakes
co2.from.ch4.tmdl = data.frame(co2.from.ch4.Mg = unlist(ch4[3,]), # 1 MG = 1 metric ton = 1000kg
                               WB_ID = ch4[[6,1]]$WB_ID, # for merging
                               simulation = rep(1:N, each = nrow(ch4[[6]]))) # called in co2 calcs below

emissions.by.type.ch4 = ch4[4, N] ## keep just the final mean... clearly a cleaner way but this works

# CH4 emissions by season for each scenario
seasonal_ch4 <- map_df(ch4["seasonal_ch4",], \(x) x %>%
   summarize(across(contains("winter"), sum),
             across(contains("warm"), sum))
  ) 

## CALCULATE AVERAGE AREAL EMISSION RATES, BY LAKE, ACROSS ALL ITERATIONS OF SIMULATION---------
# Mean lake specific results for plotting.
tic() # 1.5 min with map, much faster than future_map.  Also future_map maxes RAM, even on VM.  
ch4.by.lake <- list(ch4[6,], # tmdl scenario.  
            ch4[5,])  %>% # 2010 scenario
  flatten() %>% # code above nests two lists of 10,000 elements in main list.  Flatten creates a list of 20,000 elements
  #.[c(1:10, 10001:10011)] %>% # first 10 tmdl and 2010 for development
  purrr::map(., function(.x) {
    .x %>% 
      dplyr::select(WB_ID, AREASQKM, contains("preds")) %>% # pull out needed columns to reduce memory demands
      # create new column specifying scenario.
      mutate(scenario = case_when(any(str_detect(names(.), "tmdl")) ~ "tmdl",
                                  any(str_detect(names(.), "2010")) ~ "2010",
                                  TRUE ~ "FLY YOU FOOLS!")) %>%
      # remove _2010 and _tmdl from preds column name.  preds_lakes_Mg = preds_2010_lakes_Mg
      set_colnames(c("WB_ID", "AREASQKM", "preds_lakes_Mg", "scenario")) %>%
       # calculate areal emission rate for each lake: g CH4 m-2 year-1.  
      mutate(preds_lakes_g_m2_y = (preds_lakes_Mg / AREASQKM) * ((1e3*1e3)/1e6)) #(Mg->kg, kg->g)/(km2->m2)
  }) %>%
  # collapse into single data frame.  data.table implementation of rbind is fast
  data.table::rbindlist(.) %>% # full_join and bind_cols take forever.  3 minutes with rbindlist
  group_by(WB_ID, scenario) %>% # each lake is repeated 10,000 times in DF.  group by lake..
  summarize(across(everything(), mean)) %>% # then calculate average emissions, per lake, across all 10,000 iterations
  ungroup() %>%
  pivot_wider(names_from = scenario, values_from = contains("preds")) %>% # cast to wide
  rename_with(~paste0(., "_ch4"), contains("preds"))
toc() 

## check values
summary(diff_ch4)
summary(co2.from.ch4.2010)
summary(co2.from.ch4.tmdl)
emissions.by.type.ch4
head(ch4.by.lake)
head(seasonal_ch4)

## clean house
#rm(ch4)
#gc()
```
#### CO2
```{r results='hide', message=FALSE, warning=FALSE}
#####################################
################################  CO2
#####################################

#### PARTS 
## 2010 Data
dat_2010 =
  datKR %>%
  dplyr::select(Pvv2010,AREASQKM) %>%
  mutate('(Intercept)'=1,
         AREASQKM = log10(AREASQKM),
         TP..ug.L. = log10(Pvv2010 * 1e3), #mg/L -> ug/L
         'log10(Surface.Area..km2.):log10(TP..ug.L.)' = AREASQKM*TP..ug.L.) %>%
  rename('log10(Surface.Area..km2.)'=AREASQKM,'log10(TP..ug.L.)'=TP..ug.L.) %>%
  relocate('(Intercept)','log10(Surface.Area..km2.)','log10(TP..ug.L.)','log10(Surface.Area..km2.):log10(TP..ug.L.)') %>%
  dplyr::select(-Pvv2010) %>%
  as.matrix()

## TMDL Data
dat_tmdl =
  datKR %>%
  dplyr::select(PvvTMDLnew,AREASQKM) %>%
  mutate('(Intercept)'=1,
         AREASQKM = log10(AREASQKM),
         TP..ug.L. = log10(PvvTMDLnew * 1e3),
         'log10(Surface.Area..km2.):log10(TP..ug.L.)' = AREASQKM*TP..ug.L.) %>%
  rename('log10(Surface.Area..km2.)'=AREASQKM,'log10(TP..ug.L.)'=TP..ug.L.) %>%
  relocate('(Intercept)','log10(Surface.Area..km2.)','log10(TP..ug.L.)','log10(Surface.Area..km2.):log10(TP..ug.L.)') %>%
  dplyr::select(-PvvTMDLnew) %>%
  as.matrix()

####  PREDICTIONS
## empty canvas for storing climate zone specific emissions factors
emissions.by.type.co2 = tibble()

## empty object to collect results
diff_co2 <- NULL 
co2 <- list() # for list of lake-specific co2 emission rates

## number of simulations
N = 1e4
#N = 10
tic() # 2 hours
## using for loop because i need to reference index i.
for (i in 1:N) {
  
  ## print where you are in the loop
  print(i)
  
  ## distribution of coefficients 
  coefs = MASS::mvrnorm(1, mu = coef(mod.co2), Sigma = vcov(mod.co2))
  
  ## predictions based on model uncertainty.  log10(CO2-C + offset) [mg co2-c m-2 d-1]
  preds_2010_lakes <- cbind(lakes,
                            dat_2010 %*% coefs)
  preds_tmdl_lakes <- cbind(lakes,
                            dat_tmdl %*% coefs)
  
  ##  Winter rate
  # Data are mixed for CO2.  Jones et al 2016 report uptake during summer and outgassing
  # during winter for midwestern lakes.  Knoll et al reports sustained outgassing for an Ohio
  # Lake.  I think it best to assume that production rates are equal to predicted emissions
  # rates throughout the year.  CO2 produced during periods of ice cover will be emitted to 
  # atmosphere during ice out.
  
  #################################
  #################################
  preds_2010_lakes %<>% 
    mutate(preds_2010_lakes = pCo2(preds_2010_lakes$`dat_2010 %*% coefs`)) # unit conversion: mg CO2 m-2 day-1
  
  preds_tmdl_lakes %<>% 
    mutate(preds_tmdl_lakes = pCo2(preds_tmdl_lakes$`dat_tmdl %*% coefs`)) # unit conversion: mg CO2 m-2 day-1
  
  # scale to entire year.  Assume rates apply to warm, cold, and ice cover days.
  preds_2010_lakes %<>% 
    mutate(preds_2010_lakes = (preds_2010_lakes * (365)) * # apply to 365 days
             1e6 * AREASQKM) # 1000000m2 = 1km2.  new variable in mg CO2 year-1
  
  preds_tmdl_lakes %<>% 
    mutate(preds_tmdl_lakes = (preds_tmdl_lakes * (365)) * # apply to 365 days
             1e6 * AREASQKM) # 1000000m2 = 1km2.  new variable in mg CO2 year-1
  
  ## store emissions by type
  emissions.by.type.co2 =
    bind_rows(
      emissions.by.type.co2,
      left_join(
        preds_2010_lakes %>% 
          group_by(type, climate.zone) %>% 
          summarize(preds_2010_lakes = mean(preds_2010_lakes / (1e3*1e3*1e3), na.rm = T), 
                    .groups = 'drop'),
        preds_tmdl_lakes %>% 
          group_by(type, climate.zone) %>% 
          summarize(preds_tmdl_lakes = mean(preds_tmdl_lakes / (1e3*1e3*1e3), na.rm = T), 
                    .groups = 'drop'),
        by = c('type', 'climate.zone')
      ) %>% 
        mutate(incr.co2.mean = (preds_2010_lakes - preds_tmdl_lakes)/preds_2010_lakes) 
    ) %>% 
    group_by(type, climate.zone) %>% 
    summarize(incr.co2.mean.pct = mean(incr.co2.mean, na.rm = T),
              .groups = 'drop') %>% 
    ungroup 
  
  ## Add CO2 produced from methanotrophy
  # 2010 first
  co2.from.ch4.2010.i <- co2.from.ch4.2010 %>%
    filter(simulation == i) %>%
    dplyr::select(co2.from.ch4.Mg) %>% pull() # co2 from ch4 for all lakes and simulations
  
  preds_2010_lakes %<>% 
    mutate(preds_2010_lakes = 
             (preds_2010_lakes / (1e3*1e3*1e3)) + # mg->g,g->kg,kg->Mg.1 MG=1 metric ton =1000kg
             co2.from.ch4.2010.i)
  
  # tmdl next
  co2.from.ch4.tmdl.i <- co2.from.ch4.tmdl %>%
    filter(simulation == i) %>%
    select(co2.from.ch4.Mg) %>% pull() # co2 from ch4 for all lakes and simulations
  
  preds_tmdl_lakes %<>%
    mutate(preds_tmdl_lakes = 
             (preds_tmdl_lakes / (1e3*1e3*1e3)) + # mg->g,g->kg,kg->Mg.1 MG=1 metric ton =1000kg
             co2.from.ch4.tmdl.i) # co2 from ch4 for all lakes/simulations
  
  co2[[i]] <- list(preds_2010_lakes, preds_tmdl_lakes)
  
  ## convert and take difference in predictions and sum across all lakes
  diff_co2[i] <- sum(preds_2010_lakes$preds_2010_lakes - preds_tmdl_lakes$preds_tmdl_lakes, na.rm = T)
  
}
toc()

## inspect results
summary(diff_co2)
emissions.by.type.co2


## CALCULATE AVERAGE AREAL EMISSION RATES, BY LAKE, ACROSS ALL ITERATIONS OF SIMULATION---------
# Mean lake specific results for plotting.
tic() # 3.9 min with map, much faster than future_map.  Also future_map maxes RAM, even on VM.  
co2.by.lake <- co2 %>% # list of 10,000 elements.  each element is a list of 2 (tmdl and 2010)
  flatten() %>% # Flatten creates a list of 20,000 elements
  #.[1:2] %>% # first tmdl and 2010 for development
  purrr::map(., function(.x) {
    .x %>% 
      dplyr::select(WB_ID, AREASQKM, contains("preds")) %>% # pull out needed columns to reduce memory demands
      # create new column specifying scenario.
      mutate(scenario = case_when(any(str_detect(names(.), "tmdl")) ~ "tmdl",
                                  any(str_detect(names(.), "2010")) ~ "2010",
                                  TRUE ~ "FLY YOU FOOLS!")) %>%
      # remove _2010 and _tmdl from preds column name.  preds_lakes_Mg = preds_2010_lakes_Mg
      set_colnames(c("WB_ID", "AREASQKM", "preds_lakes_Mg", "scenario")) %>%
       # calculate areal emission rate for each lake: g CH4 m-2 year-1.  
      mutate(preds_lakes_g_m2_y = (preds_lakes_Mg / AREASQKM) * ((1e3*1e3)/1e6)) #(Mg->kg, kg->g)/(km2->m2)
  }) %>%
  # collapse into single data frame.  data.table implementation of rbind is fast
  data.table::rbindlist(.) %>% # full_join and bind_cols take forever.  3 minutes with rbindlist
  group_by(WB_ID, scenario) %>% # each lake is repeated 10,000 times in DF.  group by lake..
  summarize(across(everything(), mean)) %>% # then calculate average emissions, per lake, across all 10,000 iterations
  ungroup() %>%
  pivot_wider(names_from = scenario, values_from = contains("preds")) %>% # cast to wide
  rename_with(~paste0(., "_co2"), contains("preds"))
toc()

```

#### N2O
```{r results='hide', message=FALSE, warning=FALSE}
#####################################
################################  N20
#####################################

## 2010 Data
dat_2010 <-  datKR %>%
  dplyr::select(Chla2010,AREASQKM) %>%
  mutate('(Intercept)'=1,
         AREASQKM = log10(AREASQKM),
         Chla2010 = log10(Chla2010 * 1e3)) %>% # mg L-1 -> ug L-1
  rename('log10(Surface.Area..km2.)'=AREASQKM,'log10(Chlorophyll.a..ug.L.)'=Chla2010) %>%
  relocate('(Intercept)','log10(Surface.Area..km2.)','log10(Chlorophyll.a..ug.L.)') %>%
  as.matrix()

## TMDL Data
dat_tmdl <-  datKR %>%
  dplyr::select(ChlaTMDLnew,AREASQKM) %>%
  mutate('(Intercept)'=1,
         AREASQKM = log10(AREASQKM),
         ChlaTMDLnew = log10(ChlaTMDLnew * 1e3)) %>% # mg L-1 -> ug L-1
  rename('log10(Surface.Area..km2.)'=AREASQKM,'log10(Chlorophyll.a..ug.L.)'=ChlaTMDLnew) %>%
  relocate('(Intercept)','log10(Surface.Area..km2.)','log10(Chlorophyll.a..ug.L.)') %>%
  as.matrix()


####  PREDICTIONS
## empty canvas for storing climate zone specific emissions factors
emissions.by.type.n2o = tibble()

## number of simulations
N = 1e4
#N=10

## simulation
plan("multisession") # turn on parallel processing
tic() # 1 minute
n2o <- future_replicate(N, {
  
  ## Distribution of coefficients 
  coefs = MASS::mvrnorm(1, mu = coef(mod.n2o), Sigma = vcov(mod.n2o))
  
  ## Predictions based on model uncertainty
  preds_2010_lakes <- cbind(lakes,
                            dat_2010 %*% coefs)
  preds_tmdl_lakes <- cbind(lakes,
                            dat_tmdl %*% coefs)
  
  # Winter rates
  # Few annual data available for N2O.  Kortelainen et al. 2020 reported peak N2O during winter in Finnish lakes,
  # but Beaulieu et al. 2010 reported peak N2O during summer in the Ohio River and negligable N2O during the
  # winter.  I think it best to assume that production rates are equal to predicted emissions
  # rates throughout the year.  N2O produced during periods of ice cover will be emitted to 
  # atmosphere during ice out.  
  
  preds_2010_lakes %<>% 
    mutate(preds_2010_lakes = pN2o(preds_2010_lakes$`dat_2010 %*% coefs`)) # unit conversion: mg N2O m-2 day-1
  preds_tmdl_lakes %<>% 
    mutate(preds_tmdl_lakes = pN2o(preds_tmdl_lakes$`dat_tmdl %*% coefs`)) # unit conversion: mg N2O m-2 day-1
  
  # open water rates: mg N2O y-1
  preds_2010_lakes %<>% 
    mutate(preds_2010_lakes = (preds_2010_lakes * 365) * # scale to year 
             1e6 * AREASQKM) # 1000000m2 = 1km2.  new variable in mg N2O y-1
  preds_tmdl_lakes %<>% 
    mutate(preds_tmdl_lakes = (preds_tmdl_lakes * 365) * # scale to year
             1e6 * AREASQKM) # 1000000m2 = 1km2.  new variable in mg N2O y-1
  
  # unit conversion
  preds_2010_lakes %<>% 
    mutate(preds_2010_lakes = preds_2010_lakes / (1e3*1e3*1e3)) # mg->g, g->kg, kg->Mg. 1 MG = 1 metric ton = 1000kg
  preds_tmdl_lakes %<>% 
    mutate(preds_tmdl_lakes = preds_tmdl_lakes / (1e3*1e3*1e3)) # mg->g, g->kg, kg->Mg. 1 MG = 1 metric ton = 1000kg
  
  ## store emissions by type
  emissions.by.type.n2o =
    bind_rows(
      emissions.by.type.n2o,
      left_join(
        preds_2010_lakes %>% 
          group_by(type, climate.zone) %>% 
          summarize(preds_2010_lakes = mean(preds_2010_lakes / (1e3*1e3*1e3), na.rm = T), 
                    .groups = 'drop'),
        preds_tmdl_lakes %>% 
          group_by(type, climate.zone) %>% 
          summarize(preds_tmdl_lakes = mean(preds_tmdl_lakes / (1e3*1e3*1e3), na.rm = T), 
                    .groups = 'drop'),
        by = c('type', 'climate.zone')
      ) %>% 
        mutate(incr.n2o.mean.pct = (preds_2010_lakes - preds_tmdl_lakes)/preds_2010_lakes) 
    ) %>% 
    group_by(type, climate.zone) %>% 
    summarize(incr.n2o.mean.pct = mean(incr.n2o.mean.pct, na.rm = T),
              .groups = 'drop') %>% 
    ungroup 
  
  ## Convert and take difference in predictions and sum across all lakes
  list(
    # row 1: incremental N2O
    sum(preds_2010_lakes$preds_2010_lakes - preds_tmdl_lakes$preds_tmdl_lakes, na.rm = T),
    
    # row 2:  n2o by IPCC category for MRB extrapolation
    emissions.by.type.n2o,
    
    # row 3: lake specific results for 2010 scenario
    preds_2010_lakes %<>% rename(preds_2010_lakes_Mg = preds_2010_lakes),
    
    # row 4:  lake specific results for tmdl scenario
    preds_tmdl_lakes %<>% rename(preds_tmdl_lakes_Mg = preds_tmdl_lakes)
  )
})
toc()
plan("sequential") # turn off parallel processing

diff_n2o = unlist(n2o[1,])
emissions.by.type.n2o = n2o[2, N]


## CALCULATE AVERAGE AREAL EMISSION RATES, BY LAKE, ACROSS ALL ITERATIONS OF SIMULATION---------
# Mean lake specific results for plotting.
tic() # 3.9 min with map, much faster than future_map.  Also future_map maxes RAM, even on VM.  
n2o.by.lake <- list(n2o[3,], # 2010 scenario.  
            n2o[4,])  %>% # 2010 scenario
  flatten() %>% # code above nests two lists of 10,000 elements in main list.  Flatten creates a list of 20,000 elements
  #.[c(1:10, 10001:10011)] %>% # first 10 tmdl and 2010 for development
  purrr::map(., function(.x) {
    .x %>% 
      dplyr::select(WB_ID, AREASQKM, contains("preds")) %>% # pull out needed columns to reduce memory demands
      # create new column specifying scenario.
      mutate(scenario = case_when(any(str_detect(names(.), "tmdl")) ~ "tmdl",
                                  any(str_detect(names(.), "2010")) ~ "2010",
                                  TRUE ~ "FLY YOU FOOLS!")) %>%
      # remove _2010 and _tmdl from preds column name.  preds_lakes_Mg = preds_2010_lakes_Mg
      set_colnames(c("WB_ID", "AREASQKM", "preds_lakes_Mg", "scenario")) %>%
       # calculate areal emission rate for each lake: g CH4 m-2 year-1.  
      mutate(preds_lakes_g_m2_y = (preds_lakes_Mg / AREASQKM) * ((1e3*1e3)/1e6)) #(Mg->kg, kg->g)/(km2->m2)
  }) %>%
  # collapse into single data frame.  data.table implementation of rbind is fast
  data.table::rbindlist(.) %>% # full_join and bind_cols take forever.  3 minutes with rbindlist
  group_by(WB_ID, scenario) %>% # each lake is repeated 10,000 times in DF.  group by lake..
  summarize(across(everything(), mean)) %>% # then calculate average emissions, per lake, across all 10,000 iterations
  ungroup() %>%
  pivot_wider(names_from = scenario, values_from = contains("preds")) %>% # cast to wide
  rename_with(~paste0(., "_n2o"), contains("preds"))
toc()




## check values
summary(diff_n2o)
emissions.by.type.n2o
head(n2o.by.lake)
```

#### Consolidate lake specific results
```{r}
## combine lake specific simulation results with lake info
# dat.sf is spatial version of chesDat.  See lines 132-145
dat.sf <- inner_join(dat.sf, st_drop_geometry(iceCover)) %>% # merge lake data with ice cover
  list(., ch4.by.lake, co2.by.lake, n2o.by.lake) %>% # list of merged object plus lake specific simulation data
  # Each object has WB_ID and AREASQKM
  reduce(full_join, by = c("WB_ID", "AREASQKM")) # keep all records

# any change in number of observations? - NO, good
list(dat.sf, iceCover, ch4.by.lake, co2.by.lake, n2o.by.lake) %>% 
  purrr::map(., dim) # all have 4222 lakes
dim(dat.sf) # 4222 lakes!
  
```

#### Incremental change table + export for MRB extrapolation
```{r}

## export emissions by climate zone and type
emissions.by.type.ch4[[1]] %>% write_csv('output/emissions_by_lake_characteristics_ch4.csv')
emissions.by.type.co2 %>% write_csv('output/emissions_by_lake_characteristics_co2.csv')
emissions.by.type.n2o[[1]] %>% write_csv('output/emissions_by_lake_characteristics_n2o.csv')

kr_simulations <- data.frame(mean_ch4 = round(mean(diff_ch4), 0),
                             uppr_ch4 = round(quantile(diff_ch4, .95), 0),
                             lowr_ch4 = round(quantile(diff_ch4, .05), 0),
                             mean_co2 = round(mean(diff_co2), 0),
                             uppr_co2 = round(quantile(diff_co2, .95), 0),
                             lowr_co2 = round(quantile(diff_co2, .05), 0),
                             mean_n2o = round(mean(diff_n2o), 1),
                             uppr_n2o = round(quantile(diff_n2o, .95), 1),
                             lowr_n2o = round(quantile(diff_n2o, .05), 1))
rownames(kr_simulations) <- c()

kr_simulations %>%
  kbl(col.names = rep(c("mean", "upper 95", "lower 5"), 3),
      caption = "Incremental GHG (metric tons) calculated from simulation (Krinsky and Robb, 1986)") %>%
  add_header_above(c("incremental CH4" = 3, "incremental CO2" = 3, "incremental N2O" = 3)) %>%
  kable_classic()
```

# Exploratory Figures
## Set up temporary plotting data

```{r eval = FALSE}
# PLOTTING CAN BE DONE WITH ACTUAL LAKE POLYGONS OR BY REPRESENTING EACH LAKE AS A POINT
# dat.sf is polygon object
dim(dat.sf) # 4222
class(dat.sf) # spatial
plot(st_geometry(dat.sf)) #test, looks good

# Now create object for plotting points
dat.pt <- st_centroid(dat.sf)
plot(st_geometry(dat.pt))
```


## Plots of 2010 ice cover, chl, TP, and GHG emission rate: polygon plots
```{r eval = FALSE}
# FIGURE OF INPUTS AND OUTPUTS FOR BASELINE
# Polygon plot--------
# can add line below to ggplot to project to Albers for mapping, but I think looks better
# + coord_sf(crs = st_crs(5070)) # change to albers for plotting
st_crs(states) # 4326 (WGS84)

# ice days figure
p1 <- ggplot() +
  geom_sf(data = wsb) + #
  geom_sf(data = dat.sf, aes(color = day_of_ice_filled)) +
  geom_sf(data = cbb, fill = "blue", size = NA) +
  labs(color = "Ice cover duration (days)") +
  theme(panel.background = element_blank(),
        panel.border = element_rect(color = "black", fill = NA),
        legend.justification = c(0,1))


# chl figure
p2 <- ggplot() +
  geom_sf(data = wsb) + #
  geom_sf(data = dat.sf, aes(color = Chla2010)) +
  geom_sf(data = cbb, fill = "blue", size = NA) +
  labs(color = "ChlA") +
  theme(panel.background = element_blank(),
        panel.border = element_rect(color = "black", fill = NA),
        legend.justification = c(0,1))


# TP figure
p3 <- ggplot() +
  geom_sf(data = wsb) +
  geom_sf(data = dat.sf, aes(color = Pvv2010)) +
  geom_sf(data = cbb, fill = "blue", size = NA) +
  labs(color = "TP (mg/L)") +
  theme(panel.background = element_blank(),
        panel.border = element_rect(color = "black", fill = NA),
        legend.justification = c(0,1))


# CH4 figure
p4 <- ggplot() +
  geom_sf(data = wsb) +
  geom_sf(data = dat.sf, aes(color = preds_lakes_g_m2_y_2010_ch4)) +
  geom_sf(data = cbb, fill = "blue", size = NA) +
  labs(color = "CH4 (g m-2 y-1)") +
  theme(panel.background = element_blank(),
        panel.border = element_rect(color = "black", fill = NA),
        legend.justification = c(0,1))


# CO2 figure
p5 <- ggplot() +
  geom_sf(data = wsb) +
  geom_sf(data = dat.sf, aes(color = preds_lakes_g_m2_y_2010_co2)) +
  geom_sf(data = cbb, fill = "blue", size = NA) +
  labs(color = "CO2 (g m-2 y-1)") +
  theme(panel.background = element_blank(),
        panel.border = element_rect(color = "black", fill = NA),
        legend.justification = c(0,1))


# N2O figure
p6 <- ggplot() +
  geom_sf(data = wsb) +
  geom_sf(data = dat.sf, aes(color = preds_lakes_g_m2_y_2010_n2o)) +
  geom_sf(data = cbb, fill = "blue", size = NA) +
  labs(color = "N2O (g m-2 y-1)") +
  theme(panel.background = element_blank(),
        panel.border = element_rect(color = "black", fill = NA),
        legend.justification = c(0,1))


cowplot::plot_grid(p1, p2, p3, p4, p5, p6, ncol = 3, nrow = 2, align = "hv")

ggsave(file = "output/figures/arealRatesNutrientsPoly.tiff", width = 15, height = 8, units = "in")
```


## Plots of ice cover, chl, TP, and GHG emission rate: point plots
```{r eval = FALSE}
# Point plot-------------------
# Extreme values causing wide range of color ramp which hides spatial pattern
# Play with removing extremes
# these extreme values come from the same site.  Makes sense since chl is calculated from P.
# consider chl > 0.2 as extreme value.
ggplot(dat.pt, aes(Chla2010, Pvv2010)) + geom_point() + scale_y_log10() + scale_x_log10()

# where are these extreme values located?
ggplot() +
  geom_sf(data = wsb) +
  geom_sf(data = filter(dat.pt, Chla2010 > 0.2))


# ice days figure
p1 <- ggplot() +
  geom_sf(data = wsb) +
  geom_sf(data = dat.pt, aes(color = day_of_ice_filled,
                             size = AREASQKM)) +
  geom_sf(data = cbb, fill = "blue", size = NA) +
  labs(color = "Ice cover duration (days)", size = "Lake size (km2)") +
  theme(panel.background = element_blank(),
        panel.border = element_rect(color = "black", fill = NA),
        legend.justification = c(0,1))


# chl figure
# better without extreme values
p2 <- ggplot() +
  geom_sf(data = wsb) +
  geom_sf(data = filter(dat.pt, Chla2010 < 0.2),
          aes(color = Chla2010)) + #, size = AREASQKM))
  geom_sf(data = cbb, fill = "blue", size = NA) +
  labs(color = "ChlA") +
  theme(panel.background = element_blank(),
        panel.border = element_rect(color = "black", fill = NA),
        legend.justification = c(0,1))

# TP figure
p3 <- ggplot() +
  geom_sf(data = wsb) +
  geom_sf(data = filter(dat.pt, Chla2010 < 0.2), aes(color = Pvv2010, size = AREASQKM)) +
  geom_sf(data = cbb, fill = "blue", size = NA) +
  labs(color = "TP (mg/L)", size = "Lake size (km2)") +
  theme(panel.background = element_blank(),
        panel.border = element_rect(color = "black", fill = NA),
        legend.justification = c(0,1)) +
  theme(panel.background = element_blank(),
        panel.border = element_rect(color = "black", fill = NA),
        legend.justification = c(0,1))

# CH4 figure
p4 <- ggplot() +
  geom_sf(data = wsb) +
  geom_sf(data = filter(dat.pt, Chla2010 < 0.2), 
          aes(color = preds_lakes_g_m2_y_2010_ch4, size = AREASQKM)) +
  geom_sf(data = cbb, fill = "blue", size = NA) +
  labs(color = "CH4 (mg m-2 d-1)", size = "Lake size (km2)") +
  theme(panel.background = element_blank(),
        panel.border = element_rect(color = "black", fill = NA),
        legend.justification = c(0,1))


# CO2 figure
p5 <- ggplot() +
  geom_sf(data = wsb) +
  geom_sf(data = filter(dat.pt, Chla2010 < 0.2), 
          aes(color = preds_lakes_g_m2_y_2010_co2, size = AREASQKM)) +
  geom_sf(data = cbb, fill = "blue", size = NA) +
  labs(color = "CO2 (mg m-2 d-1)", size = "Lake size (km2)") +
  theme(panel.background = element_blank(),
        panel.border = element_rect(color = "black", fill = NA),
        legend.justification = c(0,1))

# N2O figure
p6 <- ggplot() +
  geom_sf(data = wsb) +
  geom_sf(data = filter(dat.pt, Chla2010 < 0.2), 
          aes(color = preds_lakes_g_m2_y_2010_ch4, size = AREASQKM)) +
  geom_sf(data = cbb, fill = "blue", size = NA) +
  labs(color = "N2O (mg m-2 d-1)", size = "Lake size (km2)") +
  theme(panel.background = element_blank(),
        panel.border = element_rect(color = "black", fill = NA),
        legend.justification = c(0,1))

cowplot::plot_grid(p1, p2, p3, p4, p5, p6, ncol = 3, nrow = 2, align = "hv")

ggsave(file = "output/figures/arealRatesNutrientsPoint.tiff", width = 15, height = 8, units = "in")
```


## Plots of difference in areal emission rates: 2010 - tmdl: point plots
```{r eval = FALSE}
# first, lets add new fields to the data object
dat.pt <- dat.pt %>% mutate(ch4diff_g_m2_y = preds_lakes_g_m2_y_2010_ch4 - preds_lakes_g_m2_y_tmdl_ch4,
                            co2diff_g_m2_y = preds_lakes_g_m2_y_2010_co2 - preds_lakes_g_m2_y_tmdl_co2,
                            n2odiff_g_m2_y = preds_lakes_g_m2_y_2010_n2o - preds_lakes_g_m2_y_tmdl_n2o,
                            ch4diffMg = preds_lakes_Mg_2010_ch4 - preds_lakes_Mg_tmdl_ch4,
                            co2diffMg = preds_lakes_Mg_2010_co2 - preds_lakes_Mg_tmdl_co2,
                            n2odiffMg = preds_lakes_Mg_2010_n2o - preds_lakes_Mg_tmdl_n2o,
                            ChlaDiff = Chla2010 - ChlaTMDLnew,
                            pDiff = Pvv2010 - PvvTMDLnew)

# st_write(dat.pt, 'store\\results\\results.shp') ## export results

# lets make sure the diff values make sense
# there appear to be some extreme values that might obscure
# interesting spatial patterns in the data.
dat.pt %>% sf::st_drop_geometry(.) %>%
  dplyr::select(contains("diff")) %>%
  lapply(., function(x) summary(x))

# lets look at distribution of values
# normal distribution with extremely long tails.
dat.pt %>% sf::st_drop_geometry(.) %>%
  dplyr::select(contains("diff")) %>%
  pivot_longer(everything()) %>%
  ggplot(., aes(value)) +
  geom_density() +
  geom_rug() +
  facet_wrap(~name, scales = "free")

# 73 cases where TP increases under TMDL, which will increase CO2 in small lakes,
# decrease CO2 in large lakes, increase CH4 and increase N2O
dat.pt %>% sf::st_drop_geometry(.) %>%
  filter(pDiff < 0)

# 75 cases where chl a increases under TMDL, which will increase CH4 and N2O
dat.pt %>% sf::st_drop_geometry(.) %>%
  filter(ChlaDiff < 0)

# chla is calculated from TP, so why do we have two more cases of increased
# chl a than increased TP?
# Not sure very small decreases in TP accompanied by small increases in chla
dat.pt %>% sf::st_drop_geometry(.) %>%
  filter(ChlaDiff < 0 & pDiff >0) %>%
  select(Chla2010, ChlaTMDLnew, ChlaDiff, Pvv2010, PvvTMDLnew, pDiff)

# chla vs TP
# hmm, a bit of wiggle around linear fit
dat.pt %>%
  ggplot(aes(ChlaTMDLnew, PvvTMDLnew)) +
  geom_point()

# the cases with crazy increases in chl and ch4 had very high initial chl values (122 and 720)
# maybe we want to omit extreme values from plots
dat.pt %>% sf::st_drop_geometry(.) %>%
  filter(ch4diffMg < 0) %>% # CH4 increased following TMDL
  dplyr::select(matches("TMDLnew|2010|diff")) %>%
  dplyr::select(!matches("in|out|Nvv|preds")) %>%
  mutate(across(contains("Chla"), ~.x*1e3)) %>% # convert to ug/L for convenience
  mutate(across(contains("Chla"), ~round(.x, 3))) %>%
  arrange(ch4diffMg)

# map of increased chl under TMDL, a few clusters of sites
ggplot(states) +
  geom_sf(data = wsb) + #
  geom_sf(fill = NA) +
  geom_sf(data = filter(dat.pt, ChlaDiff < 0))


# Point plot-------------------
# chl figure
# better without extreme values.  Remove really large chla (>200ug/L and sites 
# with greater chla after TMDL implementation)
p2 <- ggplot() +
  geom_sf(data = wsb) +
  geom_sf(data = filter(dat.pt, Chla2010 < 0.2 & ChlaDiff > 0), 
          aes(color = ChlaDiff)) + #, size = AREASQKM))
  geom_sf(data = cbb, fill = "blue", size = NA) +
  labs(color = "ChlA reduction (mg/L)") +
  theme(panel.background = element_blank(),
        panel.border = element_rect(color = "black", fill = NA),
        legend.justification = c(0,1))

# TP figure
p3 <- ggplot() +
  geom_sf(data = wsb) +
  geom_sf(data = filter(dat.pt, Chla2010 < 0.2 & ChlaDiff > 0), 
          aes(color = pDiff, size = AREASQKM)) +
  geom_sf(data = cbb, fill = "blue", size = NA) +
  labs(color = "TP reduction (mg/L)", size = "Lake size (km2)") +
  theme(panel.background = element_blank(),
        panel.border = element_rect(color = "black", fill = NA),
        legend.justification = c(0,1))


# CH4 figure
p4 <- ggplot() +
  geom_sf(data = wsb) +
  geom_sf(data = filter(dat.pt, Chla2010 < 0.2 & ChlaDiff > 0), 
          aes(color = ch4diff_g_m2_y, size = AREASQKM)) +
  geom_sf(data = cbb, fill = "blue", size = NA) +
  labs(color = "CH4 reduction (g m-2 y-1)", size = "Lake size (km2)") +
  theme(panel.background = element_blank(),
        panel.border = element_rect(color = "black", fill = NA),
        legend.justification = c(0,1))


# CO2 figure
p5 <- ggplot() +
  geom_sf(data = wsb) +
  geom_sf(data = filter(dat.pt, Chla2010 < 0.2 & ChlaDiff > 0), 
          aes(color = co2diff_g_m2_y, size = AREASQKM)) +
  geom_sf(data = cbb, fill = "blue", size = NA) +
  labs(color = "CO2 reduction (g m-2 y-1)", size = "Lake size (km2)") +
  theme(panel.background = element_blank(),
        panel.border = element_rect(color = "black", fill = NA),
        legend.justification = c(0,1))


# N2O figure
p6 <- ggplot() +
  geom_sf(data = wsb) +
  geom_sf(data = filter(dat.pt, Chla2010 < 0.2 & ChlaDiff > 0), 
          aes(color = n2odiff_g_m2_y, size = AREASQKM)) +
  geom_sf(data = cbb, fill = "white", size = NA) +
  labs(color = "N2O reduction (g m-2 y-1)", size = "Lake size (km2)") +
  theme(panel.background = element_blank(),
        panel.border = element_rect(color = "black", fill = NA),
        legend.justification = c(0,1))


cowplot::plot_grid(p2, p3, NULL, p4, p5, p6, ncol = 3, nrow = 2, align = "hv")

ggsave(file = "output/figures/pointDiff.tiff", width = 15, height = 8, units = "in")



```


## Plots of difference in areal emission rates: 2010 - tmdl: point plots with color ramps
```{r eval = FALSE}
# Point plot-------------------
# chl figure
# better without extreme values
p2.col <- p2 + scale_color_gradientn(colors = rainbow(5)) # rev(rainbow) isn't any better
p3.col <- p3 + scale_color_gradientn(colors = rainbow(5))
p4.col <- p4 + scale_color_gradientn(colors = rainbow(5))
p5.col <- p5 + scale_color_carto_c(type ="diverging", palette="Earth") #rcartcolor library
p6.col <- p6 + scale_color_carto_c(type ="diverging", palette="Earth")


g <- gridExtra::grid.arrange(p2.col, p3.col, p4.col, p5.col, p6.col, ncol = 3, nrow = 2)

ggsave(file = "output/figures/pointDiffRainbow.tiff", g, width = 15, height = 8, units = "in")

```


## Plots of total emission reductions per lake
```{r eval = FALSE}
# Cut into quantiles to better visualize spatial patterning
summary(dat.pt$co2diffMg)
qco2 <- c("Lower 25%: < 0.66 MT/yr","25% to 50%: 0.66- 1.18 MT/yr","50% to 75%: 1.19 - 2.09 MT/yr","75% to 100%: > 2.09 MT/yr")

summary(dat.pt$ch4diffMg)
qch4 <- c("Lower 25%: < 0.07 MT/yr","25% to 50%: 0.07-0.15 MT/yr","50% to 75%: 0.16-0.35 MT/yr","75% to 100%: > 0.35 MT/yr")

dat.pt <- dat.pt %>% mutate(n2odiffKg = n2odiffMg * 1000) # rescale to kg
summary(dat.pt$n2odiffKg)
qn2o <- c("Lower 25%: < 0.16 kg/yr","25% to 50%: 0.16 - 0.34 kg/yr","50% to 75%: 0.34 - 0.75 kg/yr","75% to 100%: > 0.75 kg/yr")

dat.pt <- dat.pt %>%
  mutate(ch4diff_bin = cut(x = ch4diffMg,
                           breaks = c(quantile(ch4diffMg, probs = seq(0, 1, by = 1/4), na.rm = T)),
                           include.lowest = TRUE,
                           labels = qch4),
         co2diff_bin = cut(x = co2diffMg,
                           breaks = c(quantile(co2diffMg, probs = seq(0, 1, by = 1/4), na.rm = T)),
                           include.lowest = TRUE,
                           labels = qco2),
         n2odiff_bin = cut(x = n2odiffMg,
                           breaks = c(quantile(n2odiffMg, probs = seq(0, 1, by = 1/4), na.rm = T)),
                           include.lowest = TRUE,
                           labels = qn2o))


# CH4
p1 <- ggplot() +
  geom_sf(data = wsb) +
  geom_sf(data = cbb, fill = "white", size = NA) +
  geom_sf(data = dat.pt %>% arrange(AREASQKM), # larger dots plot on top of small
          aes(color = ch4diffMg, size = AREASQKM)) +
  labs(color = expression(atop(Avoided~CH[4], ~(MT~yr^{-1}))), 
       size = expression(Lake~size~(km^{2}))) +
  theme(panel.background = element_blank(),
        panel.border = element_rect(color = "black", fill = NA),
        legend.justification = c(0,1)) 
  #scale_color_carto_c(type ="diverging", palette="Earth")

# CH4, alternative
p1.alt <- ggplot() +
  geom_sf(data = wsb) +
  geom_sf(data = cbb, fill = "white", size = NA) +
  geom_sf(data = dat.pt %>% arrange(AREASQKM), # larger dots plot on top of small
          aes(color = ch4diff_bin)) +  #size = AREASQKM
  labs(color = expression(atop(Reduced~CH[4], ~(MT~yr^{-1}))), size = expression(Lake~size~(km^{2}))) +
  theme(panel.background = element_blank(),
        panel.border = element_rect(color = "black", fill = NA),
        legend.justification = c(0,1)) +
  scale_color_carto_d(type ="diverging", palette="Earth")

ggsave(file = "output/figures/ch4PointIncremental.tiff", width = 6, height = 5, units = "in")



# CO2
p2 <- ggplot() +
  geom_sf(data = wsb) +
  geom_sf(data = cbb, fill = "white", size = NA) +
  geom_sf(data = dat.pt %>% arrange(AREASQKM), # larger dots plot on top of small
          aes(color = co2diffMg, size = AREASQKM)) +
  labs(color = expression(atop(Avoided~CO[2], ~(MT~yr^{-1}))), size = expression(Lake~size~(km^{2}))) +
  theme(panel.background = element_blank(),
        panel.border = element_rect(color = "black", fill = NA),
        legend.justification = c(0,1))

# CO2 alternative
p2.alt <- ggplot() +
  geom_sf(data = wsb) +
  geom_sf(data = cbb, fill = "white", size = NA) +
  geom_sf(data = dat.pt %>% arrange(AREASQKM), # larger dots plot on top of small
          aes(color = co2diff_bin, size = AREASQKM)) + #  
  labs(color = expression(atop(Reduced~CO[2], ~(MT~yr^{-1}))), size = expression(Lake~size~(km^{2}))) +
  theme(panel.background = element_blank(),
        panel.border = element_rect(color = "black", fill = NA),
        legend.justification = c(0,1)) +
  scale_color_carto_d(type ="diverging", palette="Earth")

# N2O
p3 <- ggplot() +
  geom_sf(data = wsb) +
  geom_sf(data = cbb, fill = "white", size = NA) +
  geom_sf(data = dat.pt %>% arrange(AREASQKM), # larger dots plot on top of small
          aes(color = n2odiffKg, size = AREASQKM)) +
  labs(color = expression(atop(Avoided~N[2]*O, ~(kg~yr^{-1}))), size = expression(Lake~size~(km^{2}))) +
  theme(panel.background = element_blank(),
        panel.border = element_rect(color = "black", fill = NA),
        legend.justification = c(0,1))

# N2O alternative
p3.alt <- ggplot() +
  geom_sf(data = wsb) +
  geom_sf(data = cbb, fill = "white", size = NA) +
  geom_sf(data = dat.pt %>% arrange(AREASQKM), # larger dots plot on top of small
          aes(color = n2odiff_bin, size = AREASQKM)) + # 
  labs(color = expression(atop(Avoided~N[2]*O, ~(kg~yr^{-1}))), size = expression(Lake~size~(km^{2}))) +
  theme(panel.background = element_blank(),
        panel.border = element_rect(color = "black", fill = NA),
        legend.justification = c(0,1)) +
  scale_color_carto_d(type ="diverging", palette="Earth")


cowplot::plot_grid(p1, p2, p3, ncol = 3, nrow = 1, align = "h")
ggsave(file = "output/figures/pointIncremental.tiff", width = 15, height = 5, units = "in")

cowplot::plot_grid(p1.alt, p2.alt, p3.alt, ncol = 3, nrow = 1, align = "h")
ggsave(file = "output/figures/pointIncrementalBin.tiff", width = 15, height = 5, units = "in")
```

## Plots of total emission reductions per county
```{r eval = FALSE}
cnty.us.tigris <- tigris::counties(state = c("Virginia", "Maryland", "Delaware",
                                             "West Virginia", "Pennsylvania", "New York")) %>%
  st_transform(crs = st_crs(wsb))
st_crs(cnty.us.tigris) # 4326, WGS84

st_crs(cnty.us.tigris) == st_crs(wsb) #TRUE

# clip county to Chesapeake watershed
cnty <- sf::st_intersection(x = cnty.us.tigris, y = wsb) 
st_crs(cnty)

# need to project cnty to dat.pt
cnty <- st_transform(cnty, crs = st_crs(dat.pt))
dat.pt <- sf::st_intersection(x = dat.pt, y = cnty) # this adds cty to points

# aggregate incremental emissions and lake area by county
dat.pt.agg <- dat.pt %>%
  group_by(STATEFP, COUNTYFP) %>% # unique cnty within state
  summarise(across(c(ch4diffMg, co2diffMg, n2odiffKg, AREASQKM), sum),
            meanTP = mean(Pvv2010),
            meanChla = mean(Chla2010))

ggplot(dat.pt.agg) + geom_point(aes(AREASQKM, ch4diffMg))

# now add aggregated incremental change to cnty attributes
cnty.increment <- merge(cnty, dat.pt %>% sf::st_drop_geometry())


# lake area by cnty
p1 <- ggplot() +
  geom_sf(data = wsb) + #
  geom_sf(data = cnty.increment, aes(fill = AREASQKM)) +
  geom_sf(data = cbb, fill = "blue", size = NA) +
  labs(fill = "lake area (km2)") +
  theme(legend.position = "top",
        panel.background = element_blank(),
        panel.border = element_rect(color = "black", fill = NA),
        legend.justification = c(0,1))

# # mean TP by cnty
# p1 <- ggplot() +
#   geom_sf(data = wsb) + #
#   geom_sf(data = cnty.increment, aes(fill = meanTP)) +
#   geom_sf(data = cbb, fill = "blue", size = NA) +
#   labs(fill = "mean TP (mg/L)") +
#   theme(legend.position = "top")
#
# # lake chla by cnty
# p1 <- ggplot() +
#   geom_sf(data = wsb) + #
#   geom_sf(data = cnty.increment, aes(fill = meanChla)) +
#   geom_sf(data = cbb, fill = "blue", size = NA) +
#   labs(fill = "mean Chla (mg/L)") +
#   theme(legend.position = "top")


# CH4 reductions
p2 <- ggplot() +
  geom_sf(data = wsb) + #
  geom_sf(data = cnty.increment, aes(fill = ch4diffMg)) +
  geom_sf(data = cbb, fill = "blue", size = NA) +
  labs(fill = "CH4 reduction (mt year-1)") +
  theme(legend.position = "top",
        panel.background = element_blank(),
        panel.border = element_rect(color = "black", fill = NA),
        legend.justification = c(0,1))


# CO2 reductions
p3 <- ggplot() +
  geom_sf(data = wsb) + #
  geom_sf(data = cnty.increment, aes(fill = co2diffMg)) +
  geom_sf(data = cbb, fill = "blue", size = NA) +
  labs(fill = "CO2 reduction (mt year-1)") +
  theme(legend.position = "top",
        panel.background = element_blank(),
        panel.border = element_rect(color = "black", fill = NA),
        legend.justification = c(0,1))


# N2O reductions
p4 <- ggplot() +
  geom_sf(data = wsb) + #
  geom_sf(data = cnty.increment, aes(fill = n2odiffKg)) +
  geom_sf(data = cbb, fill = "blue", size = NA) +
  labs(fill = "N2O reduction (mt year-1)") +
  theme(legend.position = "top",
        panel.background = element_blank(),
        panel.border = element_rect(color = "black", fill = NA),
        legend.justification = c(0,1))


g <- gridExtra::grid.arrange(p1, p2, p3, p4, ncol = 4, nrow = 1)

ggsave(file = "output/figures/cntyIncremental.tiff", g, width = 15, height = 6, units = "in")


# Use interactive plot to identify counties with large incremental reductions




gg <- ggplot(cnty.increment) +
  geom_sf_interactive(aes(fill = ch42010.lk.yr.diff.mt, tooltip = GEOID, data_id = GEOID))
ggiraph::girafe(ggobj = gg)

dat.yr.sf %>% filter(ALAND == 2305001140)

```

## Plots of nutrient and emission reductions by latitude
```{r eval = FALSE}

# reduction in areal CH4 emission rate vs latitude
dat.lat <- dat.pt %>%
  filter(Chla2010 < 0.2 & ChlaDiff > 0) %>%
  mutate(lat = st_coordinates(.)[,2]) %>%
  st_drop_geometry() %>%
  dplyr::select(lat, ChlaDiff, pDiff, contains("diff_g")) %>%
  pivot_longer(cols = !lat)

ggplot(dat.lat, aes(lat, value)) +
  geom_point() +
  facet_wrap(~name, scales = "free")


```


## CDF plots
```{r eval = FALSE}
# CDF PRE AND POST-----------------------
dat.long <- dat.pt %>% st_drop_geometry() %>%
  dplyr::select(Chla2010, ChlaTMDLnew,
                Pvv2010, PvvTMDLnew,
                preds_lakes_g_m2_y_2010_ch4, preds_lakes_g_m2_y_tmdl_ch4,
                preds_lakes_g_m2_y_2010_co2, preds_lakes_g_m2_y_tmdl_co2,
                preds_lakes_g_m2_y_2010_n2o, preds_lakes_g_m2_y_tmdl_n2o) %>%
  pivot_longer(cols = everything()) %>%
  mutate(scenario = case_when(grepl("tmdl", name, ignore.case = TRUE) ~ "TMDL",
                              grepl("2010", name) ~ "Baseline",
                              TRUE ~ "WazUp!"))

# Two panel plot of P and Chl for manuscript-------------------------
chl.ecdf <- ggplot(dplyr::filter(dat.long, grepl(pattern = "Chl", x = name)), 
             aes(value, linetype = scenario)) +
  stat_ecdf(geom="step", pad = FALSE) +
  xlim(0, 0.125) + # otherwise extreme values obscure patterns
  ylab("Proportion of Lakes") +
  xlab("chlorophyll a (mg/L)") +
  annotate("text", x = 0, y = 1, label = "A") +
  theme_bw() +
  theme(legend.position = c(0.8, 0.4),
        legend.title = element_blank())

tp.ecdf <- ggplot(dplyr::filter(dat.long, grepl(pattern = "Pvv", x = name)), 
             aes(value, linetype = scenario)) +
  stat_ecdf(geom="step", pad = FALSE) +
  xlim(0, 0.25) +
  ylab("Proportion of Lakes") +
  xlab("Total phosphorus (mg/L)") +
  annotate("text", x = 0, y = 1, label = "B") +
  #ggtitle("total phosphorus") +
  theme_bw() +
  theme(axis.title.y = element_blank(),
        legend.position = "none")

g <- gridExtra::grid.arrange(chl.ecdf, tp.ecdf, ncol = 2, nrow = 1)

ggsave(file = "output/figures/tp.chl.cdf.tiff", g, width = 7.5, height = 3.5, units = "in")


# 5 panel plot----------------------------
p1 <- ggplot(dplyr::filter(dat.long, grepl(pattern = "Chl", x = name)), 
             aes(value, color = name)) +
  stat_ecdf(geom="step", pad = FALSE) +
  xlim(0, 0.2) + # otherwise extreme values obscure patterns
  ggtitle("Chlorophyll") +
  ylab("Cumulative Percent") +
  theme(legend.position = c(0.8, 0.4),
        legend.title = element_blank())

p2 <- ggplot(dplyr::filter(dat.long, grepl(pattern = "Pvv", x = name)), 
             aes(value, color = name)) +
  stat_ecdf(geom="step", pad = FALSE) +
  xlim(0, 0.5) +
  ggtitle("total phosphorus") +
  theme(axis.title.y = element_blank(),
        legend.position = "none")

p3 <- ggplot(dplyr::filter(dat.long, grepl(pattern = "ch4", x = name)), 
             aes(value, color = name)) +
  stat_ecdf(geom="step", pad = FALSE) +
  xlim(0, 200) + 
  ggtitle("CH4 emission rate") +
  ylab("Cumulative Percent") +
  theme(legend.position = "none")

p4 <- ggplot(dplyr::filter(dat.long, grepl(pattern = "co2", x = name)), 
             aes(value, color = name)) +
  stat_ecdf(geom="step", pad = FALSE) +
  xlim(0, 2000) +
  ggtitle("CO2 emission rate") +
  theme(axis.title.y = element_blank(),
        legend.position = "none")

p5 <- ggplot(dplyr::filter(dat.long, grepl(pattern = "n2o", x = name)), 
             aes(value, color = name)) +
  stat_ecdf(geom="step", pad = FALSE) +
  xlim(0, 0.4) +
  ggtitle("N2O emission rate") +
  theme(axis.title.y = element_blank(),
        legend.position = "none")

g <- gridExtra::grid.arrange(gridExtra::arrangeGrob(p1, p2, ncol = 3),
                             gridExtra::arrangeGrob(p3, p4, p5, ncol = 3),
                             nrow = 2)

ggsave(file = "output/figures/cdf.tiff", g, width = 12, height = 8, units = "in")

```


## Histogram of reductions

```{r eval = FALSE}

# PERCENT REDUCTION------

# why do we have so many sites where CH4 increased after TMDL implementation?
ggplot(dplyr::filter(dat.pt, Chla2010 < 0.2),
       aes(x = (ch4diff_g_m2_y)/preds_lakes_g_m2_y_2010_ch4)) + 
  geom_histogram()

# model predicts increased chla after TMDL for these sites
dplyr::filter(dat.pt, ch4diff_g_m2_y <0) %>%
  dplyr::select(preds_lakes_g_m2_y_2010_ch4, preds_lakes_g_m2_y_tmdl_ch4, 
                AREASQKM, Chla2010, ChlaTMDLnew)


# TOTAL REDUCTION-----
# histogram
# CH4
p.ch4 <- ggplot(dat.pt, aes(x = ch4diffMg))  + 
  geom_histogram(bins = 75) +
  scale_x_continuous(trans = ggallin::pseudolog10_trans, 
                     breaks = c(-10, -3, 0, 3, 10, 30, 100), 
                     minor_breaks = NULL) +
  geom_rug(length = grid::unit(3, units = "mm")) +
  xlab(expression(atop("Emission Change", ~(metric~tons~CH[4]~yr^{-1}~lake^{-1})))) +
  theme_bw() +
  theme(axis.title.y = element_blank(),
        axis.text = element_text(size = 15),
        axis.title = element_text(size = 20))


# N2O
p.n2o <- ggplot(dat.pt, aes(x = n2odiffKg)) + 
  geom_histogram(bins = 75) +
  scale_x_continuous(trans = ggallin::pseudolog10_trans, 
                     breaks = c(-10, -3, 0, 3, 10, 30, 100)) +
  geom_rug(length = grid::unit(3, units = "mm")) +
  xlab(expression(atop("Emission Change", ~(kg~N[2]*O~yr^{-1}~lake^{-1})))) +
  theme_bw() +
  theme(axis.title.y = element_blank(),
        axis.text = element_text(size = 15),
        axis.title = element_text(size = 20))

# CO2
p.co2 <- ggplot(dat.pt, aes(x = co2diffMg)) + 
  geom_histogram(bins = 75) +
  scale_x_continuous(trans = ggallin::pseudolog10_trans,
                     breaks = c(-10, -3, 0, 3, 10, 30, 100)) +
  geom_rug(length = grid::unit(3, units = "mm")) +
  xlab(expression(atop("Emission Change", ~(metric~tons~CO[2]~yr^{-1}~lake^{-1})))) +
  theme_bw() +
  theme(axis.title.y = element_blank(),
        axis.text = element_text(size = 15),
        axis.title = element_text(size = 20))


g <- gridExtra::grid.arrange(p.ch4, p.co2, p.n2o, ncol = 3, nrow = 1)

ggsave(file = "output/figures/incremental.histogram.tiff", g, width = 15, height = 6, units = "in")

# What fraction have negative avoided emissions?  Higher emissions in TMDL
dat.pt %>%
  st_drop_geometry() %>%
  summarize(neg.p.ch4 = sum(ch4diffMg < 0, na.rm = TRUE) / nrow(.),
            neg.p.co2 = sum(co2diffMg < 0, na.rm = TRUE) / nrow(.),
            neg.p.n2o = sum(n2odiffKg < 0, na.rm = TRUE) / nrow(.))
```

## Avoided emissions vs environmental variables
```{r eval = FALSE}

# scatterplot vs size, 3 gases----------------
dat.pt %>%
  st_drop_geometry() %>%
  dplyr::select(co2diffMg, ch4diffMg, n2odiffKg, AREASQKM) %>%
  pivot_longer(cols = !AREASQKM) %>%
  ggplot(., aes(AREASQKM, value, color = name)) +
  scale_color_discrete(labels = c(expression(CH[4]),
                                  expression(CO[2]),
                                  expression(N[2]*O))) +
  geom_point(alpha = 0.5) +
  scale_x_continuous(trans = ggallin::pseudolog10_trans, breaks = c(0,1,2.5,5,10,20,30)) +
  scale_y_continuous(trans = ggallin::pseudolog10_trans, breaks = c(-100,-50, -25,-10, -1, 0, 1, 10, 25, 50, 100, 150)) +
  ylab(expression(atop("Avoided GHG emissions per lake", ~(MT~CH[4]~yr^{-1})~~or~~(MT~CO[2]~yr^{-1})~~or~            ~(kg~N[2]*O~yr^{-1})))) +
  xlab(expression(Lake~area~(km^{2}))) +
  theme_bw() +
  theme(legend.title = element_blank(),
        legend.position = c(0.5, 0.1),
        legend.direction = "horizontal")

ggsave(file = "output/figures/incremental.lake.area.tiff", width = 6, height = 5, units = "in")


# scatterplot vs size, CH4 only----------------
dat.pt %>%
  st_drop_geometry() %>%
  ggplot(., aes(AREASQKM, ch4diffMg)) +
  geom_point(alpha = 0.5) +
  scale_x_continuous(trans = ggallin::pseudolog10_trans, breaks = c(0,1,2.5,5,10,20,30)) +
  scale_y_continuous(trans = ggallin::pseudolog10_trans, breaks = c(-100,-50, -25,-10, -1, 0, 1, 10, 25, 50, 100, 150)) +
  ylab(expression(atop("Reduced emissions per lake", ~(MT~CH[4]~yr^{-1})))) +
  xlab(expression(Lake~area~(km^{2}))) +
  theme_bw()

ggsave(file = "output/figures/incremental.ch4.lake.area.tiff", width = 6, height = 5, units = "in")


# Avoided GHG emissions by lake surface area bar plot----------
# set up data
dat.bin <- dat.pt %>%
  st_drop_geometry() %>%
  mutate(lake.bins = ifelse(AREASQKM <= 0.01,
                            "< 0.01 km2",
                            ifelse(AREASQKM > 0.01 & AREASQKM <= 0.1,
                                   ">0.01 km2 & < 0.1 km2",
                                   ifelse(AREASQKM > 0.10 & AREASQKM <= 1,
                                          ">0.1 km2 & < 1 km2",
                                          ifelse(AREASQKM > 1 & AREASQKM <= 10,
                                                 ">1 km2 & < 10 km2",
                                                 ifelse(AREASQKM > 10,
                                                        "> 10 km2",
                                                        "error"))))),
         lake.bins = factor(lake.bins, levels = c("< 0.01 km2", ">0.01 km2 & < 0.1 km2",
                                                  ">0.1 km2 & < 1 km2", ">1 km2 & < 10 km2",
                                                  "> 10 km2"))) %>%

 dplyr::select(co2diffMg, ch4diffMg, n2odiffKg, lake.bins, AREASQKM) %>%
  pivot_longer(cols = -c(lake.bins, AREASQKM)) %>%
  group_by(name, lake.bins) %>% # operate by gas x lake.bin
  summarize(total = sum(value), # total avoided
            obs = paste0("n = ", length(value), ", area = ", round(sum(AREASQKM), 0), " km2")) #lakes per group

# create labels for facets
name.labs <- as_labeller(c("ch4diffMg" = "CH[4]",
                           "co2diffMg" = "CO[2]",
                           "n2odiffKg" = "N[2]*O"),
                         default = label_parsed)


# plot
ggplot(dat.bin, aes(x=lake.bins, y=total)) +
  geom_bar(position="dodge", stat="identity") +
  facet_wrap(~name, nrow = 3, scales = "free_y", labeller = name.labs) +
  ylab(expression(Avoided~GHG~emissions~(MT~GHG~yr^{-1}))) +
  theme(axis.title.x = element_blank()) +
  geom_text(aes(label = obs), vjust = -0.5, size = 3) +
  scale_y_continuous(expand = expansion(mult = c(0.05, 0.2)))


ggsave(file = "output/figures/incremental.by.lake.area.tiff", width = 10, height = 5, units = "in")



# Avoided emissions by ice cover and nutrients-----------------------
dat.pt <- dat.pt %>% 
  mutate(day_of_ice_filled_bin = cut(x = day_of_ice_filled, breaks = 4,
                                     labels = c("< 28", "28 - 55", "56 - 82", ">82")))

# ice cover first
# scatterplot, not so great
ggplot(dat.pt, aes(day_of_ice_filled, ch4diffMg)) + geom_point() +
  scale_y_continuous(trans = ggallin::pseudolog10_trans,
                     breaks = c(-100,-50, -25,-10, -1, 0, 1, 10, 25, 50, 100, 150))

# bar and whisker, not much better
ggplot(dat.pt, aes(day_of_ice_filled_bin, ch4diffMg)) +
  geom_boxplot() +
  scale_y_continuous(trans = ggallin::pseudolog10_trans,
                     breaks = c(-100,-50, -25,-10, -1, 0, 1, 10, 25, 50, 100, 150),
                     limits = c(-1, 150))

# error bars for bar chart
# https://www.geeksforgeeks.org/bootstrap-confidence-interval-with-r-programming/
library(boot)

# custom function for boot
mean.fun <- function(data, idx){ # idx is boot() index
  df <- data[idx, ] # sample data
  mean(df$ch4diffMg) # calculate mean of sample
}

# Setting the seed for
# reproducability of results
set.seed(42)

# Calling the boot function with the dataset
# our function and no. of rounds
poo <- dat.pt %>%
  st_drop_geometry() %>%
  group_by(day_of_ice_filled_bin) %>%
  group_split() %>%
  lapply(., function(x) {
    boot.out <- boot(x, mean.fun, R = 1000)
    foo <- boot.ci(boot.out, type = "norm")
    return(foo)
  }
  ) %>%
  lapply(., function(x) {
    temp <- x$normal[2:3]
    foo <- data.frame(lwr = temp[1],
                      upr = temp[2])
    return(foo)
  }
  ) %>%
  do.call("rbind", .)

# bar chart, this looks ok
dat.pt %>%
  st_drop_geometry() %>%
  group_by(day_of_ice_filled_bin) %>%
  summarize(ch4diff.MTbyIceBin = mean(ch4diffMg, na.rm = TRUE),
            nobs = n()) %>%
  cbind(., poo) %>% # bring in 95% CI
  ggplot(., aes(day_of_ice_filled_bin, ch4diff.MTbyIceBin)) +
  geom_bar(stat = "identity") +
  geom_errorbar(aes(x = day_of_ice_filled_bin, ymin = lwr, ymax = upr), width = 0.4) +
  ylab(expression(Reduced~CH[4]~emissions~(MT~CH[4]~yr^{-1}))) +
  xlab("Days of ice cover")

ggsave("output/figures/ch4ReductionByIceCoverBin.tiff", width = 4, height = 4, units = "in")



# more chlorophyll equates to lower reduced emissions
ggplot(filter(dat.pt, Chla2010 < 0.2), aes(Chla2010, ch4diffMg)) + geom_point() +
  scale_y_continuous(trans = ggallin::pseudolog10_trans,
                     breaks = c(-100,-50, -25,-10, -1, 0, 1, 10, 25, 50, 100, 150))

ggplot(filter(dat.pt, Chla2010 < 0.2), aes(Pvv2010, ch4diffMg)) + geom_point() +
  scale_y_continuous(trans = ggallin::pseudolog10_trans,
                     breaks = c(-100,-50, -25,-10, -1, 0, 1, 10, 25, 50, 100, 150))


# Areal emission rate reductions by nutrients
# Greater reduction in emission rates (mg GHG m-2 d-1) in high chl lakes
ggplot(filter(dat.pt, Chla2010 < 0.2), aes(Chla2010, ch4diff_g_m2_y)) +
  geom_point() +
  ylim(-10, 60) + # cut out a few points with large negative values
  ylab(expression(atop("Reduction in areal emission rate", (g~CH[4]~m^{-2}*~year^{-1})))) +
  xlab(expression(Baseline~chlorophyll~a~(mu*g~L^{-1}))) +
  theme(axis.title = element_text(size = 14))

ggsave("output/figures/arealCh4ReductionByChl.tiff", width = 6, height = 5, units = "in")



# Reduction in emission rates (mg GHG m-2 d-1) is proportional to reduction in chl
ggplot(filter(dat.pt, Chla2010 < 0.2), aes(ChlaDiff, ch4diff_g_m2_y)) +
  geom_point() +
  #ylim(-10, 60) + # cut out a few points with large negative values
  ylab(expression(atop("Change in areal emission rate", (g~CH[4]~m^{-2}*~year^{-1})))) +
  xlab(expression("Change in chlorophyll a"~(mu*g~L^{-1}))) +
  theme(axis.title = element_text(size = 14))




```
## Lake size distribution
```{r}
# lake size histogram
ggplot(dat.pt, aes(x=AREASQKM)) + 
  geom_histogram(bins = 75) + 
  scale_x_log10() +
  xlab(expression(Waterbody~surface~area~(km^{2})))


# lake size CDF
ggplot(dat.pt, aes(x=AREASQKM)) +
   stat_ecdf(geom="step", pad = FALSE)

```


## Avoided emissions expressed in GWP
```{r eval = FALSE}
# CH4 and N2O are more potent GHGs than CO2.  To enable comparison, the global warming potential (GWP)
# of CH4 and N2O emissions can be expressed relative to that of CO2.  On 100-year horizon, CH4 = 28, N2O = 265

dat.gwp <- data.frame(type = rep(c("mass", "gwp"), each = 3),
                      gas = rep(c("CH4", "CO2", "N2O"), 2), #rep(c("CH4", "CO2", "N2O"), 2)
                      tot = c(2039, 7871, 5.3, 2039*28, 7871, 5.3*265),
                      tot.lwr = c(1195, 6646, 2.5, 1195*28, 6646, 2.5*265),
                      tot.upr = c(3145, 9123, 8.6, 3145*28, 9123, 8.6*265))

p.mass <- ggplot(data = filter(dat.gwp, type == "mass") , aes(x=gas, y=tot)) +
  geom_bar(stat = "identity") +
  geom_errorbar(aes(ymin=tot.lwr, ymax=tot.upr), width=.2,
                position=position_dodge(.9)) +
  scale_x_discrete(labels = c(expression(CH[4]), expression(CO[2]), expression(N[2]*O))) +
  ylab(expression(Avoided~GHG~emissions~(MT~GHG~yr^{-1}))) +
  theme(axis.title.x = element_blank())

p.gwp <- ggplot(data = filter(dat.gwp, type == "gwp") , aes(x=gas, y=tot)) +
  geom_bar(stat = "identity") +
  geom_errorbar(aes(ymin=tot.lwr, ymax=tot.upr), width=.2,
                position=position_dodge(.9)) +
  scale_x_discrete(labels = c(expression(CH[4]), expression(CO[2]), expression(N[2]*O))) +
  ylab(expression(Avoided~GHG~emissions~(MT~CO[2]~equivalents~yr^{-1}))) +
  theme(axis.title.x = element_blank())

cowplot::plot_grid(p.mass, p.gwp, ncol = 2, nrow = 1, align = "hv")

ggsave(file = "output/figures/mass.gwp.tiff", width = 9, height = 4, units = "in")
```

## NE lakes model output
```{r eval=FALSE}
# Map of 2010 chla and TP-----------------
# chl figure
# better without extreme values
library(RColorBrewer)
p2 <- ggplot() +
  geom_sf(data = wsb) +
  geom_sf(data = filter(dat.pt, Chla2010 < 0.2),
          aes(color = Chla2010)) + #, size = AREASQKM))
  geom_sf(data = cbb, fill = "white", size = NA) +
  scale_x_continuous(breaks = c(-80, -78, -76)) +
  labs(color = expression(Chl~a~(mu*g~L^{-1}))) +
  theme(panel.background = element_blank(),
        panel.border = element_rect(color = "black", fill = NA),
        legend.position = "top") #legend.justification = c(0,1)



# TP figure
p3 <- ggplot() +
  geom_sf(data = wsb) +
  geom_sf(data = filter(dat.pt, Chla2010 < 0.2), aes(color = Pvv2010)) +
  geom_sf(data = cbb, fill = "white", size = NA) +
  scale_x_continuous(breaks = c(-80, -78, -76)) +
  labs(color = expression(TP~(mg~L^{-1}))) +
  theme(panel.background = element_blank(),
        panel.border = element_rect(color = "black", fill = NA),
        legend.position = "top") #legend.justification = c(0,1)

# ice days figure
p4 <- ggplot() +
  geom_sf(data = wsb) +
  geom_sf(data = dat.pt, aes(color = day_of_ice_filled)) +
  geom_sf(data = cbb, fill = "white", size = NA) +
  labs(color = "Ice cover duration (days)", size = "Lake size (km2)") +
  theme(panel.background = element_blank(),
        panel.border = element_rect(color = "black", fill = NA),
        legend.position = "top")


cowplot::plot_grid(p2, p3, p4, ncol = 3, nrow = 1, align = "hv")
ggsave(file = "output/figures/NElakesOutputMap.tiff", width = 10, height = 5, units = "in")

# CDF figures---------------
# Dataframe for medians shown in plot
chl.summary <- dplyr::filter(dat.long, grepl(pattern = "Chl", x = name), value < 0.2) %>%
  mutate(value = value * 1e3) %>% # mg -> ug/L
  dplyr::select(value, name) %>%
  group_by(name) %>%
  summarize(md. = median(value))

# default ggplot colors.  used to match text color in annotate()
cols.def <- hue_pal()(2)

p.chl <- ggplot(dplyr::filter(dat.long, grepl(pattern = "Chl", x = name), value < 0.2) %>%
                  mutate(value = value * 1e3), # mg -> ug/L,
                aes(value, color = name)) +
  stat_ecdf(geom="step") +
  ylab("Cumulative Percent") +
  geom_segment(data = chl.summary, aes(x=md., xend = md., y=0, yend=0.5, color = name), linetype = 2) +
  annotate("text", label = "2010 median = 20.8", x=20.8, y = 0.25,
           color = cols.def[1], hjust = -0.1, vjust = 0, size = 3) +
  annotate("text", label = "TMDL median= 16.4", x=20.8, y = 0.1,
           color = cols.def[2], hjust = -0.1, vjust = 0, size = 3) +
  xlab(expression(Chl~a~(mu*g~L^{-1}))) +
  theme(legend.position = c(0.8, 0.4),
        legend.title = element_blank()) +
  scale_color_discrete(labels = c("2010", "TMDL"))

# Dataframe for medians shown in plot
tp.summary <- dplyr::filter(dat.long, grepl(pattern = "Pvv", x = name), value < 0.5) %>%
  mutate(value = value * 1e3) %>% # mg -> ug/L
  dplyr::select(value, name) %>%
  group_by(name) %>%
  summarize(md. = median(value))

p.tp <- ggplot(dplyr::filter(dat.long, grepl(pattern = "Pvv", x = name), value < 0.5) %>%
                 mutate(value = value * 1e3),
               aes(value, color = name)) +
  stat_ecdf(geom="step") +
  ylab("Cumulative Percent") +
  geom_segment(data = tp.summary, aes(x=md., xend = md., y=0, yend=0.5, color = name), linetype = 2) +
  annotate("text", label = "2010 median = 43.9", x=43.9, y = 0.25,
           color = cols.def[1], hjust = -0.1, vjust = 0, size = 3) +
  annotate("text", label = "TMDL median= 34.6", x=43.9, y = 0.05,
           color = cols.def[2], hjust = -0.1, vjust = 0, size = 3) +
  xlab(expression(TP~(mg~L^{-1}))) +
  theme(legend.position = c(0.8, 0.4),
        legend.title = element_blank()) +
  scale_color_discrete(labels = c("2010", "TMDL"))

cowplot::plot_grid(p.chl, p.tp, ncol = 1, nrow = 2, align = "hv")
ggsave(file = "output/figures/NElakesOutputCDF.tiff", width = 4, height = 5.5, units = "in")

```

# Manuscript Figures
  
## Figure 3: CDF and spatial of TP and Chla
```{r}
#Figure 3
# 4 panel plot of chl cdf, chl diff spatial plot, tp cdf, tp diff spatial

# chl figure
# better without extreme values.  Remove single lake with really large chla value
# (>200ug/L) and  greater chla after TMDL implementation
filter(dat.pt, Chla2010 > 0.2 & ChlaDiff < 0) # one lake

p1 <- ggplot() +
  geom_sf(data = wsb) +
  geom_sf(data = filter(dat.pt, Chla2010 < 0.2 & ChlaDiff > 0) %>%
            arrange(ChlaDiff), 
          aes(color = ChlaDiff * 1000)) + # *1000 for mg -> ug
  geom_sf(data = cbb, fill = "white", size = 0.1) +
  annotate("text", x = -80, y = 43, label = "B") +
  labs(color = "Chl a\nreduction (ug/L)") +
  theme(panel.background = element_blank(),
        panel.border = element_rect(color = "black", fill = NA),
        legend.justification = c(0,1),
        legend.title = element_text(size=8),
        axis.title = element_blank())

# chl.ecdf as above
chl.ecdf <- ggplot(dplyr::filter(dat.long, grepl(pattern = "Chl", x = name)), 
             aes(value * 1000, linetype = scenario)) + # *1000 for mg -> ug
  stat_ecdf(geom="step", pad = FALSE) +
  xlim(0, 125) + # otherwise extreme values obscure patterns
  ylab("Proportion of Lakes") +
  xlab("chlorophyll a (ug/L)") +
  annotate("text", x = 0, y = 1, label = "A") +
  theme_bw() +
  theme(legend.position = c(0.8, 0.4),
        legend.title = element_blank())

# TP figure
p2 <- ggplot() +
  geom_sf(data = wsb) +
  geom_sf(data = filter(dat.pt, Chla2010 < 0.2 & ChlaDiff > 0) %>%
            arrange(pDiff), 
          aes(color = pDiff * 1000)) + # *1000 for mg -> ug
  geom_sf(data = cbb, fill = "white", size = 0.1) + #size = NA
  annotate("text", x = -80, y = 43, label = "D") +
  labs(color = "TP\nreduction (ug/L)", size = "Lake size (km2)") +
  theme(panel.background = element_blank(),
        panel.border = element_rect(color = "black", fill = NA),
        legend.justification = c(0,1),
        legend.title = element_text(size=8),
        axis.title = element_blank())



tp.ecdf <- ggplot(dplyr::filter(dat.long, grepl(pattern = "Pvv", x = name)), 
             aes(value * 1000, linetype = scenario)) + # *1000 for mg -> ug
  stat_ecdf(geom="step", pad = FALSE) +
  xlim(0, 250) +
  ylab("Proportion of Lakes") +
  xlab("Total phosphorus (ug/L)") +
  annotate("text", x = 0, y = 1, label = "C") +
  theme_bw() +
  theme(legend.position = "none")

g <- gridExtra::grid.arrange(chl.ecdf, p1, tp.ecdf, p2, ncol = 2, nrow = 2)

ggsave(file = "output/figures/Fig.3.tiff", g, width = 7.5, height = 6.0, units = "in")






```

## Figure 3: CDF and spatial of TP and Chla with small points
```{r}
#Figure 3
# 4 panel plot of chl cdf, chl diff spatial plot, tp cdf, tp diff spatial

# chl figure
# better without extreme values.  Remove single lake with really large chla value
# (>200ug/L) and  greater chla after TMDL implementation
filter(dat.pt, Chla2010 > 0.2 & ChlaDiff < 0) # one lake

p1 <- ggplot() +
  geom_sf(data = wsb) +
  geom_sf(data = filter(dat.pt, Chla2010 < 0.2 & ChlaDiff > 0) %>%
            arrange(ChlaDiff), 
          aes(color = ChlaDiff * 1000), # *1000 for mg -> ug
          size = 1) + 
  geom_sf(data = cbb, fill = "white", size = 0.1) +
  annotate("text", x = -80, y = 43, label = "B") +
  labs(color = "Chl a\nreduction (ug/L)") +
  theme(panel.background = element_blank(),
        panel.border = element_rect(color = "black", fill = NA),
        legend.justification = c(0,1),
        legend.title = element_text(size=8),
        axis.title = element_blank())

# chl.ecdf as above
chl.ecdf <- ggplot(dplyr::filter(dat.long, grepl(pattern = "Chl", x = name)), 
             aes(value * 1000, linetype = scenario)) + # *1000 for mg -> ug
  stat_ecdf(geom="step", pad = FALSE) +
  xlim(0, 125) + # otherwise extreme values obscure patterns
  ylab("Proportion of Lakes") +
  xlab("chlorophyll a (ug/L)") +
  annotate("text", x = 0, y = 1, label = "A") +
  theme_bw() +
  theme(legend.position = c(0.8, 0.4),
        legend.title = element_blank())

# TP figure
p2 <- ggplot() +
  geom_sf(data = wsb) +
  geom_sf(data = filter(dat.pt, Chla2010 < 0.2 & ChlaDiff > 0) %>%
            arrange(pDiff), 
          aes(color = pDiff * 1000), # *1000 for mg -> ug
          size = 1) +
  geom_sf(data = cbb, fill = "white", size = 0.1) + #size = NA
  annotate("text", x = -80, y = 43, label = "D") +
  labs(color = "TP\nreduction (ug/L)", size = "Lake size (km2)") +
  theme(panel.background = element_blank(),
        panel.border = element_rect(color = "black", fill = NA),
        legend.justification = c(0,1),
        legend.title = element_text(size=8),
        axis.title = element_blank())



tp.ecdf <- ggplot(dplyr::filter(dat.long, grepl(pattern = "Pvv", x = name)), 
             aes(value * 1000, linetype = scenario)) + # *1000 for mg -> ug
  stat_ecdf(geom="step", pad = FALSE) +
  xlim(0, 250) +
  ylab("Proportion of Lakes") +
  xlab("Total phosphorus (ug/L)") +
  annotate("text", x = 0, y = 1, label = "C") +
  theme_bw() +
  theme(legend.position = "none")

g <- gridExtra::grid.arrange(chl.ecdf, p1, tp.ecdf, p2, ncol = 2, nrow = 2)

ggsave(file = "output/figures/Fig.3_small.tiff", g, width = 7.5, height = 6.0, units = "in")






```

## Figure 3: CDF and spatial of TP and Chla with rainbow color ramp
```{r}
#Figure 3
# 4 panel plot of chl cdf, chl diff spatial plot, tp cdf, tp diff spatial

# chl figure
# better without extreme values.  Remove single lake with really large chla value
# (>200ug/L) and  greater chla after TMDL implementation
filter(dat.pt, Chla2010 > 0.2 & ChlaDiff < 0) # one lake

p1 <- ggplot() +
  geom_sf(data = wsb) +
  geom_sf(data = filter(dat.pt, Chla2010 < 0.2 & ChlaDiff > 0) %>%
            arrange(ChlaDiff), 
          aes(color = ChlaDiff * 1000)) + # *1000 for mg -> ug
  geom_sf(data = cbb, fill = "white", size = 0.1) +
  annotate("text", x = -80, y = 43, label = "B") +
  labs(color = "Chl a\nreduction (ug/L)") +
  theme(panel.background = element_blank(),
        panel.border = element_rect(color = "black", fill = NA),
        legend.justification = c(0,1),
        legend.title = element_text(size=8),
        axis.title = element_blank()) + 
  scale_color_gradientn(colors = rainbow(5))

# chl.ecdf as above
chl.ecdf <- ggplot(dplyr::filter(dat.long, grepl(pattern = "Chl", x = name)), 
             aes(value * 1000, linetype = scenario)) + # *1000 for mg -> ug
  stat_ecdf(geom="step", pad = FALSE) +
  xlim(0, 125) + # otherwise extreme values obscure patterns
  ylab("Proportion of Lakes") +
  xlab("chlorophyll a (ug/L)") +
  annotate("text", x = 0, y = 1, label = "A") +
  theme_bw() +
  theme(legend.position = c(0.8, 0.4),
        legend.title = element_blank())

# TP figure
p2 <- ggplot() +
  geom_sf(data = wsb) +
  geom_sf(data = filter(dat.pt, Chla2010 < 0.2 & ChlaDiff > 0) %>%
            arrange(pDiff), 
          aes(color = pDiff * 1000)) + # *1000 for mg -> ug
  geom_sf(data = cbb, fill = "white", size = 0.1) + #size = NA
  annotate("text", x = -80, y = 43, label = "D") +
  labs(color = "TP\nreduction (ug/L)", size = "Lake size (km2)") +
  theme(panel.background = element_blank(),
        panel.border = element_rect(color = "black", fill = NA),
        legend.justification = c(0,1),
        legend.title = element_text(size=8),
        axis.title = element_blank()) + 
  scale_color_gradientn(colors = rainbow(5))



tp.ecdf <- ggplot(dplyr::filter(dat.long, grepl(pattern = "Pvv", x = name)), 
             aes(value * 1000, linetype = scenario)) + # *1000 for mg -> ug
  stat_ecdf(geom="step", pad = FALSE) +
  xlim(0, 250) +
  ylab("Proportion of Lakes") +
  xlab("Total phosphorus (ug/L)") +
  annotate("text", x = 0, y = 1, label = "C") +
  theme_bw() +
  theme(legend.position = "none")

g <- gridExtra::grid.arrange(chl.ecdf, p1, tp.ecdf, p2, ncol = 2, nrow = 2)

ggsave(file = "output/figures/Fig.3_rainbow.tiff", g, width = 7.5, height = 6.0, units = "in")






```


## Figure 4: areal N2O, CH4, CO2 reductions spatial
```{r}
# CH4 figure
p4 <- ggplot() +
  geom_sf(data = wsb) +
  geom_sf(data = filter(dat.pt, Chla2010 < 0.2 & ChlaDiff > 0) %>%
            arrange(ch4diff_g_m2_y), 
          aes(color = ch4diff_g_m2_y)) +
  geom_sf(data = cbb, fill = "white", size = 0.1) +
  annotate("text", x = -80, y = 43, label = "A") +
  labs(color = expression(atop(CH[4]~change, (g~m^{-2}~y^{-1})))) +
  theme(panel.background = element_blank(), # plot space background
        panel.border = element_rect(color = "black", fill = NA), # plot border
        axis.text = element_text(size = 7),
        axis.title = element_blank(),
        #legend.justification = c(0,1), # legend position
        legend.title = element_text(size=8),
        legend.text = element_text(size = 6),
        legend.key.width = unit(0.5, "cm"),
        legend.key.height = unit(0.5, "cm"),
        legend.position = "top") + 
  scale_color_gradientn(colors = rainbow(5))


# CO2 figure
p5 <- ggplot() +
  geom_sf(data = wsb) +
  geom_sf(data = filter(dat.pt, Chla2010 < 0.2 & ChlaDiff > 0) %>%
            arrange(co2diff_g_m2_y), 
          aes(color = co2diff_g_m2_y)) +
  geom_sf(data = cbb, fill = "white", size = 0.1) +
  annotate("text", x = -80, y = 43, label = "B") +
  labs(color = expression(atop(CO[2]~change, (g~m^{-2}~y^{-1})))) +
  theme(panel.background = element_blank(),
        panel.border = element_rect(color = "black", fill = NA),
        axis.text = element_text(size = 7),
        axis.title = element_blank(),
        legend.justification = c(0,1),
        legend.title = element_text(size=8),
        legend.text = element_text(size = 6),
        legend.key.width = unit(0.5, "cm"),
        legend.key.height = unit(0.5, "cm"),
        legend.position = "top") +
  scale_color_gradientn(colors = rainbow(5))


# N2O figure
p6 <- ggplot() +
  geom_sf(data = wsb) +
  geom_sf(data = filter(dat.pt, Chla2010 < 0.2 & ChlaDiff > 0) %>%
            arrange(n2odiff_g_m2_y), # plot higher value points on top of lower
          aes(color = n2odiff_g_m2_y)) +
  geom_sf(data = cbb, fill = "white", size = 0.1) +
  annotate("text", x = -80, y = 43, label = "C") +
  labs(color = expression(atop(N[2]*O~change, (g~m^{-2}~y^{-1})))) +
  theme(panel.background = element_blank(),
        panel.border = element_rect(color = "black", fill = NA),
        axis.text = element_text(size = 7),
        axis.title = element_blank(),
        legend.justification = c(0,1),
        legend.title = element_text(size=8),
        legend.text = element_text(size = 6),
        legend.key.width = unit(0.5, "cm"),
        legend.key.height = unit(0.5, "cm"),
        legend.position = "top") +
  scale_color_gradientn(colors = rainbow(5), breaks = c(0.01, 0.05, 0.1))


cowplot::plot_grid(p4, p5, p6, ncol = 3, nrow = 1, align = "hv")

ggsave(file = "output/figures/figure4.tiff", width = 7, height = 5, units = "in")

```

## Figure 5: cumulative plot of total emission reductions by lake size
```{r fig5}
# total reduction by lake size
dat.cum.emissions <- dat.pt %>%
  st_drop_geometry() %>%
  arrange(AREASQKM) %>%
  select(AREASQKM, ch4diffMg, co2diffMg, n2odiffKg) %>%
  mutate(across(contains("diff"), cumsum)) %>%
  pivot_longer(!AREASQKM, values_to = "emission") %>%
  group_by(name) %>%
  mutate(ninety = 0.9*max(emission), # this grabs 90% of total emission reduction
         max = max(emission))

######## this chunk grabs rows corresponding to 90% of total reduction for each gas
######## I thought about adding these via geom_vline to plot, but decided against it
# identify row corresponding to 90% of total emission reductions
index.ninety <- dat.cum.emissions %>%
  summarize(index = which.min(abs(emission - unique(ninety))))

ninety <- dat.cum.emissions %>% # grab the row corresponding to 90% of total reductions
  group_by(name) %>%
  slice(index.ninety$index)
  
###### make the figure
dat.cum.emissions %>%
  ggplot(aes(AREASQKM, emission, color = name)) + 
  geom_point(size = 1) + geom_line() +
  scale_x_log10() +
  # change name of legend items
  scale_color_discrete(labels = c(expression(CH[4]), expression(CO[2]), expression(N[2]*O))) +
  ylab(expression(atop("Cumulative emission reductions",
  paste("(mt ", CO[2], ", mt ", CH[4], ", kg ", N[2], "O)")))) +
  xlab(expression(Waterbody ~ surface ~ area ~ (km^{2}))) +
  theme_bw() +
  theme(legend.title = element_blank(),
        legend.position = "top",
        legend.margin=margin(0,0,0,0),
        legend.box.margin=margin(-10,-10,-10,-10),
        axis.title = element_text(size = 9),
        axis.text = element_text(size = 7))


ggsave(file = "output/figures/Figure5.tiff", width = 3, height = 2.5, units = "in")
```

## Supplemental Figure 1
```{r supplementalFig1}
# version 1 was replaced with Trend Surface analysis figure in version 2
# 
# # Version 1:  reduction in areal CH4 emission rate vs latitude
# dat.lat <- dat.pt %>%
#   filter(Chla2010 < 0.2 & ChlaDiff > 0) %>%
#   mutate(lat = st_coordinates(.)[,2]) %>%
#   st_drop_geometry() %>%
#   dplyr::select(lat, ChlaDiff, pDiff, contains("diff_g")) %>%
#   mutate(ChlaDiff = ChlaDiff *1000, # mg/l --> ug/L
#          pDiff = pDiff * 1000) %>% # mg/l --> ug/L
#   pivot_longer(cols = !lat) %>%
#   # this trick below controls placement of facets
#   mutate(name = factor(name, levels = c("ch4diff_g_m2_y", "co2diff_g_m2_y", "n2odiff_g_m2_y","pDiff", "ChlaDiff")))
#  
# # custom labels for facets.  This is a DF containing a custom label for each row in data.lat
# facet.labs <- dat.lat %>% select(name) %>%
#   mutate(name = case_when(name == "ch4diff_g_m2_y" ~ "CH[4]", # note subscript picked up below
#                            name == "ChlaDiff" ~ "chlorophyll~a",
#                            name == "co2diff_g_m2_y" ~ "CO[2]",
#                            name == "n2odiff_g_m2_y" ~ "N[2]*O",
#                            name == "pDiff" ~ "total~phosphorus"))
# facet.labs <- setNames(facet.labs$name, dat.lat$name) # apply labels to data
# 
# p1 <- ggplot(dat.lat %>% filter(name %in% c("ChlaDiff", "pDiff")), aes(lat, value)) +
#   geom_point() +
#   facet_wrap(~name, scales = "free", 
#              labeller = as_labeller(facet.labs, # custom labels
#                                     default = label_parsed)) + # this applies formatting
#   ylab(expression(atop("Baseline - TMDL", "("*mu*"g"~L^{-1}*")"))) +
#   theme(axis.title.x = element_blank())
# 
# ggsave(p1, file = "output/figures/supplementalFigure1A.tiff", width = 6.9*(2/3), height = 2.5, units = "in")
# 
# p2 <- ggplot(dat.lat %>% filter(name %in% c("ch4diff_g_m2_y", "co2diff_g_m2_y", "n2odiff_g_m2_y")), 
#              aes(lat, value)) +
#   geom_point() +
#   facet_wrap(~name, scales = "free", 
#              labeller = as_labeller(facet.labs, # custom labels
#                                     default = label_parsed)) + # this applies formatting
#   ylab(expression(atop("Baseline - TMDL", "(g"~m^{-2}~year^{-1}*")"))) +
#   xlab("latitude")
# ggsave(p2, file = "output/figures/supplementalFigure1B.tiff", width = 7, height = 2.7, units = "in")
# 
# # ended up stitching together in .ppt.  Couldn't get separate y-axis labels and proper facet sizes
# # with cowplot.  

# Version 2: Trend Surface Analysis
# https://www.css.cornell.edu/faculty/dgr2/_static/files/R_PDF/ex_TrendSurface.pdf


# Prepare data
dat.pt.alber <- dat.pt %>%
  filter(Chla2010 < 0.2 & ChlaDiff > 0) %>% # remove outliers
  st_transform(5070) %>% # albers equal area.  want equal distance in cardinal directions
  mutate(x= st_coordinates(.)[,1], # add longitude as df column
         y = st_coordinates(.)[,2]) # add latitude as df column

# Trend Surface model for each GHG
models <- dat.pt.alber %>%
  st_drop_geometry() %>%
  select(ch4diff_g_m2_y, co2diff_g_m2_y, 
         n2odiff_g_m2_y, ChlaDiff, pDiff, x, y) %>%
  pivot_longer(-c(x,y)) %>%
  group_split(name) %>% # split each dependent variable into list element
  purrr::set_names(purrr::map_chr(., ~.x$name[1])) %>% # name each list element
  map(., ~lm(value ~ x * y, data = .)) # linear model for each list element

map(models, summary) # cardinal directions significant for all variables

# Extract residuals
m_resid <- map(models, ~residuals(.) %>% tibble::enframe(name = NULL))

# residual distributions a bit log_normal, but really not too bad.
imap(m_resid, ~ggplot(., aes(x=value)) + geom_histogram() +
       ggtitle(.y))

# residuals vs fitted
# yeah, not so great
imap(models, function(x, .y){
  plot(x$fitted.values, x$residuals, main = .y)
  
})


# create grid
range(dat.pt.alber$x);range(dat.pt.alber$y) # bounding box
seq.x <- seq(1330000, 1860000, by=2000)  # expand limits relative to above.  Make sure to cover entire watershed
seq.y <- seq(1670000, 2410000, by=2000) # expand limits relative to above.  Make sure to cover entire watershed
grid.albers <- expand.grid(x = seq.x, y = seq.y)
plot(grid.albers$y ~ grid.albers$x, cex=0.1, asp=1) # visualize grid

# predict to grid
pred_model <- map(models, ~predict.lm(object = ., 
                                      newdata = grid.albers, 
                                      interval = "prediction") %>%
                    cbind(as.data.frame(.), grid.albers) %>% # combine predictions with observations
                    st_as_sf(., coords = c("x", "y"))) %>% # coerce to sf
  map(., function(x) {
    st_crs(x) <- 5070 # set crs as albers
    x
  })


# clip grid to watershed boundary
# slow, arcGIS Pro alternative below
tic() #24 minutes in R on Dell Precision laptop
pred_grid_clip <- map(pred_model, ~st_intersection(., wsb_albers))
toc()

# # Alternatively, write to Pro, clip in Pro, then read in
# # this gives benefit of manually editing out points that
# # fall outside watershed boundary.
# # write to disk for clipping in Pro
# imap(pred_model, ~st_write(., paste0("output/", .y, "_grid.shp"), delete_layer = TRUE))
# 
# # clip grid to watershed boundary in Pro, read from disk
# pred_grid_clip <- fs::dir_ls(path = "output", regexp = "grid_clip.shp") %>%
#   .[!grepl(".xml|lock", .)] %>%
#   map(., st_read)


names(pred_grid_clip)
map(pred_grid_clip, st_crs) #5070, good

# watershed boundary
wsb_albers <- wsb %>% st_transform(5070)

# Maps
# could generate all 5 with one map call, but difficult
# to customize legend label, especially if we want to 
# format with subscripts.
# using data from Pro now, but switch to pred_grid_clip to keep workflow in R
# chl figure
p1 <- ggplot() +
  geom_sf(data = pred_grid_clip$`output/ChlaDiff_grid_clip.shp`,
          aes(color = fit*1000)) +
  geom_sf(data = dat.pt.alber, color = "black", size = 0.1) +
  annotate("text", x = 1330000, y = 2410000, label = "A") +
  labs(color = expression(atop(chlorophyll~a~change, (mu*g~L^{-1})))) +
  geom_sf(data = cbb %>% st_transform(5070), fill = "white", size = 0.1) +
  theme(panel.background = element_blank(), # plot space background)
        panel.border = element_rect(color = "black", fill = NA), # plot border
        axis.text = element_text(size = 7),
        axis.title = element_blank(),
        #legend.justification = c(0,1), # legend position
        legend.title = element_text(size=8),
        legend.text = element_text(size = 6),
        legend.key.width = unit(0.5, "cm"),
        legend.key.height = unit(0.5, "cm"),
        legend.position = "top")  +
  scale_color_distiller(palette = "OrRd",
                        direction = 1)
        
# TP figure
p2 <- ggplot() +
  geom_sf(data = pred_grid_clip$`output/pDiff_grid_clip.shp`,
          aes(color = fit*1000)) +
  geom_sf(data = dat.pt.alber, color = "black", size = 0.1) +
  annotate("text", x = 1330000, y = 2410000, label = "B") +
  labs(color = expression(atop(phosphorus~change, (mu*g~L^{-1})))) +
  geom_sf(data = cbb %>% st_transform(5070), fill = "white", size = 0.1) +
  theme(panel.background = element_blank(), # plot space background)
        panel.border = element_rect(color = "black", fill = NA), # plot border
        axis.text = element_text(size = 7),
        axis.title = element_blank(),
        #legend.justification = c(0,1), # legend position
        legend.title = element_text(size=8),
        legend.text = element_text(size = 6),
        legend.key.width = unit(0.5, "cm"),
        legend.key.height = unit(0.5, "cm"),
        legend.position = "top")  +
  scale_color_distiller(palette = "OrRd",
                        direction = 1)

# CH4 figure
p3 <- ggplot() +
  geom_sf(data = pred_grid_clip$`output/ch4diff_g_m2_y_grid_clip.shp`,
          aes(color = fit)) +
  geom_sf(data = dat.pt.alber, color = "black", size = 0.1) +
  annotate("text", x = 1330000, y = 2410000, label = "C") +
  labs(color = expression(atop(CH[4]~change, (g~m^{-2}~y^{-1})))) +
  geom_sf(data = cbb %>% st_transform(5070), fill = "white", size = 0.1) +
  theme(panel.background = element_blank(), # plot space background)
        panel.border = element_rect(color = "black", fill = NA), # plot border
        axis.text = element_text(size = 7),
        axis.title = element_blank(),
        #legend.justification = c(0,1), # legend position
        legend.title = element_text(size=8),
        legend.text = element_text(size = 6),
        legend.key.width = unit(0.5, "cm"),
        legend.key.height = unit(0.5, "cm"),
        legend.position = "top")  +
  scale_color_distiller(palette = "OrRd",
                        direction = 1)


# CO2 figure
p4 <- ggplot() +
  geom_sf(data = pred_grid_clip$`output/co2diff_g_m2_y_grid_clip.shp`,
          aes(color = fit)) +
  geom_sf(data = dat.pt.alber, color = "black", size = 0.1) +
  annotate("text", x = 1330000, y = 2410000, label = "D") +
  labs(color = expression(atop(CO[2]~change, (g~m^{-2}~y^{-1})))) +
  geom_sf(data = cbb %>% st_transform(5070), fill = "white", size = 0.1) +
  theme(panel.background = element_blank(), # plot space background)
        panel.border = element_rect(color = "black", fill = NA), # plot border
        axis.text = element_text(size = 7),
        axis.title = element_blank(),
        #legend.justification = c(0,1), # legend position
        legend.title = element_text(size=8),
        legend.text = element_text(size = 6),
        legend.key.width = unit(0.5, "cm"),
        legend.key.height = unit(0.5, "cm"),
        legend.position = "top")  +
  scale_color_distiller(palette = "OrRd",
                        direction = 1)


# N2O figure
p5 <- ggplot() +
  geom_sf(data = pred_grid_clip$`output/n2odiff_g_m2_y_grid_clip.shp`,
          aes(color = fit)) +
  geom_sf(data = dat.pt.alber, color = "black", size = 0.1) +
  annotate("text", x = 1330000, y = 2410000, label = "E") +
  labs(color = expression(atop(N[2]*O~change, (g~m^{-2}~y^{-1})))) +
  geom_sf(data = cbb %>% st_transform(5070), fill = "white", size = 0.1) +
  theme(panel.background = element_blank(), # plot space background)
        panel.border = element_rect(color = "black", fill = NA), # plot border
        axis.text = element_text(size = 7),
        axis.title = element_blank(),
        #legend.justification = c(0,1), # legend position
        legend.title = element_text(size=8),
        legend.text = element_text(size = 6),
        legend.key.width = unit(0.5, "cm"),
        legend.key.height = unit(0.5, "cm"),
        legend.position = "top")  +
  scale_color_distiller(palette = "OrRd",
                        direction = 1)

# having trouble getting a satisfactory layout with cowplot.
# got sick of fighting and arranged each panel in a drawing
# canvas in Word.
ggsave(p1, file = "output/figures/supplementalFigure1A.tiff")
ggsave(p2, file = "output/figures/supplementalFigure1B.tiff")
ggsave(p3, file = "output/figures/supplementalFigure1C.tiff")
ggsave(p4, file = "output/figures/supplementalFigure1D.tiff")
ggsave(p5, file = "output/figures/supplementalFigure1E.tiff")


# cowplot::plot_grid(p1, p2, NULL, p3, p4, p5, ncol = 3, nrow = 2, align = "hv")
# 
# ggsave(file = "output/figures/trendSurface.tiff", width = 7, height = 2.5, units = "in")

```


## Supplemental Figure 2
```{r supplementalFig2}
# Reduction in emission rates (mg GHG m-2 d-1) is proportional to reduction in chl
ggplot(dat.pt, aes(ChlaDiff, ch4diff_g_m2_y)) +
  geom_point(size = 0.5) +
  ylim(-25, 60) + # cut out a few points with large negative values
  xlim(-0.03, 0.075) +
  ylab(expression(atop(CH[4]~emission~rate, Baseline~-~TMDL~(g~m^{-2}~y^{-1})))) +
  xlab(expression(atop(chlorophyll~a, Baseline~-~TMDL~(mu*g~L^{-1})))) +
  theme(axis.title = element_text(size = 10))

ggsave("output/figures/supplementalFigure2.tiff", width = 3, height = 3, units = "in")


```
## Supplemental Figure 3: ice cover
```{r supplementalFig3}
 ggplot() +
  geom_sf(data = wsb) +
  geom_sf(data = dat.pt, aes(color = day_of_ice_filled), size =1) +
  geom_sf(data = cbb, fill = "white", size = NA) +
  labs(color = expression("Ice cover \n duration (days)")) +
  theme(panel.background = element_blank(),
        panel.border = element_rect(color = "black", fill = NA),
        legend.text = element_text(size = 7),
        legend.title = element_text(size = 7),
        axis.text = element_text(size = 7))

ggsave(file = "output/figures/supplementalFigure3.tiff", width = 4, height = 3, units = "in")
```

## Supplemental Figure 4: delta CO2 vs delta chla
```{r supplementalFig4}
# Change in CO2 areal emission rate (g CO2 m-2 y-1) vs waterbody size
ggplot(dat.pt, aes(AREASQKM, co2diff_g_m2_y)) + 
  geom_point(size = 0.5) + 
  scale_x_log10() +
  ylab(expression(atop(CO[2]~emission~rate, Baseline~-~TMDL~(g~m^{-2}~y^{-1})))) +
  xlab(expression(waterbody~surface~area~(km^{2}))) +
  theme(axis.title = element_text(size = 10))

ggsave(file = "output/figures/supplementalFigure4.tiff", width = 3, height = 3, units = "in")
```

## Supplemental Figure 5: lake size histogram
```{r supplementalFig5}
# See 'Lake size distribution' section
# lake size histogram
ggplot(dat.pt, aes(x=AREASQKM)) + 
  geom_histogram(bins = 75) + 
  scale_x_log10() +
  xlab(expression(Waterbody~surface~area~(km^{2}))) +
   theme(axis.title = element_text(size = 10))

ggsave("output/figures/supplementalFigure5.tiff", width = 3, height = 3, units = "in")

```

## Supplemental Table 1  
```{r supplementalTable1}
dat.pt %>% 
  st_drop_geometry() %>% # remove spatial
  dplyr::select(Chla2010, Pvv2010,
                ChlaTMDLnew, PvvTMDLnew,
                AREASQKM) %>% 
  mutate(across(matches(c("2010|new")), ~ .*1e3)) %>% # *1e3 mg/L to ug/L
  summarise(across(everything(), list(mean = ~mean(.),
                                      median = ~median(.),
                                      low.99 = ~quantile(., 0.01),
                                      high.99 = ~quantile(., 0.99)))) %>%
  pivot_longer(cols = everything()) %>%
  mutate(# https://www.statology.org/r-extract-string-after-character/
    stat = sub(".*_", "", name), # extract characters after string.  
    name = sub("_.*", "", name)) %>% # extract characters before string
  pivot_wider(names_from = stat, values_from = value) %>%
  arrange(name)

nrow(dat.pt) # 4222
                                       



```


## Optional Data Figure 1
```{r optionalFig1}

# TOTAL REDUCTION-----
# histogram
# CH4
p.ch4 <- ggplot(dat.pt, aes(x = ch4diffMg))  + 
  geom_histogram(bins = 75) +
  scale_x_continuous(trans = ggallin::pseudolog10_trans, 
                     breaks = c(-10, -3, 0, 3, 10, 30, 100), 
                     minor_breaks = NULL) +
  geom_rug(length = grid::unit(3, units = "mm")) +
  annotate("text", x = min(dat.pt$ch4diffMg), y = Inf, hjust = 0, vjust = 1, label = "A", size = 8) +
  xlab(expression(atop("Emission Change", ~(metric~tons~CH[4]~yr^{-1}~lake^{-1})))) +
  theme_bw() +
  theme(axis.title.y = element_blank(),
        axis.text = element_text(size = 15),
        axis.title = element_text(size = 20))


# N2O
p.n2o <- ggplot(dat.pt, aes(x = n2odiffKg)) + 
  geom_histogram(bins = 75) +
  scale_x_continuous(trans = ggallin::pseudolog10_trans, 
                     breaks = c(-10, -3, 0, 3, 10, 30, 100)) +
  geom_rug(length = grid::unit(3, units = "mm")) +
  annotate("text", x = min(dat.pt$n2odiffKg), y = Inf, hjust = 0, vjust = 1, label = "B", size = 8) +
  xlab(expression(atop("Emission Change", ~(kg~N[2]*O~yr^{-1}~lake^{-1})))) +
  theme_bw() +
  theme(axis.title.y = element_blank(),
        axis.text = element_text(size = 15),
        axis.title = element_text(size = 20))

# CO2
p.co2 <- ggplot(dat.pt, aes(x = co2diffMg)) + 
  geom_histogram(bins = 75) +
  scale_x_continuous(trans = ggallin::pseudolog10_trans,
                     breaks = c(-10, -3, 0, 3, 10, 30, 100)) +
  geom_rug(length = grid::unit(3, units = "mm")) +
  annotate("text", x = min(dat.pt$co2diffMg), Inf, hjust = 0, vjust = 1, label = "C", size=8) +
  xlab(expression(atop("Emission Change", ~(metric~tons~CO[2]~yr^{-1}~lake^{-1})))) +
  theme_bw() +
  theme(axis.title.y = element_blank(),
        axis.text = element_text(size = 15),
        axis.title = element_text(size = 20))


g <- gridExtra::grid.arrange(p.ch4, p.co2, p.n2o, ncol = 3, nrow = 1)

ggsave(file = "output/figures/optionalFigure1.tiff", g, width = 15, height = 6, units = "in")


```

## Optional Data Figure 2
```{r optionalFig2}
# see ## Avoided emissions vs environmental variables (above)


# Avoided GHG emissions by lake surface area bar plot----------
# set up data
dat.bin <- dat.pt %>%
  st_drop_geometry() %>%
  mutate(lake.bins = ifelse(AREASQKM <= 0.01,
                            "< 0.01 km2",
                            ifelse(AREASQKM > 0.01 & AREASQKM <= 0.1,
                                   ">0.01 km2 & < 0.1 km2",
                                   ifelse(AREASQKM > 0.10 & AREASQKM <= 1,
                                          ">0.1 km2 & < 1 km2",
                                          ifelse(AREASQKM > 1 & AREASQKM <= 10,
                                                 ">1 km2 & < 10 km2",
                                                 ifelse(AREASQKM > 10,
                                                        "> 10 km2",
                                                        "error"))))),
         lake.bins = factor(lake.bins, levels = c("< 0.01 km2", ">0.01 km2 & < 0.1 km2",
                                                  ">0.1 km2 & < 1 km2", ">1 km2 & < 10 km2",
                                                  "> 10 km2"))) %>%

 dplyr::select(co2diffMg, ch4diffMg, n2odiffKg, lake.bins, AREASQKM) %>%
  pivot_longer(cols = -c(lake.bins, AREASQKM)) %>%
  group_by(name, lake.bins) %>% # operate by gas x lake.bin
  summarize(total = sum(value), # total avoided
            obs = paste0("n = ", length(value), ", area = ", round(sum(AREASQKM), 0), " km2")) #lakes per group

# create labels for facets
name.labs <- as_labeller(c("ch4diffMg" = "CH[4]",
                           "co2diffMg" = "CO[2]",
                           "n2odiffKg" = "N[2]*O"),
                         default = label_parsed)


# plot
ggplot(dat.bin, aes(x=lake.bins, y=total)) +
  geom_bar(position="dodge", stat="identity") +
  facet_wrap(~name, nrow = 3, scales = "free_y", labeller = name.labs) +
  ylab(expression(Avoided~GHG~emissions~(MT~GHG~yr^{-1}))) +
  theme(axis.title.x = element_blank()) +
  geom_text(aes(label = obs), vjust = -0.5, size = 3) +
  scale_y_continuous(expand = expansion(mult = c(0.05, 0.2)))


ggsave(file = "output/figures/optionalFigure2.tiff", width = 10, height = 5, units = "in")
```

# Manuscript Stats
## Policy effect on nutrients, chlorophyll, and area GHG emission rates  
```{r}
# how many sites with increased TP and chla under TMDL
dat.pt %>% # 78 sites out of 4221 = 1.8%
  st_drop_geometry() %>% 
  as_tibble() %>%
  filter(pDiff < 0 | ChlaDiff < 0) %>%
  summarize(n = nrow(.))


# TP and Chla:  average reduction across all sites
map(dat.pt %>% select(pDiff, ChlaDiff) %>% mutate(across(everything(), ~ .x * 1000)), summary)

# TP and Chla:  average % reduction across all sites  
# 21.1 and 21.4%, respectively.  Slightly different than when calculated using
# data from extended data table 1 due to rounding errors.
dat.pt %>% # 
  st_drop_geometry() %>%
  select(ChlaTMDLnew, Chla2010, PvvTMDLnew, Pvv2010) %>%
  summarise(across(everything(), ~mean(.) * 1000)) %>%
  mutate(perc_chla = (Chla2010 -  ChlaTMDLnew) / Chla2010 * 100,
         perc_tp = (Pvv2010 - PvvTMDLnew) / Pvv2010 * 100)
  
# CH4: average change across sites
map(dat.pt %>% select(ch4diff_g_m2_y, preds_lakes_g_m2_y_2010_ch4), summary) # 6.65
dat.pt %>% mutate(ch4diff_perc = (ch4diff_g_m2_y / preds_lakes_g_m2_y_2010_ch4) * 100) %>%
  {summary(.$ch4diff_perc)}

# CO2: average change across sites
map(dat.pt %>% select(co2diff_g_m2_y, preds_lakes_g_m2_y_2010_co2), summary) # 42

dat.pt %>% filter(AREASQKM > 12) %>% 
  select(AREASQKM, co2diff_g_m2_y, pDiff, ChlaDiff) %>% 
  arrange(AREASQKM) # 4 large lakes w/<co2Diff

dat.pt %>% filter(AREASQKM > 12) %>% 
  select(AREASQKM, co2diff_g_m2_y, pDiff, ChlaDiff) %>% 
 summarize(meanCo2Large = mean(co2diff_g_m2_y)) # 4 large lakes w/<co2Diff

dat.pt %>% mutate(size = case_when(AREASQKM > 12 ~ "big", TRUE ~ "small")) %>%
  {table(.$size)} # only 4 big lakes

ggplot(dat.pt, aes(AREASQKM, co2diff_g_m2_y)) + geom_point()

dat.pt %>% mutate(co2diff_perc = (co2diff_g_m2_y / preds_lakes_g_m2_y_2010_co2) * 100) %>%
  {summary(.$co2diff_perc)} #4.9%

# N2O: average change across sites
map(dat.pt %>% select(n2odiff_g_m2_y, preds_lakes_g_m2_y_2010_n2o), summary) # 0.006
dat.pt %>% mutate(n2odiff_perc = (n2odiff_g_m2_y / preds_lakes_g_m2_y_2010_n2o) * 100) %>%
  {summary(.$n2odiff_perc)}



```


## Policy effect on GHG emissions
```{r}

# total GHG reductions
kr_simulations %>%
  kbl(col.names = rep(c("mean", "upper 95", "lower 5"), 3),
      caption = "Incremental GHG (metric tons) calculated from simulation (Krinsky and Robb, 1986)") %>%
  add_header_above(c("incremental CH4" = 3, "incremental CO2" = 3, "incremental N2O" = 3)) %>%
  kable_classic()


# this give lake size at specified probability
quantile(dat.pt$AREASQKM, probs = 0.987) # 98.7% are <= 0.95796 km2


# proportion of SA attributable to lakes < 1km2.  57%!!!
dat.pt[dat.pt$AREASQKM <= 1, "AREASQKM"] %>% 
  st_drop_geometry() %>%
  sum() / #280.85
  sum(dat.pt$AREASQKM) #491.626 km2

# proportion of SA attributable to lakes > 1km2.  43%!!!
dat.pt[dat.pt$AREASQKM >= 1, "AREASQKM"] %>% 
  st_drop_geometry() %>%
  sum() / #210.78
  sum(dat.pt$AREASQKM) #491.626 km2

# how many greater than 1km2
dat.pt[dat.pt$AREASQKM >= 1, "AREASQKM"] %>% nrow() #54




# total reduction by lake size
dat.cum.emissions <- dat.pt %>%
  st_drop_geometry() %>%
  arrange(AREASQKM) %>%
  select(AREASQKM, ch4diffMg, co2diffMg, n2odiffKg) %>%
  mutate(across(contains("diff"), cumsum)) %>%
  pivot_longer(!AREASQKM, values_to = "emission") %>%
  group_by(name) %>%
  mutate(max = max(emission))

# total reduction for >1km2
dat.cum.emissions %>%
  slice(which.min(abs(AREASQKM - 1))) %>%
  mutate(prop.less.1 = 1 - (emission / max))


# % reduction by gas
dat.pt %>%
  st_drop_geometry() %>%
  summarize(across(matches(c("Mg_2010|Mg_tmdl")), sum)) %>%
  mutate(ch4_diff_percent = ((preds_lakes_Mg_2010_ch4 - preds_lakes_Mg_tmdl_ch4) / preds_lakes_Mg_2010_ch4) * 100,
         co2_diff_percent = ((preds_lakes_Mg_2010_co2 - preds_lakes_Mg_tmdl_co2) / preds_lakes_Mg_2010_co2) * 100,
         n2o_diff_percent = ((preds_lakes_Mg_2010_n2o - preds_lakes_Mg_tmdl_n2o) / preds_lakes_Mg_2010_n2o) * 100)
                   
                   _n2o = sum(preds_lakes_Mg_2010_n2o, na.rm = TRUE),
            preds_lakes_Mg_tmdl_n2o = sum(preds_lakes_Mg_tmdl_n2o, na.rm = TRUE)
  "preds_lakes_Mg_2010_n2o"     "preds_lakes_Mg_tmdl_n2o"

```

## Seasonal CH4 emissions
```{r}
# winter proportion of emissions under TMDL and 2010
seasonal_ch4 %>%
  mutate(
    # annual avoided emissions 
    inc_ch4_annual = (winter_ch4_2010 + warm_ch4_2010) - (winter_ch4_tmdl + warm_ch4_tmdl),
    # warm weather avoided emissions
    inc_ch4_warm = warm_ch4_2010 - warm_ch4_tmdl,
    # cold weather avoided emissions
    inc_ch4_winter = winter_ch4_2010 - winter_ch4_tmdl,
    # proportion of annual emissions occuring during winter: TMDL
    winter_prop_tmdl = winter_ch4_tmdl / (warm_ch4_tmdl + winter_ch4_tmdl),
    # proportion of annual emissions occuring during summer: 2010
    winter_prop_2010 = winter_ch4_2010 / warm_ch4_2010) %>%
  summarise(
    # Avoided emissions
    inc_ch4_annual = mean(inc_ch4_annual), # annual
    inc_ch4_warm = mean(inc_ch4_warm), # warm weather
    inc_ch4_winter = mean(inc_ch4_winter), # cold weather
    # proportion of annual emissions occuring during winter: TMDL
    uppr_winter_prop_tmdl = quantile(winter_prop_tmdl, .95), # upper 95%
    lowr_winter_prop_tmdl = quantile(winter_prop_tmdl, .05), # lower 5%
    winter_prop_tmdl = mean(winter_prop_tmdl), # mean
    # proportion of annual emissions occuring during winter: 2010    
    uppr_winter_prop_2010 = quantile(winter_prop_2010, .95), # upper 95%
    lowr_winter_prop_2010 = quantile(winter_prop_2010, .05), # lower 5%
    winter_prop_2010 = mean(winter_prop_2010), # mean
    # proportion of annual avoided emissions that were avoided during winter
    inc_ch4_winter_prop = mean(inc_ch4_winter / inc_ch4_annual))
```

## Latitudinal pattern in land use
```{r}

# NLCD cropland data
crop_cb <- geodata::landcover(var = "cropland", path = "store") %>%
  terra::crop(., wsb, mask = TRUE) %>% # crop to watershed
  terra::as.points() # convert to SpatVector

coords <- as.data.frame(terra::geom(crop_cb)) # extract lat, lon
values <- crop_cb$cropland # prop land cover per cell

crop_dat <- bind_cols(coords$x, coords$y, values) %>%
  setNames(c("x", "y", "values"))

# NLCD built data
built_cb <- geodata::landcover(var = "built", path = "store") %>%
terra::crop(., wsb, mask = TRUE) %>% # crop to watershed
  terra::as.points() # convert to SpatVector

coords <- as.data.frame(terra::geom(built_cb)) # extract lat, lon
values <- built_cb$built # prop land cover per cell

built_dat <- bind_cols(coords$x, coords$y, values) %>%
  setNames(c("x", "y", "values"))

# Model
list(crop_dat, built_dat) %>%
  map(., ~lm(values ~ x * y, data = .)) %>% # linear model for each list element
  map(., summary) # cardinal directions significant for all variables



```

# Write data for collaborators
```{r eval=FALSE}
# select columns of interest, convert units

dat.yr.sf.all %>%
  # select the stuff Elizabeth wanted
  dplyr::select(WB_ID, AREASQKM, day_of_ice_filled, Pvv2010, Chla2010, ch42010.lk.yr, ch4TMDLnew.lk.yr, co22010.lk.yr,                         co2TMDLnew.lk.yr, n2o2010.lk.yr, n2oTMDLnew.lk.yr, STATEFP, COUNTYFP) %>%
  # convert to Elizabeth's preferred units
  mutate(across(contains("lk.yr"),  ~. / (1e3*1e3*1e3))) %>% # mg->g, g->kg, kg->Mg. 1 MG = 1 metric ton = 1000kg)))
  # write to disk
  write.table(., paste0("C:\\Users\\JBEAULIE\\Environmental Protection Agency (EPA)\\Moore, Chris - Climate benefits of nutrient management\\Lakes Modeling\\climateBenefitsResults", Sys.Date(), ".txt"))

```






